[
  {
    "objectID": "notebooks/EC_GLM/EC_GLM.html#s.1-set-the-working-directory-and-create-a-folder-for-data.",
    "href": "notebooks/EC_GLM/EC_GLM.html#s.1-set-the-working-directory-and-create-a-folder-for-data.",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "S.1 Set the working directory and create a folder for data.",
    "text": "S.1 Set the working directory and create a folder for data.\nSave the Quarto Markdown file (.QMD) to a folder of your choice, and then set the path to your folder as your working directory.\n\n# Set the workspace to the current working directory\n# Uncomment and replace the path below with your own working directory if needed:\n# setwd(\"/Users/zhaoxiang/Documents/tmp/EC_GLM_notebook\") \n\nworkspace &lt;- getwd()  # Get the current working directory and store it in 'workspace'\n\n# Increase the plot size by adjusting the options for plot dimensions in the notebook output\noptions(repr.plot.width = 16, repr.plot.height = 8)  # Sets width to 16 and height to 8 for larger plots\n\nIdeally, you would use the renv package to create an isolated environment for installing all the required R packages used in this notebook. However, since installing renv and its dependencies can be time-consuming, we recommend trying this after the workshop.\n\n# # Ensure \"renv\" package is installed\n# if (!requireNamespace(\"renv\", quietly = TRUE)) {\n#   install.packages(\"renv\")\n# }\n# \n# # Check if renv has been initialized in the project\n# if (!file.exists(\"renv/activate.R\")) {\n#   message(\"renv has not been initiated in this project. Initializing now...\")\n#   renv::init()  # Initialize renv if not already set up\n# } else {\n#   source(\"renv/activate.R\")  # Activate the renv environment\n#   message(\"renv is activated.\")\n# }\n# \n# # Check for the existence of renv.lock and restore the environment\n# if (file.exists(\"renv.lock\")) {\n#   message(\"Restoring renv environment from renv.lock...\")\n#   renv::restore()\n# } else {\n#   message(\"No renv.lock file found in the current directory. Skipping restore.\")\n# }"
  },
  {
    "objectID": "notebooks/EC_GLM/EC_GLM.html#s.2-install-and-load-essential-libraries.",
    "href": "notebooks/EC_GLM/EC_GLM.html#s.2-install-and-load-essential-libraries.",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "S.2 Install and load essential libraries.",
    "text": "S.2 Install and load essential libraries.\nInstall and load R packages.\n\n# Set CRAN mirror\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\n\n# List of packages to check, install if needed, and load\npackages &lt;- c(\"dplyr\", \"terra\", \"sf\", \"googledrive\", \"ggplot2\", \"corrplot\", \"pROC\", \"dismo\", \"spatstat.geom\", \"patchwork\", \"biomod2\", \"leaflet\", \"car\", \"gridExtra\", \"htmltools\", \"RColorBrewer\")\n\n# Function to display a cat message\ncat_message &lt;- function(pkg, message_type) {\n  if (message_type == \"installed\") {\n    cat(paste0(pkg, \" has been installed successfully!\\n\"))\n  } else if (message_type == \"loading\") {\n    cat(paste0(pkg, \" is already installed and has been loaded!\\n\"))\n  }\n}\n\n# Install missing packages and load them\nfor (pkg in packages) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg)\n    cat_message(pkg, \"installed\")\n  } else {\n    cat_message(pkg, \"loading\")\n  }\n  library(pkg, character.only = TRUE)\n}\n\ndplyr is already installed and has been loaded!\n\n\nterra is already installed and has been loaded!\n\n\nsf is already installed and has been loaded!\n\n\ngoogledrive is already installed and has been loaded!\nggplot2 is already installed and has been loaded!\ncorrplot is already installed and has been loaded!\n\n\npROC is already installed and has been loaded!\n\n\ndismo is already installed and has been loaded!\n\n\nspatstat.geom is already installed and has been loaded!\n\n\npatchwork is already installed and has been loaded!\n\n\nbiomod2 is already installed and has been loaded!\n\n\nleaflet is already installed and has been loaded!\ncar is already installed and has been loaded!\n\n\ngridExtra is already installed and has been loaded!\n\n\nhtmltools is already installed and has been loaded!\nRColorBrewer is already installed and has been loaded!\n\n# If you are using renv, you can snapshot the renv after loading all the packages.\n\n#renv::snapshot()"
  },
  {
    "objectID": "notebooks/EC_GLM/EC_GLM.html#s.3-download-case-study-datasets",
    "href": "notebooks/EC_GLM/EC_GLM.html#s.3-download-case-study-datasets",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "S.3 Download case study datasets",
    "text": "S.3 Download case study datasets\nWe have prepared the following data and uploaded them to our Google Drive for your use:\n\nSpecies occurrence data: Shapefile format (.shp)\nEnvironmental variables: Stacked Raster format (.tif)\nStudy area boundary: Shapefile format (.shp)\n\n\n# # De-authenticate Google Drive to access public files\n# drive_deauth()\n# \n# # Define Google Drive file ID and the path for downloading\n# zip_file_id &lt;- \"1twKlNokB7t33QH2KesH7BHYffp5kvoiP\" # Replace with the actual file ID of the zipped file\n# datafolder_path &lt;- file.path(workspace)\n# \n# # Create a local path for the zipped file\n# zip_file_path &lt;- file.path(datafolder_path, \"mountain_ash_centralhighlands_data.zip\")\n# \n# # Function to download a file with progress messages\n# download_zip_file &lt;- function(file_id, file_path) {\n#   cat(\"Downloading zipped file...\\n\")\n#   drive_download(as_id(file_id), path = file_path, overwrite = TRUE)\n#   cat(\"Downloaded zipped file to:\", file_path, \"\\n\")\n# }\n# \n# # Create local directory if it doesn't exist\n# if (!dir.exists(datafolder_path)) {\n#   dir.create(datafolder_path, recursive = TRUE)\n# }\n# \n# # Download the zipped file\n# cat(\"Starting to download the zipped file...\\n\")\n# download_zip_file(zip_file_id, zip_file_path)\n# \n# # Unzip the downloaded file\n# cat(\"Unzipping the file...\\n\")\n# unzip(zip_file_path, exdir = datafolder_path)\n# cat(\"Unzipped files to folder:\", datafolder_path, \"\\n\")"
  },
  {
    "objectID": "notebooks/EC_GLM/EC_GLM.html#taxon-location-data-and-scale",
    "href": "notebooks/EC_GLM/EC_GLM.html#taxon-location-data-and-scale",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "1.1 Taxon, location, data and scale",
    "text": "1.1 Taxon, location, data and scale\nTaxon: Mountain Ash (Eucalyptus regnans)\n\nPhotographer: Reiner Richter, ALA\nMountain Ash (Eucalyptus regnans), is a remarkably tall and straight tree native to Victoria and Tasmania. This species thrives in cool, temperate rainforests characterized by high rainfall, deep, well-drained soils, mild temperatures, and high humidity. It is typically found at altitudes ranging from 200 to 1,000 meters above sea level (Burns et al., 2015).\nThe Mountain Ash faces two main forms of disturbance: bushfires, which are its primary natural disturbance, and logging, which represents the primary human-induced threat to its habitat (Burns et al., 2015; Nevill et al., 2010).\nLocation: the Central Highlands (study area) in the south part of Victoria\nSpatial and temporal scales: small (spatial) and static (temporal)\n\n# Load your shapefiles\ncentral_highlands &lt;- st_read(\"mountain_ash_centralhighlands/central_highlands.shp\")\n\nReading layer `central_highlands' from data source \n  `/Users/zhaoxiang/Documents/tmp/notebook-blog/notebooks/EC_GLM/mountain_ash_centralhighlands/central_highlands.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 144.9398 ymin: -38.20964 xmax: 146.4563 ymax: -36.97746\nGeodetic CRS:  GDA94\n\n# Custom CSS for a smaller legend box\ncustom_css &lt;- tags$style(HTML(\"\n  .leaflet-control .legend {\n    font-size: 8px !important; /* Reduce font size */\n    padding: 4px; /* Reduce padding inside the legend box */\n    line-height: 1; /* Reduce spacing between lines */\n    width: auto; /* Automatically size the legend box */\n    height: auto; /* Automatically size the legend box */\n  }\n  .leaflet-control .legend i {\n    width: 10px; /* Smaller legend icons */\n    height: 10px;\n  }\n\"))\n\n# Render the map\nleaflet() %&gt;%\n  addProviderTiles(providers$Esri.WorldImagery) %&gt;%\n  # Add the Central Highlands layer with a distinct color\n  addPolygons(\n    data = central_highlands,\n    color = \"lightblue\",         # Border color of Central Highlands polygon\n    weight = 1,                  # Border width\n    fillColor = \"lightblue\",     # Fill color of Central Highlands\n    fillOpacity = 0.3,           # Transparency for fill\n    group = \"Central Highlands\"\n  ) %&gt;%\n  setView(lng = 145.7, lat = -37.5, zoom = 7) %&gt;% # Set the view to desired location\n  addLegend(\n    position = \"bottomright\",\n    colors = c(\"lightblue\"),\n    labels = c(\"Central Highlands\"),\n    opacity = 0.7\n  ) %&gt;%\n  # Add the custom CSS to modify the legend font size\n  htmlwidgets::prependContent(custom_css)"
  },
  {
    "objectID": "notebooks/EC_GLM/EC_GLM.html#model-objective",
    "href": "notebooks/EC_GLM/EC_GLM.html#model-objective",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "1.2 Model objective",
    "text": "1.2 Model objective\nExplanation: To conduct detailed analyses of species–environment relationships and test specific hypotheses about the main factors driving species distributions.\nMapping/interpolating: To use the estimated species-environment relationships to map the distribution of the targeted species in the same geographic area.\nPrediction in new area: To forecast or project the estimated species–environment relationships to a different geographic area. (Exercise, data provided)"
  },
  {
    "objectID": "notebooks/EC_GLM/EC_GLM.html#biodiversity-data",
    "href": "notebooks/EC_GLM/EC_GLM.html#biodiversity-data",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "2.1 Biodiversity data",
    "text": "2.1 Biodiversity data\nUnderstanding your species is essential. This includes knowing their common names (which may include multiple names) and scientific name to ensure you collect the most comprehensive records available in open-access biodiversity data portals, such as the Atlas of Living Australia (ALA) or the Global Biodiversity Information Facility (GBIF).\nFor this exercise, we have prepared a species occurrence data file in CSV format, which was downloaded from ALA. To make it accessible, we have stored this file in the EcoCommons Public Google Drive for you to download and use conveniently.\n\n# Read the shapefile for mountain ash occurrence point dataset\nmountain_ash_centralhighlands &lt;- st_read(\"mountain_ash_centralhighlands/mountain_ash_centralhighlands.shp\")\n\nReading layer `mountain_ash_centralhighlands' from data source \n  `/Users/zhaoxiang/Documents/tmp/notebook-blog/notebooks/EC_GLM/mountain_ash_centralhighlands/mountain_ash_centralhighlands.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3933 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 145.0258 ymin: -38.2 xmax: 146.4333 ymax: -37.22625\nGeodetic CRS:  GDA94\n\n# Filter the data to include only PRESENT points\nmountain_ash_present &lt;- mountain_ash_centralhighlands %&gt;%\n  dplyr::filter(occrrnS == \"1\")\n\nleaflet() %&gt;%\n  addProviderTiles(providers$Esri.WorldImagery) %&gt;%\n  # Add the Central Highlands layer with a distinct color\n  addPolygons(\n    data = central_highlands,\n    color = \"lightblue\",         # Border color of Central Highlands polygon\n    weight = 1,                  # Border width\n    fillColor = \"lightblue\",     # Fill color of Central Highlands\n    fillOpacity = 0.3,           # Transparency for fill\n    group = \"Central Highlands\"\n  ) %&gt;%\n  # Add Mountain Ash presence points\n  addCircleMarkers(\n    data = mountain_ash_present,\n    color = \"#11aa96\",\n    radius = 1,\n    weight = 0.5,\n    opacity = 1,\n    fillOpacity = 1,\n    group = \"Mountain Ash Presence Records\"\n  ) %&gt;%\n  setView(lng = 145.7, lat = -37.5, zoom = 7) %&gt;% # Adjust longitude, latitude, and zoom as needed\n  # Add layer controls for easier toggling\n  addLayersControl(\n    overlayGroups = c(\"Central Highlands\", \"Mountain Ash Presence Records\"),\n    options = layersControlOptions(collapsed = FALSE)\n  ) %&gt;%\n  # Add a compact legend with a clean style\n  addControl(\n    html = \"\n    &lt;div style='background-color: white; padding: 4px; font-size: 8px; border: none; box-shadow: none;'&gt;\n      &lt;div style='display: flex; align-items: center; margin-bottom: 3px;'&gt;\n        &lt;div style='background: lightblue; width: 10px; height: 10px; margin-right: 5px; opacity: 0.7;'&gt;&lt;/div&gt;\n        Central Highlands\n      &lt;/div&gt;\n      &lt;div style='display: flex; align-items: center;'&gt;\n        &lt;div style='background: #11aa96; width: 10px; height: 10px; margin-right: 5px;'&gt;&lt;/div&gt;\n        Mountain Ash Presence Records\n      &lt;/div&gt;\n    &lt;/div&gt;\n    \",\n    position = \"bottomright\"\n  )"
  },
  {
    "objectID": "notebooks/EC_GLM/EC_GLM.html#pseudo-absence-data",
    "href": "notebooks/EC_GLM/EC_GLM.html#pseudo-absence-data",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "2.2 Pseudo Absence Data",
    "text": "2.2 Pseudo Absence Data\nSpecies distribution models typically require both presence and absence data to predict the distribution of a species. However, true absence data—locations where the species is confirmed not to occur—are often unavailable for various reasons. In such cases, pseudo-absence data are used to fill this gap.\nWe generated pseudo-absence data using the EcoCommons platform with the following configuration:\n\nDispersal Kernel\n\nKey point: Mountain Ash seed dispersal is likely within 150 meters, based on von Takach Dukai (2019).\nImplication: This distance should be factored into pseudo-absence generation to avoid selecting pseudo-absence points too close to presence points, which could bias the model by including areas that the species might still occupy but haven’t been sampled.\n\nAbsence-Presence Ratio\n\nKey point: The ratio of absence to presence is set to 1.\nImplication: For each presence point, one pseudo-absence point should be generated. This balanced ratio ensures the model isn’t skewed by an overabundance of either class and aids in robust statistical comparisons.\n\nPseudo-Absence Strategy\n\nKey point: Disk strategy with a range of 1000 - 5000 meters.\nImplication:\n\nThe disk strategy selects pseudo-absences outside a certain buffer zone from presence points.\nThe range of 1000–5000 meters should be carefully reviewed since it must balance avoiding areas within the species’ potential dispersal kernel (150 meters) and including areas beyond the likely range of colonization.\n\n\n\n\n# Filter the data to include only ABSENT points\nmountain_ash_absent &lt;- mountain_ash_centralhighlands %&gt;%\n  dplyr::filter(occrrnS == \"0\")\n\nleaflet() %&gt;%\n  addProviderTiles(providers$Esri.WorldImagery) %&gt;%\n # Add the Central Highlands layer with a distinct color\n  addPolygons(data = central_highlands,\n              color = \"lightblue\",         # Border color of Central Highlands polygon\n              weight = 1,            # Border width\n              fillColor = \"lightblue\",  # Fill color of Central Highlands\n              fillOpacity = 0.3,     # Transparency for fill\n              group = \"Central Highlands\") %&gt;%\n  \n    # Add Mountain Ash presence points\n  addCircleMarkers(data = mountain_ash_present,\n                   color = \"#11aa96\",\n                   radius = 1,\n                   weight = 0.5,\n                   opacity = 1,\n                   fillOpacity = 1,\n                   group = \"Mountain Ash Presence Records\") %&gt;%\n  \n\n      # Add Mountain Ash absent points\n  addCircleMarkers(data = mountain_ash_absent,\n                   color = \"#f6aa70\",\n                   radius = 1,\n                   weight = 0.5,\n                   opacity = 1,\n                   fillOpacity = 1,\n                   group = \"Mountain Ash Pseudo_absent Records\") %&gt;%\n  \n  setView(lng = 145.7, lat = -37.5, zoom = 7)  %&gt;% # Adjust longitude, latitude, and zoom as needed \n  \n    # Add layer controls for easier toggling\n  addLayersControl(\n    overlayGroups = c(\"Central Highlands\", \"Mountain Ash Presence Records\", \"Mountain Ash Pseudo_absent Records\"),\n    options = layersControlOptions(collapsed = FALSE)\n  ) %&gt;%\n  \n  # Add a legend for the layers\n  addControl(\n    html = \"\n    &lt;div style='background-color: white; padding: 10px; border-radius: 5px;'&gt;\n      &lt;strong&gt;Legend&lt;/strong&gt;&lt;br&gt;\n      &lt;i style='background: lightblue; width: 18px; height: 18px; display: inline-block; margin-right: 8px; opacity: 0.7;'&gt;&lt;/i&gt;\n      Central Highlands&lt;br&gt;\n      &lt;i style='background: #11aa96; width: 10px; height: 10px; border-radius: 50%; display: inline-block; margin-right: 8px;'&gt;&lt;/i&gt;\n      Mountain Ash Presence Records&lt;br&gt;\n      &lt;i style='background: #f6aa70; width: 10px; height: 10px; border-radius: 50%; display: inline-block; margin-right: 8px;'&gt;&lt;/i&gt;\n      Mountain Ash Pseudo-absent Records\n    &lt;/div&gt;\n    \",\n    position = \"bottomright\"\n  )"
  },
  {
    "objectID": "notebooks/EC_GLM/EC_GLM.html#environmental-data",
    "href": "notebooks/EC_GLM/EC_GLM.html#environmental-data",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "2.3 Environmental Data",
    "text": "2.3 Environmental Data\nWhen selecting environmental variables for a model, it is important to avoid indiscriminately including any available data. Instead, select variables thoughtfully, guided by ecological knowledge and the specific hypotheses being tested.\nAs previously mentioned, Mountain Ash thrives in cool, temperate rainforests characterized by high rainfall, deep, well-drained soils, mild temperatures, and high humidity. This species is typically found at altitudes ranging from 200 to 1,000 meters above sea level (Burns et al., 2015). Mountain Ash habitats face two primary forms of disturbance: bushfires, which are the main natural disturbance, and logging, which constitutes the primary human-induced threat (Burns et al., 2015; Nevill et al., 2010).\n\n\n\n\n\n\n\n\n\nEnvironmental Variables Categories\nVariables\nData Type\nSource\n\n\n\n\nTemperature and Radiation\nBioclim 01: Annual mean temperature\nBioclim 04: Temperature Seasonality (standard deviation *100)\nBioclim 06: Min Temperature of Coldest Month\nBioclim 10: Mean Temperature of Warmest Quarter\nBioclim 20: Annual mean radiation\nContinuous\n1976-2005, CSIRO via EcoCommons\n\n\nHumidity\nBioclim 12: Annual Precipitation\nBioclim 18: Precipitation of Warmest Quarter\nBioclim 19: Precipitation of Coldest Quarter\nBioclim 28: Annual mean moisture index\nBioclim 34: Mean moisture index of warmest quarter\nBioclim 35: Mean moisture index of coldest quarter\nContinuous\n1976-2005, CSIRO via EcoCommons\n\n\nTopography\nDigital Elevation Model\nContinuous\nGeoscience Australia via EcoCommons\n\n\nSoil\nAustralian Soil Classification\nCategorical\nTern via EcoCommons\n\n\nDisturbance\nFires\nLogging\nContinuous\nVic DEECA spatial data and resources\n\n\n\n\n# Load the stacked raster layers\nenv_var_stack &lt;- rast(\"mountain_ash_centralhighlands/central_highlands_15envvar.tif\")\n\n# Define the custom names for the raster layers\nlayer_names &lt;- c(\n  \"Annual_Mean_Temp\",\n  \"Temp_Seasonality\",\n  \"Min_Temp_Coldest_Month\",\n  \"Mean_Temp_Warmest_Quarter\",\n  \"Annual_Mean_Radiation\",\n  \"Annual_Precipitation\",\n  \"Precip_Warmest_Quarter\",\n  \"Precip_Coldest_Quarter\",\n  \"Annual_Mean_Moisture\",\n  \"Moisture_Warmest_Quarter\",\n  \"Moisture_Coldest_Quarter\",\n  \"Elevation\",\n  \"Soil_Type\",\n  \"Fires\",\n  \"Logging\"\n)\n\n\n# Assign the custom names to the raster layers\nnames(env_var_stack) &lt;- layer_names\n\n# We want to make sure that soil type raster layer is factor.\nenv_var_stack[[\"Soil_Type\"]] &lt;- as.factor(env_var_stack[[\"Soil_Type\"]])\n\n# Check if the names are assigned correctly\nprint(names(env_var_stack))\n\n [1] \"Annual_Mean_Temp\"          \"Temp_Seasonality\"         \n [3] \"Min_Temp_Coldest_Month\"    \"Mean_Temp_Warmest_Quarter\"\n [5] \"Annual_Mean_Radiation\"     \"Annual_Precipitation\"     \n [7] \"Precip_Warmest_Quarter\"    \"Precip_Coldest_Quarter\"   \n [9] \"Annual_Mean_Moisture\"      \"Moisture_Warmest_Quarter\" \n[11] \"Moisture_Coldest_Quarter\"  \"Elevation\"                \n[13] \"Soil_Type\"                 \"Fires\"                    \n[15] \"Logging\"                  \n\n\n\n# Custom titles for the layers\nlayer_titles &lt;- c(\n  \"Bioclim 01: Annual Mean Temperature\",\n  \"Bioclim 04: Temperature Seasonality (standard deviation *100)\",\n  \"Bioclim 06: Min Temperature of Coldest Month\",\n  \"Bioclim 10: Mean Temperature of Warmest Quarter\",\n  \"Bioclim 20: Annual mean radiation\"\n)\n\n# Indices of the layers to plot\nlayers_to_plot &lt;- c(1, 2, 3, 4, 8)\n\n# Set layout for plotting (3 rows, 2 columns for 5 plots)\npar(mfrow = c(3, 2)) \n\n# Plot each specified layer with its custom title and smaller title size\nfor (i in seq_along(layers_to_plot)) {\n  layer_index &lt;- layers_to_plot[i]\n  plot(env_var_stack[[layer_index]], main = layer_titles[i], cex.main = 0.8) # Adjust cex.main for title size\n}\n\n\n\n\n\n\n\n\n\n# Custom titles for the specified layers\nlayer_titles &lt;- c(\n  \"Bioclim 12: Annual Precipitation\",\n  \"Bioclim 18: Precipitation of Warmest Quarter\",\n  \"Bioclim 19: Precipitation of Coldest Quarter\",\n  \"Bioclim 28: Annual Mean Moisture Index\",\n  \"Bioclim 34: Mean Moisture Index of Warmest Quarter\",\n  \"Bioclim 35: Mean Moisture Index of Coldest Quarter\"\n)\n\n# Indices of the layers to plot\nlayers_to_plot &lt;- c(5, 6, 7, 9, 10, 11)\n\n# Set layout for plotting (3 rows, 2 columns for 5 plots)\npar(mfrow = c(3, 2)) \n\n# Plot each specified layer with its custom title and smaller title size\nfor (i in seq_along(layers_to_plot)) {\n  layer_index &lt;- layers_to_plot[i]\n  plot(env_var_stack[[layer_index]], main = layer_titles[i], cex.main = 0.8) # Adjust cex.main for title size\n}\n\n\n\n\n\n\n\n\n\n# Custom titles for the specified layers\nlayer_titles &lt;- c(\n  \"Digital Elevation Model\",\n  \"Australian Soil Classification\",\n  \"Logging\",\n  \"Fires\"\n)\n\n# Indices of the layers to plot\nlayers_to_plot &lt;- c(12:15)\n\n# Set layout for plotting (3 rows, 2 columns for 5 plots)\npar(mfrow = c(2, 2)) \n\n# Plot each specified layer with its custom title and smaller title size\nfor (i in seq_along(layers_to_plot)) {\n  layer_index &lt;- layers_to_plot[i]\n  plot(env_var_stack[[layer_index]], main = layer_titles[i], cex.main = 0.8) # Adjust cex.main for title size\n}\n\n\n\n\n\n\n\n\nSoil Type Classification: 3 - Dermosol, 4 - Chromosol, 5 - Ferrosol, 7 - Tenosol, 8 - Kandosol,12 - Calcarosol, 13 - Organosol, and 14 - Anthroposol."
  },
  {
    "objectID": "notebooks/EC_GLM/EC_GLM.html#combine-species-occurrence-data-and-environmental-variables",
    "href": "notebooks/EC_GLM/EC_GLM.html#combine-species-occurrence-data-and-environmental-variables",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "2.4 Combine species occurrence data and environmental variables",
    "text": "2.4 Combine species occurrence data and environmental variables\nWe will create a data frame that combines each presence/absence record of Mountain Ash with data from our 15 environmental variables.\n\n# Convert species occurrence data to terra-compatible SpatVector\noccurrence_vect &lt;- vect(mountain_ash_centralhighlands)\n\n# Extract raster values at species occurrence points\nextracted_values &lt;- terra::extract(env_var_stack, occurrence_vect)\n\n# Combine occurrence data with extracted raster values\n# (Keep geometry or drop it based on your needs)\noccurrence_data &lt;- cbind(as.data.frame(mountain_ash_centralhighlands), extracted_values)\n\n# Remove rows with any NA values in predictors\noccurrence_data &lt;- na.omit(occurrence_data)\n\n# we want to make sure the data type of soil types is factor.\noccurrence_data$Soil_Type &lt;- as.factor(occurrence_data$Soil_Type)\n\nhead(occurrence_data)\n\n  occrrnS                   geometry ID Annual_Mean_Temp Temp_Seasonality\n1       1 POINT (145.7339 -37.67417)  1        10.369396         1.424792\n2       1  POINT (146.1373 -37.7804)  2         8.822482         1.449565\n3       1 POINT (145.3817 -37.88166)  3        12.967784         1.280466\n4       1 POINT (146.1797 -37.84517)  4        10.826058         1.390526\n5       1 POINT (145.3362 -37.88002)  5        11.825127         1.278574\n6       1 POINT (145.9281 -37.83222)  6        10.293063         1.386414\n  Min_Temp_Coldest_Month Mean_Temp_Warmest_Quarter Annual_Mean_Radiation\n1              2.0631714                  15.60523              1578.439\n2              0.4309082                  14.10276              1577.427\n3              4.2351027                  17.71625              1133.458\n4              1.5544521                  15.95073              1583.145\n5              3.9153066                  16.52677              1266.487\n6              1.6763960                  15.38035              1609.709\n  Annual_Precipitation Precip_Warmest_Quarter Precip_Coldest_Quarter\n1             250.6433               530.1663               13.70784\n2             268.0575               503.1617               13.63218\n3             203.8828               331.7352               14.27531\n4             275.0496               479.6527               13.56016\n5             230.7354               364.2117               13.97706\n6             267.1724               513.3069               13.54408\n  Annual_Mean_Moisture Moisture_Warmest_Quarter Moisture_Coldest_Quarter\n1            0.9548221                0.8892441                1.0000000\n2            0.9821509                0.9541187                1.0000000\n3            0.8531148                0.6036963                0.9996078\n4            0.9700990                0.9209611                1.0000000\n5            0.9097116                0.7599657                1.0000000\n6            0.9698939                0.9229909                1.0000000\n  Elevation Soil_Type Fires Logging\n1  834.7029         4     0       0\n2 1058.5144         4     0       3\n3  314.3798         4     0       0\n4  658.4626         7     0       9\n5  544.9786         4     0       0\n6  902.7314         4     0       7"
  },
  {
    "objectID": "notebooks/EC_GLM/EC_GLM.html#multicollinearity-and-variable-selection",
    "href": "notebooks/EC_GLM/EC_GLM.html#multicollinearity-and-variable-selection",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "3.1 Multicollinearity and Variable Selection",
    "text": "3.1 Multicollinearity and Variable Selection\nTesting for collinearity among continuous variables is an important step in many modeling processes, particularly in species distribution modeling and other regression-based analyses. Codllinearity occurs when two or more predictor variables in a dataset are highly correlated, which can lead to unstable estimates of regression coefficients and make it difficult to interpret the results.\nThere are two common methods for testing collinearity among continuous variables.\nCorrelation matrix.\n\n\nlayer_names &lt;- c(\n  \"Annual_Mean_Temp\",\n  \"Temp_Seasonality\",\n  \"Min_Temp_Coldest_Month\",\n  \"Mean_Temp_Warmest_Quarter\",\n  \"Annual_Mean_Radiation\",\n  \"Annual_Precipitation\",\n  \"Precip_Warmest_Quarter\",\n  \"Precip_Coldest_Quarter\",\n  \"Annual_Mean_Moisture\",\n  \"Moisture_Warmest_Quarter\",\n  \"Moisture_Coldest_Quarter\",\n  \"Elevation\",\n  \"Fires\",\n  \"Logging\"\n)\n\n\n# Select columns by their names\ncor_data &lt;- occurrence_data[, layer_names]\n\n# Check the structure of the numeric data\nstr(cor_data)\n\n'data.frame':   3932 obs. of  14 variables:\n $ Annual_Mean_Temp         : num  10.37 8.82 12.97 10.83 11.83 ...\n $ Temp_Seasonality         : num  1.42 1.45 1.28 1.39 1.28 ...\n $ Min_Temp_Coldest_Month   : num  2.063 0.431 4.235 1.554 3.915 ...\n $ Mean_Temp_Warmest_Quarter: num  15.6 14.1 17.7 16 16.5 ...\n $ Annual_Mean_Radiation    : num  1578 1577 1133 1583 1266 ...\n $ Annual_Precipitation     : num  251 268 204 275 231 ...\n $ Precip_Warmest_Quarter   : num  530 503 332 480 364 ...\n $ Precip_Coldest_Quarter   : num  13.7 13.6 14.3 13.6 14 ...\n $ Annual_Mean_Moisture     : num  0.955 0.982 0.853 0.97 0.91 ...\n $ Moisture_Warmest_Quarter : num  0.889 0.954 0.604 0.921 0.76 ...\n $ Moisture_Coldest_Quarter : num  1 1 1 1 1 ...\n $ Elevation                : num  835 1059 314 658 545 ...\n $ Fires                    : num  0 0 0 0 0 0 5 0 0 0 ...\n $ Logging                  : num  0 3 0 9 0 7 0 4 8 4 ...\n\n# Calculate the correlation matrix for the numeric columns\ncor_matrix &lt;- cor(cor_data, use = \"complete.obs\", method = \"pearson\")\n\n\ncorrplot(cor_matrix,\n         method = \"color\",            # Use colored squares for correlation\n         type = \"upper\",              # Show upper triangle only\n         order = \"hclust\",            # Reorder variables hierarchically\n         addCoef.col = \"black\",       # Show correlation coefficients in black\n         number.cex = 0.5,            # Reduce the size of correlation labels\n         tl.col = \"black\",            # Text label color\n         tl.srt = 30,                 # Rotate labels slightly for readability\n         tl.cex = 0.5,                # Reduce text size of variable labels (set smaller valu)\n         cl.cex = 0.8,                # Reduce text size of color legend\n         diag = FALSE,                # Hide diagonal\n         col = colorRampPalette(c(\"#11aa96\", \"#61c6fa\", \"#f6aa70\"))(200),\n         sig.level = 0.01, insig = \"blank\")\n\n\n\n\n\n\n\n\nIf you find corrplot is hard for you to make decisions, we can use Variance Inflation Factor (VIF). VIF is another statistical measure used to detect multicollinearity in a set of explanatory (independent) variables in a regression model.\nInterpretation:\n\nVIF = 1: No correlation\nVIF &gt; 1 and &lt;= 5: Moderate correlation; may not require corrective action.\nVIF &gt; 5: Indicates high correlation. Multicollinearity may be problematic, and further investigation is recommended.\nVIF &gt; 10: Strong multicollinearity. The variable is highly collinear with others, and steps should be taken to address this.\n\n\n# Fit a GLM for species distribution\nglm_model &lt;- glm(\n  occrrnS ~ Annual_Mean_Temp + Temp_Seasonality + Min_Temp_Coldest_Month +\n    Mean_Temp_Warmest_Quarter + Annual_Mean_Radiation + Annual_Precipitation +\n    Precip_Warmest_Quarter + Precip_Coldest_Quarter + Annual_Mean_Moisture +\n    Moisture_Warmest_Quarter + Moisture_Coldest_Quarter + Elevation + Fires + Logging,\n  data = occurrence_data,\n  family = binomial(link = \"logit\")  # Logistic regression\n)\n\n\n# Calculate VIF for the GLM\nvif_values &lt;- vif(glm_model)\n\n# Convert VIF values to a data frame with two columns\nvif_table &lt;- data.frame(\n  Variable = names(vif_values),  # Column 1: Variable names\n  VIF = round(vif_values, 2)     # Column 2: VIF values rounded to 2 decimals\n)\n\n# Rank the VIF table from high to low\nvif_table &lt;- vif_table[order(vif_table$VIF, decreasing = TRUE), ]\n\n# Print the ranked table\nprint(vif_table)\n\n                                           Variable      VIF\nAnnual_Mean_Temp                   Annual_Mean_Temp 30369.96\nMean_Temp_Warmest_Quarter Mean_Temp_Warmest_Quarter 21826.71\nAnnual_Mean_Radiation         Annual_Mean_Radiation  2863.99\nAnnual_Mean_Moisture           Annual_Mean_Moisture  1625.31\nTemp_Seasonality                   Temp_Seasonality  1527.84\nMoisture_Warmest_Quarter   Moisture_Warmest_Quarter  1241.81\nPrecip_Warmest_Quarter       Precip_Warmest_Quarter  1228.60\nPrecip_Coldest_Quarter       Precip_Coldest_Quarter   562.37\nAnnual_Precipitation           Annual_Precipitation   308.52\nElevation                                 Elevation    42.83\nMin_Temp_Coldest_Month       Min_Temp_Coldest_Month    24.07\nMoisture_Coldest_Quarter   Moisture_Coldest_Quarter     3.80\nLogging                                     Logging     1.27\nFires                                         Fires     1.03\n\n\nRules of thumb for VIF:\nVariables to Drop (Initial Recommendation):\n\nAnnual_Mean_Temp (High VIF + highly correlated with many others).\nMean_Temp_Warmest_Quarter (High VIF + redundant with Min_Temp_Coldest_Month).\nAnnual_Mean_Radiation (High VIF + redundant with Elevation).\nAnnual_Precipitation (Redundant with Annual_Mean_Moisture).\nPrecip_Warmest_Quarter (Redundant with Moisture_Warmest_Quarter).\n\nGetting rid of some highly correlated variables and run VIF again.\n\n# Fit a GLM for testing the VIF\nglm_model &lt;- glm(\n  occrrnS ~ Temp_Seasonality + Min_Temp_Coldest_Month +\n    Precip_Coldest_Quarter + Moisture_Coldest_Quarter + Elevation + Fires + Logging,\n  data = occurrence_data,\n  family = binomial(link = \"logit\")  # Logistic regression\n)\n\n# Calculate VIF for the GLM\nvif_values &lt;- vif(glm_model)\n\n# Convert VIF values to a data frame with two columns\nvif_table &lt;- data.frame(\n  Variable = names(vif_values),  # Column 1: Variable names\n  VIF = round(vif_values, 2)     # Column 2: VIF values rounded to 2 decimals\n)\n\n# Rank the VIF table from high to low\nvif_table &lt;- vif_table[order(vif_table$VIF, decreasing = TRUE), ]\n\n# Print the ranked table\nprint(vif_table)\n\n                                         Variable  VIF\nElevation                               Elevation 7.21\nMin_Temp_Coldest_Month     Min_Temp_Coldest_Month 5.43\nTemp_Seasonality                 Temp_Seasonality 4.33\nPrecip_Coldest_Quarter     Precip_Coldest_Quarter 3.41\nMoisture_Coldest_Quarter Moisture_Coldest_Quarter 1.53\nLogging                                   Logging 1.13\nFires                                       Fires 1.01\n\n\nNow, from our 14 continuous variables, we choose above 7 variables and 1 categorical variable Soil_Types to make our final model."
  },
  {
    "objectID": "notebooks/EC_GLM/EC_GLM.html#data-splitting",
    "href": "notebooks/EC_GLM/EC_GLM.html#data-splitting",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "3.2 Data splitting",
    "text": "3.2 Data splitting\nFor cross-validation purposes, we need to leave out some data as testing dataset. There are many strategies of splitting data for cross-validation, like random, k-fold, and leave-one-out etc. Here we will use the easiest one: random splitting.\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Split the data into training (80%) and testing (20%)\ntrain_index &lt;- sample(1:nrow(occurrence_data), size = 0.8 * nrow(occurrence_data))\n\n# Create training and testing datasets\ntrain_data &lt;- occurrence_data[train_index, ]\ntest_data &lt;- occurrence_data[-train_index, ]\n\n# Check the split\ncat(\"Training Set:\", nrow(train_data), \"rows\\n\")\n\nTraining Set: 3145 rows\n\ncat(\"Testing Set:\", nrow(test_data), \"rows\\n\")\n\nTesting Set: 787 rows"
  },
  {
    "objectID": "notebooks/EC_GLM/EC_GLM.html#model-fitting-1",
    "href": "notebooks/EC_GLM/EC_GLM.html#model-fitting-1",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "3.3 Model fitting",
    "text": "3.3 Model fitting\nNull model: no explanatory variables or predictors are included.\nIt is always helpful to create a null model as a benchmark to assess how the inclusion of explanatory variables improves the model.\n\n# Let's make a null model as a benchmark\n\n# Fit a null model with only the intercept\nnull_model &lt;- glm(occrrnS ~ 1,\n                  data = train_data,\n                  family = binomial(link = \"logit\"))\n\nsummary(null_model)\n\n\nCall:\nglm(formula = occrrnS ~ 1, family = binomial(link = \"logit\"), \n    data = train_data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.51541    0.03685   13.98   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 4157.8  on 3144  degrees of freedom\nResidual deviance: 4157.8  on 3144  degrees of freedom\nAIC: 4159.8\n\nNumber of Fisher Scoring iterations: 4\n\n\nNow, we can fit a full model.\n\n# Fit the GLM on the training data\nglm_model &lt;- glm(\n  occrrnS ~ Temp_Seasonality + Min_Temp_Coldest_Month +\n    Precip_Coldest_Quarter + Moisture_Coldest_Quarter +\n    Elevation + Fires + Soil_Type + Logging,\n  data = train_data,\n  family = binomial(link = \"logit\")  # Logistic regression\n)\n\n# Summarize the model\nsummary(glm_model)\n\n\nCall:\nglm(formula = occrrnS ~ Temp_Seasonality + Min_Temp_Coldest_Month + \n    Precip_Coldest_Quarter + Moisture_Coldest_Quarter + Elevation + \n    Fires + Soil_Type + Logging, family = binomial(link = \"logit\"), \n    data = train_data)\n\nCoefficients:\n                           Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)               1.662e+01  3.074e+01   0.541   0.5887    \nTemp_Seasonality         -3.247e+00  1.315e+00  -2.470   0.0135 *  \nMin_Temp_Coldest_Month    1.551e+00  9.849e-02  15.750  &lt; 2e-16 ***\nPrecip_Coldest_Quarter   -4.519e+00  3.233e-01 -13.978  &lt; 2e-16 ***\nMoisture_Coldest_Quarter  4.487e+01  2.935e+01   1.529   0.1264    \nElevation                 2.484e-03  4.838e-04   5.133 2.85e-07 ***\nFires                     1.018e-02  9.933e-02   0.103   0.9184    \nSoil_Type4                1.949e+00  3.955e-01   4.928 8.31e-07 ***\nSoil_Type5               -1.770e-01  4.959e-01  -0.357   0.7211    \nSoil_Type7                1.621e+00  4.052e-01   4.002 6.29e-05 ***\nSoil_Type8               -1.347e+01  6.038e+02  -0.022   0.9822    \nSoil_Type12              -1.336e+01  4.723e+02  -0.028   0.9774    \nSoil_Type13              -1.554e+01  1.309e+03  -0.012   0.9905    \nSoil_Type14              -1.286e+01  6.500e+02  -0.020   0.9842    \nLogging                   1.378e-01  1.514e-02   9.102  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 4157.8  on 3144  degrees of freedom\nResidual deviance: 2414.8  on 3130  degrees of freedom\nAIC: 2444.8\n\nNumber of Fisher Scoring iterations: 15"
  },
  {
    "objectID": "notebooks/EC_GLM/EC_GLM.html#summary-of-interpretation",
    "href": "notebooks/EC_GLM/EC_GLM.html#summary-of-interpretation",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "4.1 Summary of Interpretation",
    "text": "4.1 Summary of Interpretation\n\n# Let's compare the performance of our model to a null model\n\n# Compare null model with full model using the analysis of deviance (Likelihood Ratio Test)\nanova(null_model, glm_model, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: occrrnS ~ 1\nModel 2: occrrnS ~ Temp_Seasonality + Min_Temp_Coldest_Month + Precip_Coldest_Quarter + \n    Moisture_Coldest_Quarter + Elevation + Fires + Soil_Type + \n    Logging\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1      3144     4157.8                          \n2      3130     2414.8 14     1743 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Compare the AIC of the null model and the full model\nAIC(null_model, glm_model)\n\n           df      AIC\nnull_model  1 4159.769\nglm_model  15 2444.787\n\n# Get the null deviance and residual deviance from the full model\nnull_deviance &lt;- glm_model$null.deviance\nresidual_deviance &lt;- glm_model$deviance\n\n# Calculate the deviance explained\ndeviance_explained &lt;- (null_deviance - residual_deviance) / null_deviance\n\n# Print the deviance explained as a percentage\ndeviance_explained_percent &lt;- deviance_explained * 100\ncat(\"Deviance Explained:\", deviance_explained_percent, \"%\\n\")\n\nDeviance Explained: 41.92108 %\n\n\nThe Likelihood Ratio Test (ANOVA) shows that adding the predictors significantly improved the model’s fit compared to the null model, as indicated by the high deviance reduction and a p-value of 0.\nThe AIC for the full model is much lower than the null model, further indicating a better fit when balancing model complexity.\nThe Deviance Explained of 42 % suggests that the full model explains almost half of the variability in mountain ash presence/absence, indicating that while the predictors contribute useful information, there is still substantial unexplained variability that may require further investigation or additional predictors.\nVariable Importance metric.\nIt is a measure used to assess the relative importance of predictors (environmental variables) in the model.\n\n# Function to plot effect size graph\nplot_effect_size &lt;- function(glm_model) {\n  # Check if required libraries are installed\n  if (!requireNamespace(\"ggplot2\", quietly = TRUE)) {\n    stop(\"Please install the 'ggplot2' package to use this function.\")\n  }\n  library(ggplot2)\n\n  # Extract effect sizes (coefficients) from the model\n  coefs &lt;- summary(glm_model)$coefficients\n  effect_sizes &lt;- data.frame(\n    Variable = rownames(coefs)[-1],  # Exclude the intercept\n    Effect_Size = coefs[-1, \"Estimate\"],\n    Std_Error = coefs[-1, \"Std. Error\"]\n  )\n\n  # Sort by effect size\n  effect_sizes &lt;- effect_sizes[order(-abs(effect_sizes$Effect_Size)), ]\n\n  # Plot the effect sizes with error bars\n  ggplot(effect_sizes, aes(x = reorder(Variable, Effect_Size), y = Effect_Size)) +\n    geom_bar(stat = \"identity\", fill = \"#11aa96\") +\n    geom_errorbar(aes(ymin = Effect_Size - Std_Error, ymax = Effect_Size + Std_Error), width = 0.2) +\n    coord_flip() +\n    labs(\n      title = \"Effect Sizes of Variables\",\n      x = \"Variable\",\n      y = \"Effect Size (Coefficient Estimate)\"\n    ) +\n    theme_minimal()\n}\n\n# Example usage of effect size plot\nplot_effect_size(glm_model)"
  },
  {
    "objectID": "notebooks/EC_GLM/EC_GLM.html#cross-validation",
    "href": "notebooks/EC_GLM/EC_GLM.html#cross-validation",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "4.2 Cross validation",
    "text": "4.2 Cross validation\nNow, we use the testing data to evaluate the model performance.\n\n# Predict on the testing data\npredicted_probs &lt;- predict(glm_model, newdata = test_data, type = \"response\")\n\n# Create an ROC curve and compute AUC\nroc_curve &lt;- roc(test_data$occrrnS, predicted_probs)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nauc_value &lt;- auc(roc_curve)\n\n# Extract ROC data for ggplot\nroc_data &lt;- data.frame(\n  Sensitivity = roc_curve$sensitivities,\n  Specificity = 1 - roc_curve$specificities\n)\n\n# Plot the ROC curve using ggplot2\nggplot(roc_data, aes(x = Specificity, y = Sensitivity)) +\n  geom_line(color = \"#61cafa\", linewidth = 0.5) +                  # ROC curve\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray\") + # Diagonal line\n  labs(\n    title = paste(\"ROC Curve (AUC =\", round(auc_value, 2), \")\"),\n    x = \"1 - Specificity\",\n    y = \"Sensitivity\"\n  ) +\n  theme_minimal() +                                           # Minimal theme\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"), # Centered and bold title\n    axis.title = element_text(size = 12),                   # Axis label font size\n    axis.text = element_text(size = 10)                     # Axis tick font size\n  )\n\n\n\n\n\n\n\n\n\nplot_species_response &lt;- function(glm_model, predictors, data) {\n  # Check if required libraries are installed\n  if (!requireNamespace(\"ggplot2\", quietly = TRUE) || !requireNamespace(\"gridExtra\", quietly = TRUE)) {\n    stop(\"Please install the 'ggplot2' and 'gridExtra' packages to use this function.\")\n  }\n  library(ggplot2)\n  library(gridExtra)\n\n  # Create empty list to store response plots\n  response_plots &lt;- list()\n\n  # Loop through each predictor variable\n  for (predictor in predictors) {\n    # Create new data frame to vary predictor while keeping others constant\n    pred_range &lt;- seq(\n      min(data[[predictor]], na.rm = TRUE),\n      max(data[[predictor]], na.rm = TRUE),\n      length.out = 100\n    )\n    const_data &lt;- data[1, , drop = FALSE]  # Use first row to keep other predictors constant\n    response_data &lt;- const_data[rep(1, 100), ]  # Duplicate the row\n    response_data[[predictor]] &lt;- pred_range\n\n    # Predict probabilities\n    predicted_response &lt;- predict(glm_model, newdata = response_data, type = \"response\")\n\n    # Create data frame for plotting\n    plot_data &lt;- data.frame(\n      Predictor_Value = pred_range,\n      Predicted_Probability = predicted_response\n    )\n\n    # Add presence and absence data\n    presence_absence_data &lt;- data.frame(\n      Predictor_Value = data[[predictor]],\n      Presence_Absence = data$occrrnS\n    )\n\n    # Generate the response plot\n    p &lt;- ggplot() +\n      geom_line(data = plot_data, aes(x = Predictor_Value, y = Predicted_Probability), color = \"#61c6fa\", linewidth = 1) +\n      geom_point(data = presence_absence_data[presence_absence_data$Presence_Absence == 1, ], aes(x = Predictor_Value, y = Presence_Absence), color = \"#11aa96\", alpha = 0.6) +\n      geom_point(data = presence_absence_data[presence_absence_data$Presence_Absence == 0, ], aes(x = Predictor_Value, y = Presence_Absence), color = \"#f6aa70\", alpha = 0.6) +\n      labs(x = predictor, y = NULL) +\n      theme_minimal() +\n      theme(axis.title.y = element_blank())\n\n    # Store the plot in the list\n    response_plots[[predictor]] &lt;- p\n  }\n\n  # Arrange all plots in one combined plot with a single shared y-axis label\n  grid.arrange(\n    grobs = response_plots, \n    ncol = 3,\n    left = \"Predicted Probability / Presence-Absence\"\n  )\n}\n\n# Example usage:\npredictors &lt;- c(\"Temp_Seasonality\", \"Min_Temp_Coldest_Month\", \"Precip_Coldest_Quarter\", \"Moisture_Coldest_Quarter\", \"Elevation\", \"Fires\", \"Logging\")\nplot_species_response(glm_model, predictors, train_data)\n\n\n\n\n\n\n\n\n\n# Density and Histogram Plot Function\nplot_density_histogram &lt;- function(predicted_probs, actual_labels) {\n  # Combine data into a data frame\n  plot_data &lt;- data.frame(\n    Predicted_Probability = predicted_probs,\n    Presence_Absence = factor(actual_labels, levels = c(0, 1), labels = c(\"Absence\", \"Presence\"))\n  )\n  \n  # Plot density and histogram\n  ggplot(plot_data, aes(x = Predicted_Probability, fill = Presence_Absence)) +\n    geom_histogram(aes(y = after_stat(density)), bins = 10, alpha = 0.6, position = \"identity\") +  # Histogram with density\n    geom_density(alpha = 0.4) +  # Density curve\n    labs(\n      title = \"Density and Histogram of Predicted Probabilities\",\n      x = \"Predicted Probability\",\n      y = \"Density\",\n      fill = \"Presence/Absence\"\n    ) +\n    scale_fill_manual(values = c(\"#f6aa70\", \"#11aa96\")) +  # Custom colors\n    theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n      axis.title = element_text(size = 12),\n      axis.text = element_text(size = 10),\n      legend.position = \"top\"\n    )\n}\n\n# Example usage:\n# Replace `predicted_probs` with your predicted probabilities and `test_data$occrrnS` with your actual labels\nplot_density_histogram(predicted_probs, test_data$occrrnS)"
  },
  {
    "objectID": "notebooks/dataprep.html",
    "href": "notebooks/dataprep.html",
    "title": "Data Preparation Overview",
    "section": "",
    "text": "Welcome to the Data Preparation section! Here, you can find various guides and resources to help you with the preparation of data for Species Distribution Models (SDM).\n\n\nBelow is a list of specific topics related to data preparation. Click on each link to access more detailed guides.\n\n\nEnvironmental Data Preparation\nThis guide will help you prepare environmental variables such as bioclimatic data, land use, and others required for SDM.\n\n\n\nOccurrence Data Preparation\nLearn how to download, clean, and format occurrence data for your species of interest.\n\n\n\nRaster Processing\nStep-by-step instructions on how to handle raster data, including reprojecting, cropping, and masking.\n\n\n\nData Cleaning Techniques\nA guide on the best practices for cleaning both environmental and occurrence datasets.\n\nIf you have questions or suggestions, please contact the EcoCommons team."
  },
  {
    "objectID": "notebooks/dataprep.html#available-guides",
    "href": "notebooks/dataprep.html#available-guides",
    "title": "Data Preparation Overview",
    "section": "",
    "text": "Below is a list of specific topics related to data preparation. Click on each link to access more detailed guides.\n\n\nEnvironmental Data Preparation\nThis guide will help you prepare environmental variables such as bioclimatic data, land use, and others required for SDM.\n\n\n\nOccurrence Data Preparation\nLearn how to download, clean, and format occurrence data for your species of interest.\n\n\n\nRaster Processing\nStep-by-step instructions on how to handle raster data, including reprojecting, cropping, and masking.\n\n\n\nData Cleaning Techniques\nA guide on the best practices for cleaning both environmental and occurrence datasets.\n\nIf you have questions or suggestions, please contact the EcoCommons team."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "seabass he/him\nPrincipal Data Scientist\nSebastian is a data scientist specialising in AI, computer vision, data analytics, and developing data-intensive interactive applications for AgTech, the environment, and climate. He manages QCIF’s Sustainable Futures portfolio, a team in charge of the delivery of ARDC-supported platforms such as EcoCommons and Wildlife Observatories. From 2018 to 2024, Sebastian managed FishID, Australia’s platform for automated analysis of aquatic imagery. In his free time, you can find Seb cycling, reviewing restaurants, and fishing.\n\n\n\nCaptain Marval  (she/her)\nSenior Data Scientist\nJenna is a Conservation Scientist specialising in ecological modelling, species distribution modelling and using biodiversity data to inform policy. As an Adjunct Research Fellow at the Australian Rivers Institute, she uses spatial analyses and conservation planning to drive environmental strategies. Her work bridges science and technology, advancing biodiversity conservation and ecological research. In her free time, you can find Jenna growing food and flowers in the garden, hiking or getting crafty.\n\n\n\nIron Man (he/him)\nData Ecologist\n\nAbhimanyu is a Zoologist who metamorphosed into an Environmental Scientist focused on terrestrial ecology and species behaviour/interactions. His MS majors are in environmental protection as well as climate change adaptation. He was an Environmental Field Officer in Sydney Basin, working with local councils and national parks on threatened and invasive species management. As a Functional Analyst, he facilitates platform testing strategies, provides user support, and assists with ecological and climate change modelling-based use cases/learning material/workshops for the EcoCommons platform.\n\n\n\nBrisbane Bluey (he/him)\nSoftware Developer & R Specialist\nXiang Zhao (Zhao) joined QCIF in 2024 as a Software Developer and R Specialist, focusing on maintaining and developing ecological algorithms for the EcoCommons Platform. During his MPhil at QUT, he utilized spatial mapping, modeling, statistics, and optimization algorithms to study historical biodiversity survey patterns in terrestrial Antarctica, proposing an optimal survey design for future research. At QUT, he also tutors in GIS and Environmental Planning units, leveraging his expertise in GIS and cartography.\nZhao spent two years traveling across Australia as a backpacker. Prior to this, he worked on a conservation project in Southwest China aimed at protecting giant panda habitats from the threat of free-ranging livestock. This project earned him the BirdLife International Young Conservation Leaders Award.\n\n\n\nRyeBread (he/him)\nSoftware Developer and R Specialist\nRyan joined QCIF in 2024 as a Software Developer and R Specialist, with a focus on developing an ‘Integrated Ecological Data Service’ for State of Environment reporting in Queensland and working on the EcoCommons platform. His research background encompasses various aspects of the environmental sciences including landscape ecology, ecological network analysis, chemical ecology and pollination biology and ecology. His PhD studies focused on critical but unexplored aspects of stingless bee foraging ecology and colony propagation. When not entrenched in scientific exploration, you can find Ryan in the mountains somewhere searching for secret waterfalls and adding to his birding list."
  },
  {
    "objectID": "about.html#our-team",
    "href": "about.html#our-team",
    "title": "about",
    "section": "",
    "text": "seabass he/him\nPrincipal Data Scientist\nSebastian is a data scientist specialising in AI, computer vision, data analytics, and developing data-intensive interactive applications for AgTech, the environment, and climate. He manages QCIF’s Sustainable Futures portfolio, a team in charge of the delivery of ARDC-supported platforms such as EcoCommons and Wildlife Observatories. From 2018 to 2024, Sebastian managed FishID, Australia’s platform for automated analysis of aquatic imagery. In his free time, you can find Seb cycling, reviewing restaurants, and fishing.\n\n\n\nCaptain Marval  (she/her)\nSenior Data Scientist\nJenna is a Conservation Scientist specialising in ecological modelling, species distribution modelling and using biodiversity data to inform policy. As an Adjunct Research Fellow at the Australian Rivers Institute, she uses spatial analyses and conservation planning to drive environmental strategies. Her work bridges science and technology, advancing biodiversity conservation and ecological research. In her free time, you can find Jenna growing food and flowers in the garden, hiking or getting crafty.\n\n\n\nIron Man (he/him)\nData Ecologist\n\nAbhimanyu is a Zoologist who metamorphosed into an Environmental Scientist focused on terrestrial ecology and species behaviour/interactions. His MS majors are in environmental protection as well as climate change adaptation. He was an Environmental Field Officer in Sydney Basin, working with local councils and national parks on threatened and invasive species management. As a Functional Analyst, he facilitates platform testing strategies, provides user support, and assists with ecological and climate change modelling-based use cases/learning material/workshops for the EcoCommons platform.\n\n\n\nBrisbane Bluey (he/him)\nSoftware Developer & R Specialist\nXiang Zhao (Zhao) joined QCIF in 2024 as a Software Developer and R Specialist, focusing on maintaining and developing ecological algorithms for the EcoCommons Platform. During his MPhil at QUT, he utilized spatial mapping, modeling, statistics, and optimization algorithms to study historical biodiversity survey patterns in terrestrial Antarctica, proposing an optimal survey design for future research. At QUT, he also tutors in GIS and Environmental Planning units, leveraging his expertise in GIS and cartography.\nZhao spent two years traveling across Australia as a backpacker. Prior to this, he worked on a conservation project in Southwest China aimed at protecting giant panda habitats from the threat of free-ranging livestock. This project earned him the BirdLife International Young Conservation Leaders Award.\n\n\n\nRyeBread (he/him)\nSoftware Developer and R Specialist\nRyan joined QCIF in 2024 as a Software Developer and R Specialist, with a focus on developing an ‘Integrated Ecological Data Service’ for State of Environment reporting in Queensland and working on the EcoCommons platform. His research background encompasses various aspects of the environmental sciences including landscape ecology, ecological network analysis, chemical ecology and pollination biology and ecology. His PhD studies focused on critical but unexplored aspects of stingless bee foraging ecology and colony propagation. When not entrenched in scientific exploration, you can find Ryan in the mountains somewhere searching for secret waterfalls and adding to his birding list."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "index",
    "section": "",
    "text": "EcoCommons Notebooks\nEcoCommons Notebooks represent an exciting expansion of the platform’s capabilities, offering a new layer of flexibility for advanced users. By incorporating notebooks, EcoCommons enhances its ability to serve the environmental data science community, enabling users to engage with cutting-edge methods, customize workflows, and increase reproducibility in their research. These notebooks, hosted on trusted cloud providers, provide a transparent, open-access approach to environmental data analysis while adhering to the FAIR principles. With planned monthly releases, EcoCommons Notebooks will empower users to explore complex topics such as species migration, community modeling, and data cleaning for biodiversity research."
  },
  {
    "objectID": "notebooks/sp/ecocommons-marxan-integration-poc.html",
    "href": "notebooks/sp/ecocommons-marxan-integration-poc.html",
    "title": "EcoCommons -> Marxan MaPP connection",
    "section": "",
    "text": "Author: Zhao Xiang, EcoCommons\nDate: 2024-10-02\n\n\n\n\n\n\n\nUsing the Species distribution modeling techniques provided by the EcoCommons Platform (www.ecocommons.org.au), we produced probability distribution maps for the three Queensland endangered species: koala, brush tailed rock-wallaby, and beach stone curlew.\nThen we adjusted the probability distribution maps of these three species with the planning units shapefile prepared by the Marxan MaPP, and ran four planning scenarios with a target of expanding the coverage of protected areas in QLD to 30%.\n\n\n\n\nSpecies records pulled from GBIF, ALA, EcoPlots, OBIS\nSpecies distribution modelling output: Species distribution Probability maps (This is the input tested in this project).\n\n\n\n\n\nShapefile of planning area and units.\nShapefile of cost.\nShapefile and csv of biodiversity features (Where EcoCommons can help!).\n\n\n\n\nMake sure you are in the directory you want\n\ngetwd()\n\n[1] \"/Users/zhaoxiang/Documents/tmp/notebook-blog/notebooks/sp\"\n\n# setwd(“/replace_this_with_your_actual_directory/ecocommons-marxan-integration-poc”)\n\nActivate the virtual environment “renv” to install and load all essential packages\n\n# install \"renv\" package if not been installed\nif (!requireNamespace(\"renv\", quietly = TRUE)) {\n  install.packages(\"renv\")\n}\n\nif (!file.exists(\"renv/activate.R\")) {\n   message(\"renv has not been initiated in this project. Initializing now...\")\n   renv::init()  # This initializes renv if it's not set up\n} else {\n   source(\"renv/activate.R\")  # This ensures the renv environment is activated\n   message(\"renv is activated.\")\n}\n\n# Ensure renv is installed and initialized\nif (file.exists(\"renv.lock\")) {\n  renv::restore()\n} else {\n  message(\"No renv.lock file found in the current directory.\")\n}\n\nInstall and load essential packages\n\n# Set CRAN mirror\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\n\n# First specify the packages of interest\npackages = c(\"shiny\", \"sf\", \"terra\", \"ggplot2\", \"ggspatial\", \"raster\", \"dplyr\", \"shiny\", \"httpuv\", \"rmarkdown\", \"knitr\", \"jsonlite\", \"reticulate\", \"htmltools\", \"pryr\")\n\n# Now load or install&load all. This process will take a long time since we are using a virtual environment and install a lot of packages.\npackage.check &lt;- lapply(\n  packages,\n  FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n      install.packages(x, dependencies = TRUE)\n      library(x, character.only = TRUE)\n     }\n  }\n )\n\n\nSys.setenv(PROJ_LIB = \"/usr/local/Cellar/proj/9.5.0/share/proj\")\n\nrenv::snapshot()\n\n1. We get the QLD planning units from Marxan MaPP\n\nQLD_Unit &lt;- \"qld_3species_Marxan/QLD_plannningunits/cost-surface-template.shp\"  #This cost-surface-template was prepared by the Marxan Mapp with a resolution of 189 Km2, which is the highest resolution Marxan Mapp can give at this scale.\n\nQLD_Unit  &lt;- st_read(QLD_Unit)\nQLD_Unit  &lt;- st_simplify(QLD_Unit , dTolerance = 0.01) \n\n\n# Calculate the resolution since Marxan MaPP for visulization purpose\nareas &lt;- st_area(QLD_Unit)\nareas_numeric &lt;- as.numeric(areas)\naverage_area &lt;- mean(areas_numeric)\n\n# Convert to numeric\naverage_area_km2 &lt;- average_area / 1e6\n\n# Get the number of rows\nn_rows &lt;- nrow(QLD_Unit)\n\n# Plot the shapefile with no fill color and number of rows in the title\nggplot(data = QLD_Unit) +\n  geom_sf(fill = NA, color = \"gray\") +\n  theme_minimal() +\n  ggtitle(paste(\"QLD Planning Units:\", n_rows, \"\\n\",\n                \"Resolution of planning in square kilometers:\", round(average_area_km2)))+\n  theme(plot.title = element_text(hjust = 0.5))  # Center the title\n\n\n\n\n\n\n\n\n2. I made a cost layer using the reciprocal of the distance to state-owned road as a surrogate of the cost.\nThe assumption is: the closer to the state owned road, the more expensive to purchase the unit.\n\nQLD_cost_road &lt;- st_read(\"qld_3species_Marxan/QLD_Cost/QLD_cost_road.shp\")\n\n# Plot the shapefile with continuous cost_road values\nggplot(QLD_cost_road) +\n  geom_sf(aes(fill = cost_road)) +\n  scale_fill_continuous(name = \"Cost\",\n                        low = \"lightblue\", high = \"red\",\n                        labels = c(\"0 (Low cost)\", \"1 (High cost)\"),\n                        breaks = c(0.01, 1)) +\n  theme_minimal() +\n  labs(title = \"Cost: using the distance to road of each Unit as a proxy\")+\n  theme(plot.title = element_text(hjust = 0.5))  # Center the title\n\n\n\n\n\n\n\n\n3. Biodiversity features. I used EcoCommons to produce three species’ SDM to start with.\n\nSpecies 1: koala\nSpecies 2: brush tailed rock-wallaby\nSpecies 3: beach stone curlew\n\n\n# Define the folder path where the rasters are stored\nfolder_path &lt;- \"qld_3species_Marxan/QLD_feature/\"\n\n# Get a list of all .tif files in the folder\nraster_files &lt;- list.files(path = folder_path, pattern = \"\\\\.tif$\", full.names = TRUE)\n\n# Extract the species names from the file names (removing the folder path and .tif extension)\nspecies_names &lt;- tools::file_path_sans_ext(basename(raster_files))\n\n# Read all raster files in one go using lapply\nraster_list &lt;- lapply(raster_files, rast)  # Use rast() from terra for reading rasters\n\n# Using QLD_Unit as the spatial vector for masking\n\n# Transform the raster CRS to match the vector CRS and apply masking in one step\nraster_list &lt;- lapply(raster_list, function(r) {\n  r_transformed &lt;- project(r, crs(vect(QLD_Unit)))\n  mask(r_transformed, vect(QLD_Unit))\n})\n\n# Function to convert rasters to data frames and combine them\nprepare_raster_data &lt;- function(raster_list, species_names) {\n\n  # Initialize an empty data frame\n  combined_df &lt;- data.frame()\n  # Loop through each raster and combine them into one data frame\n  for (i in seq_along(raster_list)) {\n    # Convert raster to a data frame\n    raster_df &lt;- as.data.frame(raster_list[[i]], xy = TRUE)\n    # Rename the third column to 'value' or any appropriate name for the raster values\n    names(raster_df)[3] &lt;- \"value\"\n    # Add a column to identify the species name\n    raster_df$species &lt;- species_names[i]\n    # Combine the raster data with the overall data frame\n    combined_df &lt;- bind_rows(combined_df, raster_df)\n}\n  return(combined_df)\n}\n\n# Prepare the combined data frame\ncombined_raster_df &lt;- prepare_raster_data(raster_list, species_names)\n\n# Create the ggplot with facet_wrap to display each raster in a separate facet\nggplot(combined_raster_df, aes(x = x, y = y, fill = value)) +  # Use the correct column name for fill\n  geom_raster()+\n  facet_wrap(~ species, ncol = 3) +  # Adjust ncol to control the number of columns\n  scale_fill_viridis_c() +  # You can adjust the color scale as needed\n  labs(title = \"Species SDM\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n4. We need to turn these SDMs to binary results (shapefies).\n\n# Define the folder paths where the rasters and CSV files are stored\nfolder_path_rasters &lt;- \"qld_3species_Marxan/QLD_feature/\"\nfolder_path_csvs &lt;- \"qld_3species_Marxan/model_evaluation/\"\noutput_dir &lt;- \"qld_3species_Marxan/QLD_feature/Marxan_feature_input/\"\n\nQLD_Unit &lt;- \"qld_3species_Marxan/QLD_plannningunits/cost-surface-template.shp\"  #This cost-surface-template was prepared by the Marxan Mapp with a resolution of 189 Km2, which is the highest resolution Marxan Mapp can give at this scale.\n\nQLD_Unit  &lt;- st_read(QLD_Unit)\nQLD_Unit  &lt;- st_simplify(QLD_Unit , dTolerance = 0.01) \n\n\n# Get a list of all .tif files and CSV files in the folder\nraster_files &lt;- list.files(path = folder_path_rasters, pattern = \"\\\\.tif$\", full.names = TRUE)\ncsv_files &lt;- list.files(path = folder_path_csvs, pattern = \"\\\\.csv$\", full.names = TRUE)\n\n# Extract the species names from the file names (removing the folder path and .tif/.csv extension)\nspecies_names &lt;- tools::file_path_sans_ext(basename(raster_files))\n\n# Read all raster files in one go using lapply\nraster_list &lt;- lapply(raster_files, rast)  # Use rast() from terra for reading rasters\n\n# Transform the raster CRS to match the vector CRS and apply masking in one step\nraster_list &lt;- lapply(raster_list, function(r) {\n  r_transformed &lt;- project(r, crs(vect(QLD_Unit)))\n  mask(r_transformed, vect(QLD_Unit))\n})\n\n# Prepare a named list of rasters\nspecies_rasters &lt;- setNames(raster_list, species_names)\nspecies_csvs &lt;- setNames(csv_files, species_names)\n\n# Define UI for the application\nui &lt;- fluidPage(\n  titlePanel(\"Interactive TSS-based threshold for the probability of presence and absence of Species\"),\n  \n  # Use a loop to create a row for each species\n  lapply(species_names, function(species) {\n    fluidRow(\n      column(3, \n             h4(paste(\"Species:\", species)),\n             sliderInput(paste0(\"tss_value_\", species), \n                         \"Select TSS Value:\", \n                         min = 0, max = 1, value = 0.5, step = 0.01),\n             actionButton(paste0(\"run_analysis_\", species), \"Run Species Analysis\"),\n             br(),\n             textOutput(paste0(\"tpr_tnr_\", species))\n      ),\n      \n      column(4, \n             plotOutput(paste0(\"plot_\", species), width = \"400px\")\n      ),\n      \n      column(5, \n             plotOutput(paste0(\"species_plot_\", species))\n      )\n    )\n  })\n)\n\n# Define server logic\nserver &lt;- function(input, output, session) {\n  \n  selected_raster &lt;- function(species) {\n    species_rasters[[species]]\n  }\n  \n  species_eval_data &lt;- function(species) {\n    csv_path &lt;- species_csvs[[species]]\n    \n    if (!file.exists(csv_path)) {\n      showNotification(paste(\"CSV file for\", species, \"not found!\"), type = \"error\")\n      return(NULL)\n    }\n    \n    eval_data &lt;- read.csv(csv_path)\n    \n    if (!all(c(\"tpr\", \"tnr\", \"tpv\") %in% names(eval_data))) {\n      showNotification(paste(\"Required columns missing in CSV for\", species), type = \"error\")\n      return(NULL)\n    }\n    \n    if (nrow(eval_data) == 0) {\n      showNotification(paste(\"No data found in CSV for\", species), type = \"error\")\n      return(NULL)\n    }\n    \n    eval_data$tss &lt;- round(eval_data$tpr + eval_data$tnr - 1, 3)\n    return(eval_data)\n  }\n  \n  lapply(species_names, function(species) {\n    eval_data &lt;- species_eval_data(species)\n    \n    if (!is.null(eval_data)) {\n      min_tss &lt;- min(eval_data$tss, na.rm = TRUE)\n      max_tss &lt;- max(eval_data$tss, na.rm = TRUE)\n      \n      updateSliderInput(session, paste0(\"tss_value_\", species), \n                        min = min_tss, \n                        max = max_tss, \n                        value = max_tss,\n                        step = 0.01)\n    }\n    \n    observeEvent(input[[paste0(\"tss_value_\", species)]], {\n      if (!is.null(eval_data)) {\n        row &lt;- which.min(abs(eval_data$tss - input[[paste0(\"tss_value_\", species)]]))\n        \n        tpr &lt;- eval_data$tpr[row]\n        tnr &lt;- eval_data$tnr[row]\n        \n        output[[paste0(\"tpr_tnr_\", species)]] &lt;- renderText({\n          paste0(\"TPR (Sensitivity): \", round(tpr, 3), \n                 \", TNR (Specificity): \", round(tnr, 3))\n        })\n      }\n    })\n    \n    output[[paste0(\"plot_\", species)]] &lt;- renderPlot({\n      if (is.null(eval_data)) return(NULL)\n      \n      ggplot(eval_data, aes(x = tpv)) +\n        geom_line(aes(y = tpr, colour = \"TPR\"), linewidth = 1) +\n        geom_line(aes(y = tnr, colour = \"TNR\"), linewidth = 1) +\n        geom_line(aes(y = tss, colour = \"TSS\"), linewidth = 1) +\n        geom_vline(xintercept = eval_data$tpv[which.min(abs(eval_data$tss - input[[paste0(\"tss_value_\", species)]]))],\n                   linetype = \"dotted\", color = \"red\", linewidth = 1) +\n        labs(title = paste(\"Sensitivity, Specificity, and TSS for\", species),\n             x = \"Threshold Probability Value\",\n             y = \"Value\") +\n        scale_colour_manual(values = c(\"TPR\" = \"blue\", \"TNR\" = \"green\", \"TSS\" = \"red\")) +\n        theme_minimal()\n    })\n    \n    observeEvent(input[[paste0(\"run_analysis_\", species)]], {\n      species_shp &lt;- process_species(selected_raster(species), QLD_Unit, species, output_dir, input[[paste0(\"tss_value_\", species)]])\n      \n      output[[paste0(\"species_plot_\", species)]] &lt;- renderPlot({\n        ggplot() +\n          geom_sf(data = QLD_Unit, fill = NA, color = \"grey\") +\n          geom_sf(data = species_shp, aes(fill = feature), color = NA) +\n          scale_fill_viridis_c(option = \"plasma\") +\n          labs(title = paste(\"Species Distribution for\", species),\n               x = \"Longitude\", y = \"Latitude\") +\n          theme_minimal()\n      })\n    })\n  })\n}\n\nprocess_species &lt;- function(raster_data, planning_unit, species_name, output_dir, tss_threshold) {\n  raster_data_transformed &lt;- project(raster_data, crs(vect(planning_unit)))\n  extracted_values &lt;- extract(raster_data_transformed, vect(planning_unit), fun = mean, na.rm = TRUE)\n  names(planning_unit)[names(planning_unit) == \"cost\"] &lt;- \"feature\"\n  planning_unit$feature &lt;- extracted_values[, 2]\n  \n  QLD_species &lt;- subset(planning_unit, feature &gt;= tss_threshold)\n  shapefile_base &lt;- file.path(output_dir, species_name)\n  st_write(QLD_species, paste0(shapefile_base, \".shp\"), delete_layer = TRUE)\n  \n  return(QLD_species)\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)\n\n5. Plot species SDM binary shapefile outputs for double check\n\noutput_dir &lt;- \"qld_3species_Marxan/QLD_feature/Marxan_feature_input/\"\n\n# List all the shapefiles in the directory (assuming each species has its own shapefile)\nspecies_files &lt;- list.files(output_dir, pattern = \"\\\\.shp$\", full.names = TRUE)\n\nspecies_files\n\n# Extract species names from the filenames (you can adjust this depending on your naming conventions)\nspecies_names &lt;- tools::file_path_sans_ext(basename(species_files))\n\n# Load all species shapefiles and add a species identifier\nspecies_sf_list &lt;- lapply(seq_along(species_files), function(i) {\n  sf &lt;- st_read(species_files[i])\n  sf$species &lt;- species_names[i]  # Add species name column\n  return(sf)\n})\n\n# Combine all species into one dataset\ncombined_species_sf &lt;- do.call(rbind, species_sf_list)\n\n# Plot the unit (base map) first and overlay the species habitats without borders\ncombined_plot_with_unit &lt;- ggplot() +\n  geom_sf(data = QLD_Unit, fill = NA, color = \"grey\", linewidth = 0.01) +  # Base map (QLD Unit)\n  geom_sf(data = combined_species_sf, aes(fill = species), color = NA) +  # No borders for species\n  scale_fill_manual(values = RColorBrewer::brewer.pal(n = length(species_names), name = \"Set1\")) +  # Automatically assign colors\n  theme_minimal() +\n  labs(title = \"Species Habitats within QLD Unit\",\n       subtitle = paste(species_names, collapse = \", \")) +  # List all species in subtitle\n  theme(legend.title = element_blank())\n\n# Display the plot\nprint(combined_plot_with_unit)\n\n\n\n\n\n\n\n\n6. We can also make a species presence and absence csv table.\n\n# Function to extract presence (1) and absence (0) from raster based on a threshold (e.g., 0.5)\n\nextract_presence_absence &lt;- function(raster_data, unit) {\n  extracted_values &lt;- extract(raster_data, vect(unit), fun = mean, na.rm = TRUE)\n  presence_absence &lt;- ifelse(extracted_values[, 2] &gt;= 0.5, 1, 0)\n  return(presence_absence)\n}\n\n# Create an empty presence-absence data frame\npresence_absence_df &lt;- data.frame(puid = QLD_Unit$puid)  # Assuming 'puid' is the unique identifier\n\n# Loop through each species raster in the raster list and extract presence-absence data\nfor (i in seq_along(raster_list)) {\n  # Generate a dynamic presence column name for the current species\n  presence_col_name &lt;- paste0(species_names[i], \"_presence\")\n  \n  # Extract presence/absence data and add it to the presence-absence dataframe\n  presence_absence_df[[species_names[i]]] &lt;- extract_presence_absence(raster_list[[i]], QLD_Unit)\n}\n\n# Write the final presence-absence data frame to a CSV file\noutput_csv &lt;- file.path(output_dir, \"presence_absence_species.csv\")\nwrite.csv(presence_absence_df, output_csv, row.names = FALSE)\n\n# Check the CSV output\nprint(head(presence_absence_df))\n\n  puid beach_stone_curlew_GLM brushtailed_rockwallaby_GLM Koala_GLM\n1    1                      0                           0         0\n2    2                      0                           0         0\n3    3                      0                           0         0\n4    4                      0                           0         0\n5    5                      0                           0         0\n6    6                      0                           0         0\n\n\n\n\n\n\n\n\n\n\nEcoCommons SDMs output of three species on Marxan MaPP\n\n\n\n\n\n\n\n\nNo Costs, neither SDMs\n\n\n\n\n\n\n\n\nSDMs only\n\n\n\n\n\n\n\n\nCosts only\n\n\n\n\n\n\n\n\nCosts and SDMs"
  },
  {
    "objectID": "notebooks/sp/ecocommons-marxan-integration-poc.html#introduction",
    "href": "notebooks/sp/ecocommons-marxan-integration-poc.html#introduction",
    "title": "EcoCommons -> Marxan MaPP connection",
    "section": "",
    "text": "Using the Species distribution modeling techniques provided by the EcoCommons Platform (www.ecocommons.org.au), we produced probability distribution maps for the three Queensland endangered species: koala, brush tailed rock-wallaby, and beach stone curlew.\nThen we adjusted the probability distribution maps of these three species with the planning units shapefile prepared by the Marxan MaPP, and ran four planning scenarios with a target of expanding the coverage of protected areas in QLD to 30%."
  },
  {
    "objectID": "notebooks/sp/ecocommons-marxan-integration-poc.html#ecocommons-outputs",
    "href": "notebooks/sp/ecocommons-marxan-integration-poc.html#ecocommons-outputs",
    "title": "EcoCommons -> Marxan MaPP connection",
    "section": "",
    "text": "Species records pulled from GBIF, ALA, EcoPlots, OBIS\nSpecies distribution modelling output: Species distribution Probability maps (This is the input tested in this project)."
  },
  {
    "objectID": "notebooks/sp/ecocommons-marxan-integration-poc.html#marxan-mapp-inputs",
    "href": "notebooks/sp/ecocommons-marxan-integration-poc.html#marxan-mapp-inputs",
    "title": "EcoCommons -> Marxan MaPP connection",
    "section": "",
    "text": "Shapefile of planning area and units.\nShapefile of cost.\nShapefile and csv of biodiversity features (Where EcoCommons can help!)."
  },
  {
    "objectID": "notebooks/sp/ecocommons-marxan-integration-poc.html#ecocommons-connects-with-marxan-showcase",
    "href": "notebooks/sp/ecocommons-marxan-integration-poc.html#ecocommons-connects-with-marxan-showcase",
    "title": "EcoCommons -> Marxan MaPP connection",
    "section": "",
    "text": "Make sure you are in the directory you want\n\ngetwd()\n\n[1] \"/Users/zhaoxiang/Documents/tmp/notebook-blog/notebooks/sp\"\n\n# setwd(“/replace_this_with_your_actual_directory/ecocommons-marxan-integration-poc”)\n\nActivate the virtual environment “renv” to install and load all essential packages\n\n# install \"renv\" package if not been installed\nif (!requireNamespace(\"renv\", quietly = TRUE)) {\n  install.packages(\"renv\")\n}\n\nif (!file.exists(\"renv/activate.R\")) {\n   message(\"renv has not been initiated in this project. Initializing now...\")\n   renv::init()  # This initializes renv if it's not set up\n} else {\n   source(\"renv/activate.R\")  # This ensures the renv environment is activated\n   message(\"renv is activated.\")\n}\n\n# Ensure renv is installed and initialized\nif (file.exists(\"renv.lock\")) {\n  renv::restore()\n} else {\n  message(\"No renv.lock file found in the current directory.\")\n}\n\nInstall and load essential packages\n\n# Set CRAN mirror\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\n\n# First specify the packages of interest\npackages = c(\"shiny\", \"sf\", \"terra\", \"ggplot2\", \"ggspatial\", \"raster\", \"dplyr\", \"shiny\", \"httpuv\", \"rmarkdown\", \"knitr\", \"jsonlite\", \"reticulate\", \"htmltools\", \"pryr\")\n\n# Now load or install&load all. This process will take a long time since we are using a virtual environment and install a lot of packages.\npackage.check &lt;- lapply(\n  packages,\n  FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n      install.packages(x, dependencies = TRUE)\n      library(x, character.only = TRUE)\n     }\n  }\n )\n\n\nSys.setenv(PROJ_LIB = \"/usr/local/Cellar/proj/9.5.0/share/proj\")\n\nrenv::snapshot()\n\n1. We get the QLD planning units from Marxan MaPP\n\nQLD_Unit &lt;- \"qld_3species_Marxan/QLD_plannningunits/cost-surface-template.shp\"  #This cost-surface-template was prepared by the Marxan Mapp with a resolution of 189 Km2, which is the highest resolution Marxan Mapp can give at this scale.\n\nQLD_Unit  &lt;- st_read(QLD_Unit)\nQLD_Unit  &lt;- st_simplify(QLD_Unit , dTolerance = 0.01) \n\n\n# Calculate the resolution since Marxan MaPP for visulization purpose\nareas &lt;- st_area(QLD_Unit)\nareas_numeric &lt;- as.numeric(areas)\naverage_area &lt;- mean(areas_numeric)\n\n# Convert to numeric\naverage_area_km2 &lt;- average_area / 1e6\n\n# Get the number of rows\nn_rows &lt;- nrow(QLD_Unit)\n\n# Plot the shapefile with no fill color and number of rows in the title\nggplot(data = QLD_Unit) +\n  geom_sf(fill = NA, color = \"gray\") +\n  theme_minimal() +\n  ggtitle(paste(\"QLD Planning Units:\", n_rows, \"\\n\",\n                \"Resolution of planning in square kilometers:\", round(average_area_km2)))+\n  theme(plot.title = element_text(hjust = 0.5))  # Center the title\n\n\n\n\n\n\n\n\n2. I made a cost layer using the reciprocal of the distance to state-owned road as a surrogate of the cost.\nThe assumption is: the closer to the state owned road, the more expensive to purchase the unit.\n\nQLD_cost_road &lt;- st_read(\"qld_3species_Marxan/QLD_Cost/QLD_cost_road.shp\")\n\n# Plot the shapefile with continuous cost_road values\nggplot(QLD_cost_road) +\n  geom_sf(aes(fill = cost_road)) +\n  scale_fill_continuous(name = \"Cost\",\n                        low = \"lightblue\", high = \"red\",\n                        labels = c(\"0 (Low cost)\", \"1 (High cost)\"),\n                        breaks = c(0.01, 1)) +\n  theme_minimal() +\n  labs(title = \"Cost: using the distance to road of each Unit as a proxy\")+\n  theme(plot.title = element_text(hjust = 0.5))  # Center the title\n\n\n\n\n\n\n\n\n3. Biodiversity features. I used EcoCommons to produce three species’ SDM to start with.\n\nSpecies 1: koala\nSpecies 2: brush tailed rock-wallaby\nSpecies 3: beach stone curlew\n\n\n# Define the folder path where the rasters are stored\nfolder_path &lt;- \"qld_3species_Marxan/QLD_feature/\"\n\n# Get a list of all .tif files in the folder\nraster_files &lt;- list.files(path = folder_path, pattern = \"\\\\.tif$\", full.names = TRUE)\n\n# Extract the species names from the file names (removing the folder path and .tif extension)\nspecies_names &lt;- tools::file_path_sans_ext(basename(raster_files))\n\n# Read all raster files in one go using lapply\nraster_list &lt;- lapply(raster_files, rast)  # Use rast() from terra for reading rasters\n\n# Using QLD_Unit as the spatial vector for masking\n\n# Transform the raster CRS to match the vector CRS and apply masking in one step\nraster_list &lt;- lapply(raster_list, function(r) {\n  r_transformed &lt;- project(r, crs(vect(QLD_Unit)))\n  mask(r_transformed, vect(QLD_Unit))\n})\n\n# Function to convert rasters to data frames and combine them\nprepare_raster_data &lt;- function(raster_list, species_names) {\n\n  # Initialize an empty data frame\n  combined_df &lt;- data.frame()\n  # Loop through each raster and combine them into one data frame\n  for (i in seq_along(raster_list)) {\n    # Convert raster to a data frame\n    raster_df &lt;- as.data.frame(raster_list[[i]], xy = TRUE)\n    # Rename the third column to 'value' or any appropriate name for the raster values\n    names(raster_df)[3] &lt;- \"value\"\n    # Add a column to identify the species name\n    raster_df$species &lt;- species_names[i]\n    # Combine the raster data with the overall data frame\n    combined_df &lt;- bind_rows(combined_df, raster_df)\n}\n  return(combined_df)\n}\n\n# Prepare the combined data frame\ncombined_raster_df &lt;- prepare_raster_data(raster_list, species_names)\n\n# Create the ggplot with facet_wrap to display each raster in a separate facet\nggplot(combined_raster_df, aes(x = x, y = y, fill = value)) +  # Use the correct column name for fill\n  geom_raster()+\n  facet_wrap(~ species, ncol = 3) +  # Adjust ncol to control the number of columns\n  scale_fill_viridis_c() +  # You can adjust the color scale as needed\n  labs(title = \"Species SDM\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n4. We need to turn these SDMs to binary results (shapefies).\n\n# Define the folder paths where the rasters and CSV files are stored\nfolder_path_rasters &lt;- \"qld_3species_Marxan/QLD_feature/\"\nfolder_path_csvs &lt;- \"qld_3species_Marxan/model_evaluation/\"\noutput_dir &lt;- \"qld_3species_Marxan/QLD_feature/Marxan_feature_input/\"\n\nQLD_Unit &lt;- \"qld_3species_Marxan/QLD_plannningunits/cost-surface-template.shp\"  #This cost-surface-template was prepared by the Marxan Mapp with a resolution of 189 Km2, which is the highest resolution Marxan Mapp can give at this scale.\n\nQLD_Unit  &lt;- st_read(QLD_Unit)\nQLD_Unit  &lt;- st_simplify(QLD_Unit , dTolerance = 0.01) \n\n\n# Get a list of all .tif files and CSV files in the folder\nraster_files &lt;- list.files(path = folder_path_rasters, pattern = \"\\\\.tif$\", full.names = TRUE)\ncsv_files &lt;- list.files(path = folder_path_csvs, pattern = \"\\\\.csv$\", full.names = TRUE)\n\n# Extract the species names from the file names (removing the folder path and .tif/.csv extension)\nspecies_names &lt;- tools::file_path_sans_ext(basename(raster_files))\n\n# Read all raster files in one go using lapply\nraster_list &lt;- lapply(raster_files, rast)  # Use rast() from terra for reading rasters\n\n# Transform the raster CRS to match the vector CRS and apply masking in one step\nraster_list &lt;- lapply(raster_list, function(r) {\n  r_transformed &lt;- project(r, crs(vect(QLD_Unit)))\n  mask(r_transformed, vect(QLD_Unit))\n})\n\n# Prepare a named list of rasters\nspecies_rasters &lt;- setNames(raster_list, species_names)\nspecies_csvs &lt;- setNames(csv_files, species_names)\n\n# Define UI for the application\nui &lt;- fluidPage(\n  titlePanel(\"Interactive TSS-based threshold for the probability of presence and absence of Species\"),\n  \n  # Use a loop to create a row for each species\n  lapply(species_names, function(species) {\n    fluidRow(\n      column(3, \n             h4(paste(\"Species:\", species)),\n             sliderInput(paste0(\"tss_value_\", species), \n                         \"Select TSS Value:\", \n                         min = 0, max = 1, value = 0.5, step = 0.01),\n             actionButton(paste0(\"run_analysis_\", species), \"Run Species Analysis\"),\n             br(),\n             textOutput(paste0(\"tpr_tnr_\", species))\n      ),\n      \n      column(4, \n             plotOutput(paste0(\"plot_\", species), width = \"400px\")\n      ),\n      \n      column(5, \n             plotOutput(paste0(\"species_plot_\", species))\n      )\n    )\n  })\n)\n\n# Define server logic\nserver &lt;- function(input, output, session) {\n  \n  selected_raster &lt;- function(species) {\n    species_rasters[[species]]\n  }\n  \n  species_eval_data &lt;- function(species) {\n    csv_path &lt;- species_csvs[[species]]\n    \n    if (!file.exists(csv_path)) {\n      showNotification(paste(\"CSV file for\", species, \"not found!\"), type = \"error\")\n      return(NULL)\n    }\n    \n    eval_data &lt;- read.csv(csv_path)\n    \n    if (!all(c(\"tpr\", \"tnr\", \"tpv\") %in% names(eval_data))) {\n      showNotification(paste(\"Required columns missing in CSV for\", species), type = \"error\")\n      return(NULL)\n    }\n    \n    if (nrow(eval_data) == 0) {\n      showNotification(paste(\"No data found in CSV for\", species), type = \"error\")\n      return(NULL)\n    }\n    \n    eval_data$tss &lt;- round(eval_data$tpr + eval_data$tnr - 1, 3)\n    return(eval_data)\n  }\n  \n  lapply(species_names, function(species) {\n    eval_data &lt;- species_eval_data(species)\n    \n    if (!is.null(eval_data)) {\n      min_tss &lt;- min(eval_data$tss, na.rm = TRUE)\n      max_tss &lt;- max(eval_data$tss, na.rm = TRUE)\n      \n      updateSliderInput(session, paste0(\"tss_value_\", species), \n                        min = min_tss, \n                        max = max_tss, \n                        value = max_tss,\n                        step = 0.01)\n    }\n    \n    observeEvent(input[[paste0(\"tss_value_\", species)]], {\n      if (!is.null(eval_data)) {\n        row &lt;- which.min(abs(eval_data$tss - input[[paste0(\"tss_value_\", species)]]))\n        \n        tpr &lt;- eval_data$tpr[row]\n        tnr &lt;- eval_data$tnr[row]\n        \n        output[[paste0(\"tpr_tnr_\", species)]] &lt;- renderText({\n          paste0(\"TPR (Sensitivity): \", round(tpr, 3), \n                 \", TNR (Specificity): \", round(tnr, 3))\n        })\n      }\n    })\n    \n    output[[paste0(\"plot_\", species)]] &lt;- renderPlot({\n      if (is.null(eval_data)) return(NULL)\n      \n      ggplot(eval_data, aes(x = tpv)) +\n        geom_line(aes(y = tpr, colour = \"TPR\"), linewidth = 1) +\n        geom_line(aes(y = tnr, colour = \"TNR\"), linewidth = 1) +\n        geom_line(aes(y = tss, colour = \"TSS\"), linewidth = 1) +\n        geom_vline(xintercept = eval_data$tpv[which.min(abs(eval_data$tss - input[[paste0(\"tss_value_\", species)]]))],\n                   linetype = \"dotted\", color = \"red\", linewidth = 1) +\n        labs(title = paste(\"Sensitivity, Specificity, and TSS for\", species),\n             x = \"Threshold Probability Value\",\n             y = \"Value\") +\n        scale_colour_manual(values = c(\"TPR\" = \"blue\", \"TNR\" = \"green\", \"TSS\" = \"red\")) +\n        theme_minimal()\n    })\n    \n    observeEvent(input[[paste0(\"run_analysis_\", species)]], {\n      species_shp &lt;- process_species(selected_raster(species), QLD_Unit, species, output_dir, input[[paste0(\"tss_value_\", species)]])\n      \n      output[[paste0(\"species_plot_\", species)]] &lt;- renderPlot({\n        ggplot() +\n          geom_sf(data = QLD_Unit, fill = NA, color = \"grey\") +\n          geom_sf(data = species_shp, aes(fill = feature), color = NA) +\n          scale_fill_viridis_c(option = \"plasma\") +\n          labs(title = paste(\"Species Distribution for\", species),\n               x = \"Longitude\", y = \"Latitude\") +\n          theme_minimal()\n      })\n    })\n  })\n}\n\nprocess_species &lt;- function(raster_data, planning_unit, species_name, output_dir, tss_threshold) {\n  raster_data_transformed &lt;- project(raster_data, crs(vect(planning_unit)))\n  extracted_values &lt;- extract(raster_data_transformed, vect(planning_unit), fun = mean, na.rm = TRUE)\n  names(planning_unit)[names(planning_unit) == \"cost\"] &lt;- \"feature\"\n  planning_unit$feature &lt;- extracted_values[, 2]\n  \n  QLD_species &lt;- subset(planning_unit, feature &gt;= tss_threshold)\n  shapefile_base &lt;- file.path(output_dir, species_name)\n  st_write(QLD_species, paste0(shapefile_base, \".shp\"), delete_layer = TRUE)\n  \n  return(QLD_species)\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)\n\n5. Plot species SDM binary shapefile outputs for double check\n\noutput_dir &lt;- \"qld_3species_Marxan/QLD_feature/Marxan_feature_input/\"\n\n# List all the shapefiles in the directory (assuming each species has its own shapefile)\nspecies_files &lt;- list.files(output_dir, pattern = \"\\\\.shp$\", full.names = TRUE)\n\nspecies_files\n\n# Extract species names from the filenames (you can adjust this depending on your naming conventions)\nspecies_names &lt;- tools::file_path_sans_ext(basename(species_files))\n\n# Load all species shapefiles and add a species identifier\nspecies_sf_list &lt;- lapply(seq_along(species_files), function(i) {\n  sf &lt;- st_read(species_files[i])\n  sf$species &lt;- species_names[i]  # Add species name column\n  return(sf)\n})\n\n# Combine all species into one dataset\ncombined_species_sf &lt;- do.call(rbind, species_sf_list)\n\n# Plot the unit (base map) first and overlay the species habitats without borders\ncombined_plot_with_unit &lt;- ggplot() +\n  geom_sf(data = QLD_Unit, fill = NA, color = \"grey\", linewidth = 0.01) +  # Base map (QLD Unit)\n  geom_sf(data = combined_species_sf, aes(fill = species), color = NA) +  # No borders for species\n  scale_fill_manual(values = RColorBrewer::brewer.pal(n = length(species_names), name = \"Set1\")) +  # Automatically assign colors\n  theme_minimal() +\n  labs(title = \"Species Habitats within QLD Unit\",\n       subtitle = paste(species_names, collapse = \", \")) +  # List all species in subtitle\n  theme(legend.title = element_blank())\n\n# Display the plot\nprint(combined_plot_with_unit)\n\n\n\n\n\n\n\n\n6. We can also make a species presence and absence csv table.\n\n# Function to extract presence (1) and absence (0) from raster based on a threshold (e.g., 0.5)\n\nextract_presence_absence &lt;- function(raster_data, unit) {\n  extracted_values &lt;- extract(raster_data, vect(unit), fun = mean, na.rm = TRUE)\n  presence_absence &lt;- ifelse(extracted_values[, 2] &gt;= 0.5, 1, 0)\n  return(presence_absence)\n}\n\n# Create an empty presence-absence data frame\npresence_absence_df &lt;- data.frame(puid = QLD_Unit$puid)  # Assuming 'puid' is the unique identifier\n\n# Loop through each species raster in the raster list and extract presence-absence data\nfor (i in seq_along(raster_list)) {\n  # Generate a dynamic presence column name for the current species\n  presence_col_name &lt;- paste0(species_names[i], \"_presence\")\n  \n  # Extract presence/absence data and add it to the presence-absence dataframe\n  presence_absence_df[[species_names[i]]] &lt;- extract_presence_absence(raster_list[[i]], QLD_Unit)\n}\n\n# Write the final presence-absence data frame to a CSV file\noutput_csv &lt;- file.path(output_dir, \"presence_absence_species.csv\")\nwrite.csv(presence_absence_df, output_csv, row.names = FALSE)\n\n# Check the CSV output\nprint(head(presence_absence_df))\n\n  puid beach_stone_curlew_GLM brushtailed_rockwallaby_GLM Koala_GLM\n1    1                      0                           0         0\n2    2                      0                           0         0\n3    3                      0                           0         0\n4    4                      0                           0         0\n5    5                      0                           0         0\n6    6                      0                           0         0"
  },
  {
    "objectID": "notebooks/sp/ecocommons-marxan-integration-poc.html#marxan-four-scenarios-solutions",
    "href": "notebooks/sp/ecocommons-marxan-integration-poc.html#marxan-four-scenarios-solutions",
    "title": "EcoCommons -> Marxan MaPP connection",
    "section": "",
    "text": "EcoCommons SDMs output of three species on Marxan MaPP\n\n\n\n\n\n\n\n\nNo Costs, neither SDMs\n\n\n\n\n\n\n\n\nSDMs only\n\n\n\n\n\n\n\n\nCosts only\n\n\n\n\n\n\n\n\nCosts and SDMs"
  },
  {
    "objectID": "notebooks/data_prep/raster_preparation.html#environmental-variables",
    "href": "notebooks/data_prep/raster_preparation.html#environmental-variables",
    "title": "Species Distribution Analysis - Environmental Data Preparation (Raster)",
    "section": "1. Environmental variables",
    "text": "1. Environmental variables\nIn Species Distribution Modeling (SDM), environmental variables are factors that influence where a species can live. These include:\n\nClimatic Variables: Temperature, precipitation.\nTopographic Variables: Elevation, slope.\nSoil Variables: Soil pH, texture.\nVegetation Variables: Land cover type, canopy cover.\nHydrological Variables: Distance to water bodies, soil moisture.\nBiotic Variables: Presence of prey, competitors.\nAnthropogenic Variables: Land use, human impact.\n\nThese variables help explain and predict a species’ habitat suitability based on environmental conditions."
  },
  {
    "objectID": "notebooks/data_prep/raster_preparation.html#raster",
    "href": "notebooks/data_prep/raster_preparation.html#raster",
    "title": "Species Distribution Analysis - Environmental Data Preparation (Raster)",
    "section": "2. Raster",
    "text": "2. Raster\nRaster data is a type of spatial data used to represent continuous surfaces, like environmental layers (e.g., elevation, temperature) in grids or cells. Each cell (pixel) has a value that represents information about that area.\nImportant Characteristics:\n\nResolution: Size of each cell, determining data detail (e.g., 10m x 10m cells).\nExtent: Geographic area covered by the raster.\nCoordinate Reference System (CRS): Defines the spatial reference of the raster for location accuracy.\nData Type: Can be continuous (e.g., temperature) or categorical (e.g., land cover type).\n\nThese characteristics impact how raster data is interpreted and used in analyses like SDM.\nTo make extract the value of raster data, we always want our raster data has the same resolution, extend, and CRS."
  },
  {
    "objectID": "notebooks/data_prep/raster_preparation.html#categorical-and-continuous-data",
    "href": "notebooks/data_prep/raster_preparation.html#categorical-and-continuous-data",
    "title": "Species Distribution Analysis - Environmental Data Preparation (Raster)",
    "section": "3. Categorical and Continuous data",
    "text": "3. Categorical and Continuous data\nIn environmental modeling, environmental variables can be classified as categorical or continuous:\nCategorical Data\n\nRepresents discrete classes or categories.\nExamples:\n\nLand Cover Type: Forest, grassland, urban.\nSoil Type: Sandy, clay, loam.\nVegetation Type: Different plant communities.\n\n\nContinuous Data\n\nRepresents data with a smooth gradient, measurable values.\nExamples:\n\nTemperature: Annual mean temperature.\nPrecipitation: Monthly or annual rainfall.\nElevation: Height above sea level in meters.\n\n\nCategorical data is useful for distinct classifications, while continuous data is used for variables that change gradually across the landscape. Both types are important for predicting species distributions."
  },
  {
    "objectID": "notebooks/data_prep/raster_preparation.html#set-working-directory-and-make-a-folder-to-store-data.",
    "href": "notebooks/data_prep/raster_preparation.html#set-working-directory-and-make-a-folder-to-store-data.",
    "title": "Species Distribution Analysis - Environmental Data Preparation (Raster)",
    "section": "1. Set working directory and make a folder to store data.",
    "text": "1. Set working directory and make a folder to store data.\n\n# Set Workspace as the current working directory\nworkspace &lt;- getwd()\n\n# Define directory for storing environmental data\nenv_data_dir &lt;- file.path(workspace, \"env_data\")\n\n# Create 'env_data' directory if it doesn't exist\nif (!dir.exists(env_data_dir)) {\n  dir.create(env_data_dir, recursive = TRUE)\n  cat(\"Directory 'env_data' created successfully.\\n\")\n} else {\n  cat(\"Directory 'env_data' already exists.\\n\")\n}\n\nDirectory 'env_data' already exists."
  },
  {
    "objectID": "notebooks/data_prep/raster_preparation.html#install-and-load-essential-libraries.",
    "href": "notebooks/data_prep/raster_preparation.html#install-and-load-essential-libraries.",
    "title": "Species Distribution Analysis - Environmental Data Preparation (Raster)",
    "section": "2. Install and load essential libraries.",
    "text": "2. Install and load essential libraries.\n\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\n\n\n# List of packages to check, install if needed, and load\npackages &lt;- c(\"dplyr\", \"terra\", \"sf\", \"googledrive\", \"ggplot2\")\n\n# Install missing packages and load them\nfor (pkg in packages) {\n  if (!pkg %in% installed.packages()[, \"Package\"]) {\n    install.packages(pkg)\n  }\n  library(pkg, character.only = TRUE)\n}\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nterra 1.7.78\n\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n# De-authenticate Google Drive to access public files\ndrive_deauth()"
  },
  {
    "objectID": "notebooks/data_prep/raster_preparation.html#download-environmental-data",
    "href": "notebooks/data_prep/raster_preparation.html#download-environmental-data",
    "title": "Species Distribution Analysis - Environmental Data Preparation (Raster)",
    "section": "3. Download Environmental Data",
    "text": "3. Download Environmental Data\nEnvironmental variables are downloaded from both WorldClim and Google Drive, and stored in GeoTIFF format.\n\nlibrary(googledrive)\ndrive_deauth()  # Access public files without authentication\n\n\n# # Define Google Drive file IDs and corresponding local file paths for environmental variables\n# file_ids &lt;- list(\n#   env_var_1 = \"1EA_lberXjNI3_RRM0mbAdDvVDTFL2tW3\", # Continuous Environmental Variable 1, Bioclim 01\n#   env_var_2 = \"1PO1TAQp-ND4olSgIQ29wjexMOQnhXkku\", # Continuous Environmental Variable 2, Bioclim 02\n#   env_var_3 = \"1BSEuphUV-qqR-gnA9HPZ1qKGLyJfLagC\", # Continuous Environmental Variable 3, Bioclim 03\n#   env_var_4 = \"1fCI5D_AGg2nhU75A-9WX7MspcrQYMp7f\", # Continuous Environmental Variable 4, Bioclim 04\n#   env_var_5 = \"1yWmJ9fKFPZQoV_XTRIWABV_gaF-wexzZ\", # Continuous Environmental Variable 5, Bioclim 05\n#   env_var_cat_1 = \"1WzBKghFdG67C_LMeOmi9a1A12wjrd9wo\" # Categorical Environmental Variable 1, Land use of Australia\n# )\n\n\n# Define local file paths for each environmental variable\nfile_paths &lt;- list(\n  env_var_1 = file.path(workspace, \"env_data\", \"env_var_1.tif\"),\n  env_var_2 = file.path(workspace, \"env_data\", \"env_var_2.tif\"),\n  env_var_3 = file.path(workspace, \"env_data\", \"env_var_3.tif\"),\n  env_var_4 = file.path(workspace, \"env_data\", \"env_var_4.tif\"),\n  env_var_5 = file.path(workspace, \"env_data\", \"env_var_5.tif\"),\n  env_var_cat_1 = file.path(workspace, \"env_data\", \"env_var_cat_1.tif\")\n)\n\n# # Function to download individual files with progress messages\n# download_file &lt;- function(file_id, file_path) {\n#   cat(\"Downloading:\", basename(file_path), \"...\\n\")\n#   drive_download(as_id(file_id), path = file_path, overwrite = TRUE)\n#   cat(\"Downloaded:\", basename(file_path), \"\\n\")\n# }\n\n# # Download each environmental variable file\n# cat(\"Downloading environmental variable files...\\n\")\n# invisible(mapply(download_file, file_ids, file_paths))\n# \n# # Confirm the files have been downloaded\n# downloaded_files &lt;- list.files(file.path(workspace, \"env_data\"), recursive = TRUE)\n# cat(\"Downloaded files:\\n\", downloaded_files, \"\\n\")"
  },
  {
    "objectID": "notebooks/data_prep/raster_preparation.html#load-and-process-environmental-data",
    "href": "notebooks/data_prep/raster_preparation.html#load-and-process-environmental-data",
    "title": "Species Distribution Analysis - Environmental Data Preparation (Raster)",
    "section": "4. Load and Process Environmental Data",
    "text": "4. Load and Process Environmental Data\nAll raster files are loaded and reprojected if necessary to ensure consistency.\n\n# Load all rasters and store in a list\nrasters &lt;- lapply(file_paths, rast)\n\n\n# Sometimes, when you upload a raster file (such as a GeoTIFF) to Google Drive and then open it in Google Colab, it may lose its categorical (factor) properties due to how terra or other spatial libraries interpret the file upon reloading. Rasters saved as categorical may be stored with integer values rather than explicit factor levels in the file, meaning they need to be redefined as factors when reloaded.\n\nrasters[[6]] &lt;- as.factor(rasters[[6]])\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n# Check if each raster is categorical or continuous\nfor (i in seq_along(rasters)) {\n  if (is.factor(rasters[[i]])) {\n    cat(\"Raster\", i, \"is categorical.\\n\")\n  } else {\n    cat(\"Raster\", i, \"is continuous.\\n\")\n  }\n}\n\nRaster 1 is continuous.\nRaster 2 is continuous.\nRaster 3 is continuous.\nRaster 4 is continuous.\nRaster 5 is continuous.\nRaster 6 is categorical."
  },
  {
    "objectID": "notebooks/data_prep/raster_preparation.html#download-and-load-australian-boundary-shapefile",
    "href": "notebooks/data_prep/raster_preparation.html#download-and-load-australian-boundary-shapefile",
    "title": "Species Distribution Analysis - Environmental Data Preparation (Raster)",
    "section": "5. Download and Load Australian Boundary Shapefile",
    "text": "5. Download and Load Australian Boundary Shapefile\n\nlibrary(googledrive)\n\n# De-authenticate Google Drive to access public files\ndrive_deauth()\n\n# Folder ID for the Australian polygon shapefile\naus_folder_id &lt;- \"1rzNHthnQQXVulocKkB5i7v2dObqKMP11\"\n\n# Define the local directory to save the shapefile components\nshapefile_dir &lt;- file.path(workspace, \"env_data\", \"aus_shapefile\")\ndir.create(shapefile_dir, showWarnings = FALSE, recursive = TRUE)\n\n# List all files in the shapefile folder on Google Drive\nfiles_in_folder &lt;- drive_ls(as_id(aus_folder_id))\n\n# Download each file in the folder\ncat(\"Downloading shapefile components...\\n\")\n\nDownloading shapefile components...\n\nfor (i in 1:nrow(files_in_folder)) {\n  file_name &lt;- files_in_folder$name[i]\n  cat(\"Downloading:\", file_name, \"...\\n\")\n  drive_download(files_in_folder$id[i], path = file.path(shapefile_dir, file_name), overwrite = TRUE)\n}\n\nDownloading: AUS_2021_AUST_GDA2020.xml ...\n\n\nFile downloaded:\n\n\n• 'AUS_2021_AUST_GDA2020.xml' &lt;id: 1BxMyIxENdWJ2RiZxK_8Ay_0r2Uvad5Wd&gt;\n\n\nSaved locally as:\n\n\n• '/Users/zhaoxiang/Documents/tmp/notebook-blog/notebooks/data_prep/env_data/aus_shapefile/AUS_2021_AUST_GDA2020.xml'\n\n\nDownloading: AUS_2021_AUST_GDA2020.shx ...\n\n\nFile downloaded:\n\n\n• 'AUS_2021_AUST_GDA2020.shx' &lt;id: 1wfSxFsmgK4V44f4ZJhYy3V6wL16YpVWe&gt;\n\n\nSaved locally as:\n\n\n• '/Users/zhaoxiang/Documents/tmp/notebook-blog/notebooks/data_prep/env_data/aus_shapefile/AUS_2021_AUST_GDA2020.shx'\n\n\nDownloading: AUS_2021_AUST_GDA2020.dbf ...\n\n\nFile downloaded:\n\n\n• 'AUS_2021_AUST_GDA2020.dbf' &lt;id: 1gdWxQ5aOB_KuejlHn254K7RwdtDR2N8f&gt;\n\n\nSaved locally as:\n\n\n• '/Users/zhaoxiang/Documents/tmp/notebook-blog/notebooks/data_prep/env_data/aus_shapefile/AUS_2021_AUST_GDA2020.dbf'\n\n\nDownloading: AUS_2021_AUST_GDA2020.prj ...\n\n\nFile downloaded:\n\n\n• 'AUS_2021_AUST_GDA2020.prj' &lt;id: 1Fi9K9mWOpvksSkH0CGJN9XlKf8-1LjSj&gt;\n\n\nSaved locally as:\n\n\n• '/Users/zhaoxiang/Documents/tmp/notebook-blog/notebooks/data_prep/env_data/aus_shapefile/AUS_2021_AUST_GDA2020.prj'\n\n\nDownloading: AUS_2021_AUST_GDA2020.shp ...\n\n\nFile downloaded:\n\n\n• 'AUS_2021_AUST_GDA2020.shp' &lt;id: 1ZWGQYHbygM-MCFyON76FXwj7uHwJnpxH&gt;\n\n\nSaved locally as:\n\n\n• '/Users/zhaoxiang/Documents/tmp/notebook-blog/notebooks/data_prep/env_data/aus_shapefile/AUS_2021_AUST_GDA2020.shp'\n\ncat(\"Shapefile components downloaded to:\", shapefile_dir, \"\\n\")\n\nShapefile components downloaded to: /Users/zhaoxiang/Documents/tmp/notebook-blog/notebooks/data_prep/env_data/aus_shapefile \n\n# Load necessary library for handling shapefiles\nlibrary(terra)\n\n# Load the shapefile using the components in the downloaded directory\nshapefile_path &lt;- list.files(shapefile_dir, pattern = \"\\\\.shp$\", full.names = TRUE)\n\n# Load the Australian boundary as an sf object and convert to EPSG 4326\naustralia_boundary &lt;- st_read(shapefile_path)\n\nReading layer `AUS_2021_AUST_GDA2020' from data source \n  `/Users/zhaoxiang/Documents/tmp/notebook-blog/notebooks/data_prep/env_data/aus_shapefile/AUS_2021_AUST_GDA2020.shp' \n  using driver `ESRI Shapefile'\nreplacing null geometries with empty geometries\nSimple feature collection with 2 features and 6 fields (with 1 geometry empty)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.81695 ymin: -43.7405 xmax: 167.998 ymax: -9.142163\nGeodetic CRS:  GDA2020\n\naustralia_boundary &lt;- st_transform(australia_boundary, crs = 4326)\n\nclass(australia_boundary)\n\n[1] \"sf\"         \"data.frame\""
  },
  {
    "objectID": "notebooks/data_prep/raster_preparation.html#plot-australian-boundary",
    "href": "notebooks/data_prep/raster_preparation.html#plot-australian-boundary",
    "title": "Species Distribution Analysis - Environmental Data Preparation (Raster)",
    "section": "6. Plot Australian Boundary",
    "text": "6. Plot Australian Boundary\n\nlibrary(ggplot2)\n\nggplot(data = australia_boundary) +\n  geom_sf(fill = \"#61c6fa\", color = \"black\") +  # Fill with light blue and outline in black\n  labs(title = \"Map of Australia\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 18, face = \"bold\"),\n        axis.title.x = element_text(size = 12),\n        axis.title.y = element_text(size = 12),\n        axis.text.x = element_text(size = 12),\n        axis.text.y = element_text(size = 12),\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 12),\n        panel.border = element_rect(colour = \"gray\", fill = NA, linewidth = 0.5))"
  },
  {
    "objectID": "notebooks/data_prep/raster_preparation.html#show-resolution-extent-and-crs-of-raster-and-study-area",
    "href": "notebooks/data_prep/raster_preparation.html#show-resolution-extent-and-crs-of-raster-and-study-area",
    "title": "Species Distribution Analysis - Environmental Data Preparation (Raster)",
    "section": "7. Show Resolution, Extent, and CRS of Raster and Study Area",
    "text": "7. Show Resolution, Extent, and CRS of Raster and Study Area\n\n# Get and print the extent of the Australian boundary vector\naustralia_extent &lt;- ext(australia_boundary)\ncat(\"Extent of Australia boundary:\\n\")\n\nExtent of Australia boundary:\n\nprint(australia_extent)\n\nSpatExtent : 96.8169516292395, 167.99803924286, -43.7404965718585, -9.14216252238993 (xmin, xmax, ymin, ymax)\n\n# Get and print the CRS of the Australian boundary vector\naustralia_crs &lt;- crs(australia_boundary)\ncat(\"CRS of Australia boundary:\\n\")\n\nCRS of Australia boundary:\n\nprint(australia_crs)\n\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\n# Iterate over the rasters to show resolution, extent, and CRS\nfor (i in seq_along(rasters)) {\n  cat(\"\\nRaster\", i, \":\\n\")\n\n  # Show the resolution\n  res_val &lt;- res(rasters[[i]])\n  cat(\"Resolution (x, y):\", res_val[1], \",\", res_val[2], \"\\n\")\n\n  # Show the extent - Modified to handle S4 object\n  ext_val &lt;- ext(rasters[[i]])\n  cat(\"Extent:\", as.character(ext_val), \"\\n\") # Convert ext_val to character\n\n  # Show the CRS\n  crs_val &lt;- crs(rasters[[i]])\n  cat(\"CRS:\", crs_val, \"\\n\")\n}\n\n\nRaster 1 :\nResolution (x, y): 0.04166667 , 0.04166667 \nExtent: ext(-180, 180, -90, 90) \nCRS: GEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]] \n\nRaster 2 :\nResolution (x, y): 0.04166667 , 0.04166667 \nExtent: ext(-180, 180, -90, 90) \nCRS: GEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]] \n\nRaster 3 :\nResolution (x, y): 0.04166667 , 0.04166667 \nExtent: ext(-180, 180, -90, 90) \nCRS: GEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]] \n\nRaster 4 :\nResolution (x, y): 0.04166667 , 0.04166667 \nExtent: ext(-180, 180, -90, 90) \nCRS: GEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]] \n\nRaster 5 :\nResolution (x, y): 0.04166667 , 0.04166667 \nExtent: ext(-180, 180, -90, 90) \nCRS: GEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]] \n\nRaster 6 :\nResolution (x, y): 250 , 250 \nExtent: ext(-2189542.251493, 2468707.748507, -4964936.305317, -1047686.305317) \nCRS: PROJCRS[\"unknown\",\n    BASEGEOGCRS[\"unknown\",\n        DATUM[\"Unknown based on GRS80 ellipsoid\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101004,\n                LENGTHUNIT[\"metre\",1],\n                ID[\"EPSG\",7019]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433,\n                ID[\"EPSG\",9122]]]],\n    CONVERSION[\"Albers Equal Area\",\n        METHOD[\"Albers Equal Area\",\n            ID[\"EPSG\",9822]],\n        PARAMETER[\"Latitude of false origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8821]],\n        PARAMETER[\"Longitude of false origin\",132,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8822]],\n        PARAMETER[\"Latitude of 1st standard parallel\",-18,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8823]],\n        PARAMETER[\"Latitude of 2nd standard parallel\",-36,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8824]],\n        PARAMETER[\"Easting at false origin\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8826]],\n        PARAMETER[\"Northing at false origin\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8827]]],\n    CS[Cartesian,2],\n        AXIS[\"easting\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"northing\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]"
  },
  {
    "objectID": "notebooks/data_prep/raster_preparation.html#reproject-raster-to-wgs-84-if-needed",
    "href": "notebooks/data_prep/raster_preparation.html#reproject-raster-to-wgs-84-if-needed",
    "title": "Species Distribution Analysis - Environmental Data Preparation (Raster)",
    "section": "8. Reproject Raster to WGS 84 if Needed",
    "text": "8. Reproject Raster to WGS 84 if Needed\n\nlibrary(terra)\n\n# Function to check CRS and reproject to WGS 84 if needed\nreproject_if_needed &lt;- function(raster, is_categorical = FALSE) {\n  wgs84_crs &lt;- \"EPSG:4326\"  # Define WGS 84 CRS using EPSG code\n\n  # Check if the CRS is already WGS 84\n  if (!identical(crs(raster), wgs84_crs)) {\n    # Choose the appropriate method based on raster type\n    method &lt;- if (is_categorical) \"near\" else \"bilinear\"\n    message(\"Reprojecting raster to WGS 84 using method: \", method)\n\n    # Reproject raster to WGS 84 CRS\n    raster &lt;- project(raster, wgs84_crs, method = method)\n\n    # Convert to factor again if categorical to ensure category levels are preserved\n    if (is_categorical) {\n      raster &lt;- as.factor(raster)\n    }\n  }\n\n  return(raster)\n}\n\n# Define the categorical raster indices\ncategorical_indices &lt;- c(6)  # Adjust if there are other categorical rasters\n\n# Apply the function to each raster in the list\nrasters_reprojected &lt;- lapply(seq_along(rasters), function(i) {\n  is_categorical &lt;- i %in% categorical_indices\n  reproject_if_needed(rasters[[i]], is_categorical = is_categorical)\n})\n\nReprojecting raster to WGS 84 using method: bilinear\nReprojecting raster to WGS 84 using method: bilinear\nReprojecting raster to WGS 84 using method: bilinear\nReprojecting raster to WGS 84 using method: bilinear\nReprojecting raster to WGS 84 using method: bilinear\n\n\nReprojecting raster to WGS 84 using method: near\n\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n# Print the CRS of each reprojected raster to verify\nfor (i in seq_along(rasters_reprojected)) {\n  cat(\"\\nRaster\", i, \"CRS:\\n\")\n  print(crs(rasters_reprojected[[i]]))\n}\n\n\nRaster 1 CRS:\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\nRaster 2 CRS:\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\nRaster 3 CRS:\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\nRaster 4 CRS:\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\nRaster 5 CRS:\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\nRaster 6 CRS:\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\""
  },
  {
    "objectID": "notebooks/data_prep/raster_preparation.html#resample-rasters-to-match-the-finest-resolution",
    "href": "notebooks/data_prep/raster_preparation.html#resample-rasters-to-match-the-finest-resolution",
    "title": "Species Distribution Analysis - Environmental Data Preparation (Raster)",
    "section": "9. Resample Rasters to Match the Finest Resolution",
    "text": "9. Resample Rasters to Match the Finest Resolution\n\n# Determine the finest resolution among the reprojected rasters\nresolutions &lt;- sapply(rasters_reprojected, function(r) res(r)[1] * res(r)[2])\nfinest_index &lt;- which.min(resolutions)\nfinest_raster &lt;- rasters_reprojected[[finest_index]]\n\n# Resample each raster to match the finest resolution\nrasters_resampled &lt;- lapply(seq_along(rasters_reprojected), function(i) {\n  raster &lt;- rasters_reprojected[[i]]\n\n  # Determine resampling method based on the type of raster (categorical vs continuous)\n  if (i == 6) {  # the 6th raster is the categorical one\n    message(\"Resampling categorical raster to match the finest resolution using 'nearest' method.\")\n    raster &lt;- resample(raster, finest_raster, method = \"near\")  # Use 'near' for categorical data\n  } else {\n    message(\"Resampling continuous raster to match the finest resolution using 'bilinear' method.\")\n    raster &lt;- resample(raster, finest_raster, method = \"bilinear\")  # Use 'bilinear' for continuous data\n  }\n\n  return(raster)\n})\n\nResampling continuous raster to match the finest resolution using 'bilinear' method.\n\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n\nResampling continuous raster to match the finest resolution using 'bilinear' method.\n\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n\nResampling continuous raster to match the finest resolution using 'bilinear' method.\n\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n\nResampling continuous raster to match the finest resolution using 'bilinear' method.\n\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n\nResampling continuous raster to match the finest resolution using 'bilinear' method.\n\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n\nResampling categorical raster to match the finest resolution using 'nearest' method.\n\n\n\n|---------|---------|---------|---------|\n========================================="
  },
  {
    "objectID": "notebooks/data_prep/raster_preparation.html#crop-and-mask-raster-to-study-area",
    "href": "notebooks/data_prep/raster_preparation.html#crop-and-mask-raster-to-study-area",
    "title": "Species Distribution Analysis - Environmental Data Preparation (Raster)",
    "section": "10. Crop and Mask Raster to Study Area",
    "text": "10. Crop and Mask Raster to Study Area\n\n# Reproject the Australian boundary vector to WGS 84\nwgs84_crs &lt;- \"EPSG:4326\"\n\naustralia_boundary_vect &lt;- vect(australia_boundary)\n\naustralia_boundary_vect_wgs84 &lt;- project(australia_boundary_vect, wgs84_crs)\n\n# Crop and mask each resampled raster to the extent of Australia\ncropped_masked_rasters &lt;- lapply(rasters_resampled, function(raster) {\n  # Crop the raster to the extent of Australia\n  cropped_raster &lt;- crop(raster, australia_boundary_vect_wgs84)\n  # Mask the raster with the Australia boundary to keep only data within Australia\n  masked_raster &lt;- mask(cropped_raster, australia_boundary_vect_wgs84)\n  return(masked_raster)\n})\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n========================================="
  },
  {
    "objectID": "notebooks/data_prep/raster_preparation.html#stack-and-save-raster",
    "href": "notebooks/data_prep/raster_preparation.html#stack-and-save-raster",
    "title": "Species Distribution Analysis - Environmental Data Preparation (Raster)",
    "section": "11. Stack and Save Raster",
    "text": "11. Stack and Save Raster\n\n# Stack the cropped and masked rasters together\nraster_stack &lt;- do.call(c, cropped_masked_rasters)\n\n# Print summary to verify the stack\nprint(raster_stack)\n\nclass       : SpatRaster \ndimensions  : 14113, 22774, 6  (nrow, ncol, nlyr)\nresolution  : 0.002451532, 0.002451532  (x, y)\nextent      : 105.7046, 161.5358, -43.74011, -9.141636  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsources     : spat_7370758517d3_29552.tif  \n              spat_737073888f3e_29552.tif  \n              spat_7370610954c8_29552.tif  \n              ... and 3 more source(s)\nnames       : env_var_1, env_var_2, env_var_3, env_var_4, env_var_5, Category \nmin values  :  4.272866,  3.591667,  31.50585,  53.13949,  15.60910,        1 \nmax values  : 29.350683, 17.464588,  77.26542, 682.58344,  42.34991,        6 \n\n# Plot each layer to visually verify the raster stack\nplot(raster_stack)\n\n\n\n\n\n\n\n# Save the raster stack to a GeoTIFF file\nwriteRaster(raster_stack, filename = \"stacked_raster.tif\", overwrite = TRUE)\n\n\n|---------|---------|---------|---------|\n========================================="
  }
]