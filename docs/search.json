[
  {
    "objectID": "sp_marxan/ecocommons-marxan-integration-poc.html",
    "href": "sp_marxan/ecocommons-marxan-integration-poc.html",
    "title": "EcoCommons Marxan MaPP connection",
    "section": "",
    "text": "Author: Zhao Xiang, EcoCommons\nDate: 2024-10-02\n\n\n\n\n\n\n\nUsing the Species distribution modeling techniques provided by the EcoCommons Platform (www.ecocommons.org.au), we produced probability distribution maps for the three Queensland endangered species: koala, brush tailed rock-wallaby, and beach stone curlew.\nThen we adjusted the probability distribution maps of these three species with the planning units shapefile prepared by the Marxan MaPP, and ran four planning scenarios with a target of expanding the coverage of protected areas in QLD to 30%.\n\n\n\n\nSpecies records pulled from GBIF, ALA, EcoPlots, OBIS\nSpecies distribution modelling output: Species distribution Probability maps (This is the input tested in this project).\n\n\n\n\n\nShapefile of planning area and units.\nShapefile of cost.\nShapefile and csv of biodiversity features (Where EcoCommons can help!).\n\n\n\n\nMake sure you are in the directory you want\n\ngetwd()\n\n[1] \"/Users/zhaoxiang/Documents/tmp/notebook-blog/sp_marxan\"\n\n# setwd(“/replace_this_with_your_actual_directory/ecocommons-marxan-integration-poc”)\n\nActivate the virtual environment “renv” to install and load all essential packages\n\n# install \"renv\" package if not been installed\nif (!requireNamespace(\"renv\", quietly = TRUE)) {\n  install.packages(\"renv\")\n}\n\nif (!file.exists(\"renv/activate.R\")) {\n   message(\"renv has not been initiated in this project. Initializing now...\")\n   renv::init()  # This initializes renv if it's not set up\n} else {\n   source(\"renv/activate.R\")  # This ensures the renv environment is activated\n   message(\"renv is activated.\")\n}\n\n# Ensure renv is installed and initialized\nif (file.exists(\"renv.lock\")) {\n  renv::restore()\n} else {\n  message(\"No renv.lock file found in the current directory.\")\n}\n\nInstall and load essential packages\n\n# Set CRAN mirror\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\n\n# First specify the packages of interest\npackages = c(\"shiny\", \"sf\", \"terra\", \"ggplot2\", \"ggspatial\", \"raster\", \"dplyr\", \"shiny\", \"httpuv\", \"rmarkdown\", \"knitr\", \"jsonlite\", \"reticulate\", \"htmltools\", \"pryr\")\n\n# Now load or install&load all. This process will take a long time since we are using a virtual environment and install a lot of packages.\npackage.check &lt;- lapply(\n  packages,\n  FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n      install.packages(x, dependencies = TRUE)\n      library(x, character.only = TRUE)\n     }\n  }\n )\n\n\nSys.setenv(PROJ_LIB = \"/usr/local/Cellar/proj/9.5.0/share/proj\")\n\nrenv::snapshot()\n\n1. We get the QLD planning units from Marxan MaPP\n\nQLD_Unit &lt;- \"qld_3species_Marxan/QLD_plannningunits/cost-surface-template.shp\"  #This cost-surface-template was prepared by the Marxan Mapp with a resolution of 189 Km2, which is the highest resolution Marxan Mapp can give at this scale.\n\nQLD_Unit  &lt;- st_read(QLD_Unit)\nQLD_Unit  &lt;- st_simplify(QLD_Unit , dTolerance = 0.01) \n\n\n# Calculate the resolution since Marxan MaPP for visulization purpose\nareas &lt;- st_area(QLD_Unit)\nareas_numeric &lt;- as.numeric(areas)\naverage_area &lt;- mean(areas_numeric)\n\n# Convert to numeric\naverage_area_km2 &lt;- average_area / 1e6\n\n# Get the number of rows\nn_rows &lt;- nrow(QLD_Unit)\n\n# Plot the shapefile with no fill color and number of rows in the title\nggplot(data = QLD_Unit) +\n  geom_sf(fill = NA, color = \"gray\") +\n  theme_minimal() +\n  ggtitle(paste(\"QLD Planning Units:\", n_rows, \"\\n\",\n                \"Resolution of planning in square kilometers:\", round(average_area_km2)))+\n  theme(plot.title = element_text(hjust = 0.5))  # Center the title\n\n\n\n\n\n\n\n\n2. I made a cost layer using the reciprocal of the distance to state-owned road as a surrogate of the cost.\nThe assumption is: the closer to the state owned road, the more expensive to purchase the unit.\n\nQLD_cost_road &lt;- st_read(\"qld_3species_Marxan/QLD_Cost/QLD_cost_road.shp\")\n\n# Plot the shapefile with continuous cost_road values\nggplot(QLD_cost_road) +\n  geom_sf(aes(fill = cost_road)) +\n  scale_fill_continuous(name = \"Cost\",\n                        low = \"lightblue\", high = \"red\",\n                        labels = c(\"0 (Low cost)\", \"1 (High cost)\"),\n                        breaks = c(0.01, 1)) +\n  theme_minimal() +\n  labs(title = \"Cost: using the distance to road of each Unit as a proxy\")+\n  theme(plot.title = element_text(hjust = 0.5))  # Center the title\n\n\n\n\n\n\n\n\n3. Biodiversity features. I used EcoCommons to produce three species’ SDM to start with.\n\nSpecies 1: koala\nSpecies 2: brush tailed rock-wallaby\nSpecies 3: beach stone curlew\n\n\n# Define the folder path where the rasters are stored\nfolder_path &lt;- \"qld_3species_Marxan/QLD_feature/\"\n\n# Get a list of all .tif files in the folder\nraster_files &lt;- list.files(path = folder_path, pattern = \"\\\\.tif$\", full.names = TRUE)\n\n# Extract the species names from the file names (removing the folder path and .tif extension)\nspecies_names &lt;- tools::file_path_sans_ext(basename(raster_files))\n\n# Read all raster files in one go using lapply\nraster_list &lt;- lapply(raster_files, rast)  # Use rast() from terra for reading rasters\n\n# Using QLD_Unit as the spatial vector for masking\n\n# Transform the raster CRS to match the vector CRS and apply masking in one step\nraster_list &lt;- lapply(raster_list, function(r) {\n  r_transformed &lt;- project(r, crs(vect(QLD_Unit)))\n  mask(r_transformed, vect(QLD_Unit))\n})\n\n# Function to convert rasters to data frames and combine them\nprepare_raster_data &lt;- function(raster_list, species_names) {\n\n  # Initialize an empty data frame\n  combined_df &lt;- data.frame()\n  # Loop through each raster and combine them into one data frame\n  for (i in seq_along(raster_list)) {\n    # Convert raster to a data frame\n    raster_df &lt;- as.data.frame(raster_list[[i]], xy = TRUE)\n    # Rename the third column to 'value' or any appropriate name for the raster values\n    names(raster_df)[3] &lt;- \"value\"\n    # Add a column to identify the species name\n    raster_df$species &lt;- species_names[i]\n    # Combine the raster data with the overall data frame\n    combined_df &lt;- bind_rows(combined_df, raster_df)\n}\n  return(combined_df)\n}\n\n# Prepare the combined data frame\ncombined_raster_df &lt;- prepare_raster_data(raster_list, species_names)\n\n# Create the ggplot with facet_wrap to display each raster in a separate facet\nggplot(combined_raster_df, aes(x = x, y = y, fill = value)) +  # Use the correct column name for fill\n  geom_raster()+\n  facet_wrap(~ species, ncol = 3) +  # Adjust ncol to control the number of columns\n  scale_fill_viridis_c() +  # You can adjust the color scale as needed\n  labs(title = \"Species SDM\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n4. We need to turn these SDMs to binary results (shapefies).\n\n# Define the folder paths where the rasters and CSV files are stored\nfolder_path_rasters &lt;- \"qld_3species_Marxan/QLD_feature/\"\nfolder_path_csvs &lt;- \"qld_3species_Marxan/model_evaluation/\"\noutput_dir &lt;- \"qld_3species_Marxan/QLD_feature/Marxan_feature_input/\"\n\nQLD_Unit &lt;- \"qld_3species_Marxan/QLD_plannningunits/cost-surface-template.shp\"  #This cost-surface-template was prepared by the Marxan Mapp with a resolution of 189 Km2, which is the highest resolution Marxan Mapp can give at this scale.\n\nQLD_Unit  &lt;- st_read(QLD_Unit)\nQLD_Unit  &lt;- st_simplify(QLD_Unit , dTolerance = 0.01) \n\n\n# Get a list of all .tif files and CSV files in the folder\nraster_files &lt;- list.files(path = folder_path_rasters, pattern = \"\\\\.tif$\", full.names = TRUE)\ncsv_files &lt;- list.files(path = folder_path_csvs, pattern = \"\\\\.csv$\", full.names = TRUE)\n\n# Extract the species names from the file names (removing the folder path and .tif/.csv extension)\nspecies_names &lt;- tools::file_path_sans_ext(basename(raster_files))\n\n# Read all raster files in one go using lapply\nraster_list &lt;- lapply(raster_files, rast)  # Use rast() from terra for reading rasters\n\n# Transform the raster CRS to match the vector CRS and apply masking in one step\nraster_list &lt;- lapply(raster_list, function(r) {\n  r_transformed &lt;- project(r, crs(vect(QLD_Unit)))\n  mask(r_transformed, vect(QLD_Unit))\n})\n\n# Prepare a named list of rasters\nspecies_rasters &lt;- setNames(raster_list, species_names)\nspecies_csvs &lt;- setNames(csv_files, species_names)\n\n# Define UI for the application\nui &lt;- fluidPage(\n  titlePanel(\"Interactive TSS-based threshold for the probability of presence and absence of Species\"),\n  \n  # Use a loop to create a row for each species\n  lapply(species_names, function(species) {\n    fluidRow(\n      column(3, \n             h4(paste(\"Species:\", species)),\n             sliderInput(paste0(\"tss_value_\", species), \n                         \"Select TSS Value:\", \n                         min = 0, max = 1, value = 0.5, step = 0.01),\n             actionButton(paste0(\"run_analysis_\", species), \"Run Species Analysis\"),\n             br(),\n             textOutput(paste0(\"tpr_tnr_\", species))\n      ),\n      \n      column(4, \n             plotOutput(paste0(\"plot_\", species), width = \"400px\")\n      ),\n      \n      column(5, \n             plotOutput(paste0(\"species_plot_\", species))\n      )\n    )\n  })\n)\n\n# Define server logic\nserver &lt;- function(input, output, session) {\n  \n  selected_raster &lt;- function(species) {\n    species_rasters[[species]]\n  }\n  \n  species_eval_data &lt;- function(species) {\n    csv_path &lt;- species_csvs[[species]]\n    \n    if (!file.exists(csv_path)) {\n      showNotification(paste(\"CSV file for\", species, \"not found!\"), type = \"error\")\n      return(NULL)\n    }\n    \n    eval_data &lt;- read.csv(csv_path)\n    \n    if (!all(c(\"tpr\", \"tnr\", \"tpv\") %in% names(eval_data))) {\n      showNotification(paste(\"Required columns missing in CSV for\", species), type = \"error\")\n      return(NULL)\n    }\n    \n    if (nrow(eval_data) == 0) {\n      showNotification(paste(\"No data found in CSV for\", species), type = \"error\")\n      return(NULL)\n    }\n    \n    eval_data$tss &lt;- round(eval_data$tpr + eval_data$tnr - 1, 3)\n    return(eval_data)\n  }\n  \n  lapply(species_names, function(species) {\n    eval_data &lt;- species_eval_data(species)\n    \n    if (!is.null(eval_data)) {\n      min_tss &lt;- min(eval_data$tss, na.rm = TRUE)\n      max_tss &lt;- max(eval_data$tss, na.rm = TRUE)\n      \n      updateSliderInput(session, paste0(\"tss_value_\", species), \n                        min = min_tss, \n                        max = max_tss, \n                        value = max_tss,\n                        step = 0.01)\n    }\n    \n    observeEvent(input[[paste0(\"tss_value_\", species)]], {\n      if (!is.null(eval_data)) {\n        row &lt;- which.min(abs(eval_data$tss - input[[paste0(\"tss_value_\", species)]]))\n        \n        tpr &lt;- eval_data$tpr[row]\n        tnr &lt;- eval_data$tnr[row]\n        \n        output[[paste0(\"tpr_tnr_\", species)]] &lt;- renderText({\n          paste0(\"TPR (Sensitivity): \", round(tpr, 3), \n                 \", TNR (Specificity): \", round(tnr, 3))\n        })\n      }\n    })\n    \n    output[[paste0(\"plot_\", species)]] &lt;- renderPlot({\n      if (is.null(eval_data)) return(NULL)\n      \n      ggplot(eval_data, aes(x = tpv)) +\n        geom_line(aes(y = tpr, colour = \"TPR\"), linewidth = 1) +\n        geom_line(aes(y = tnr, colour = \"TNR\"), linewidth = 1) +\n        geom_line(aes(y = tss, colour = \"TSS\"), linewidth = 1) +\n        geom_vline(xintercept = eval_data$tpv[which.min(abs(eval_data$tss - input[[paste0(\"tss_value_\", species)]]))],\n                   linetype = \"dotted\", color = \"red\", linewidth = 1) +\n        labs(title = paste(\"Sensitivity, Specificity, and TSS for\", species),\n             x = \"Threshold Probability Value\",\n             y = \"Value\") +\n        scale_colour_manual(values = c(\"TPR\" = \"blue\", \"TNR\" = \"green\", \"TSS\" = \"red\")) +\n        theme_minimal()\n    })\n    \n    observeEvent(input[[paste0(\"run_analysis_\", species)]], {\n      species_shp &lt;- process_species(selected_raster(species), QLD_Unit, species, output_dir, input[[paste0(\"tss_value_\", species)]])\n      \n      output[[paste0(\"species_plot_\", species)]] &lt;- renderPlot({\n        ggplot() +\n          geom_sf(data = QLD_Unit, fill = NA, color = \"grey\") +\n          geom_sf(data = species_shp, aes(fill = feature), color = NA) +\n          scale_fill_viridis_c(option = \"plasma\") +\n          labs(title = paste(\"Species Distribution for\", species),\n               x = \"Longitude\", y = \"Latitude\") +\n          theme_minimal()\n      })\n    })\n  })\n}\n\nprocess_species &lt;- function(raster_data, planning_unit, species_name, output_dir, tss_threshold) {\n  raster_data_transformed &lt;- project(raster_data, crs(vect(planning_unit)))\n  extracted_values &lt;- extract(raster_data_transformed, vect(planning_unit), fun = mean, na.rm = TRUE)\n  names(planning_unit)[names(planning_unit) == \"cost\"] &lt;- \"feature\"\n  planning_unit$feature &lt;- extracted_values[, 2]\n  \n  QLD_species &lt;- subset(planning_unit, feature &gt;= tss_threshold)\n  shapefile_base &lt;- file.path(output_dir, species_name)\n  st_write(QLD_species, paste0(shapefile_base, \".shp\"), delete_layer = TRUE)\n  \n  return(QLD_species)\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)\n\n5. Plot species SDM binary shapefile outputs for double check\n\noutput_dir &lt;- \"qld_3species_Marxan/QLD_feature/Marxan_feature_input/\"\n\n# List all the shapefiles in the directory (assuming each species has its own shapefile)\nspecies_files &lt;- list.files(output_dir, pattern = \"\\\\.shp$\", full.names = TRUE)\n\nspecies_files\n\n# Extract species names from the filenames (you can adjust this depending on your naming conventions)\nspecies_names &lt;- tools::file_path_sans_ext(basename(species_files))\n\n# Load all species shapefiles and add a species identifier\nspecies_sf_list &lt;- lapply(seq_along(species_files), function(i) {\n  sf &lt;- st_read(species_files[i])\n  sf$species &lt;- species_names[i]  # Add species name column\n  return(sf)\n})\n\n# Combine all species into one dataset\ncombined_species_sf &lt;- do.call(rbind, species_sf_list)\n\n# Plot the unit (base map) first and overlay the species habitats without borders\ncombined_plot_with_unit &lt;- ggplot() +\n  geom_sf(data = QLD_Unit, fill = NA, color = \"grey\", linewidth = 0.01) +  # Base map (QLD Unit)\n  geom_sf(data = combined_species_sf, aes(fill = species), color = NA) +  # No borders for species\n  scale_fill_manual(values = RColorBrewer::brewer.pal(n = length(species_names), name = \"Set1\")) +  # Automatically assign colors\n  theme_minimal() +\n  labs(title = \"Species Habitats within QLD Unit\",\n       subtitle = paste(species_names, collapse = \", \")) +  # List all species in subtitle\n  theme(legend.title = element_blank())\n\n# Display the plot\nprint(combined_plot_with_unit)\n\n\n\n\n\n\n\n\n6. We can also make a species presence and absence csv table.\n\n# Function to extract presence (1) and absence (0) from raster based on a threshold (e.g., 0.5)\n\nextract_presence_absence &lt;- function(raster_data, unit) {\n  extracted_values &lt;- extract(raster_data, vect(unit), fun = mean, na.rm = TRUE)\n  presence_absence &lt;- ifelse(extracted_values[, 2] &gt;= 0.5, 1, 0)\n  return(presence_absence)\n}\n\n# Create an empty presence-absence data frame\npresence_absence_df &lt;- data.frame(puid = QLD_Unit$puid)  # Assuming 'puid' is the unique identifier\n\n# Loop through each species raster in the raster list and extract presence-absence data\nfor (i in seq_along(raster_list)) {\n  # Generate a dynamic presence column name for the current species\n  presence_col_name &lt;- paste0(species_names[i], \"_presence\")\n  \n  # Extract presence/absence data and add it to the presence-absence dataframe\n  presence_absence_df[[species_names[i]]] &lt;- extract_presence_absence(raster_list[[i]], QLD_Unit)\n}\n\n# Write the final presence-absence data frame to a CSV file\noutput_csv &lt;- file.path(output_dir, \"presence_absence_species.csv\")\nwrite.csv(presence_absence_df, output_csv, row.names = FALSE)\n\n# Check the CSV output\nprint(head(presence_absence_df))\n\n  puid beach_stone_curlew_GLM brushtailed_rockwallaby_GLM Koala_GLM\n1    1                      0                           0         0\n2    2                      0                           0         0\n3    3                      0                           0         0\n4    4                      0                           0         0\n5    5                      0                           0         0\n6    6                      0                           0         0\n\n\n\n\n\n\n\n\n\n\nEcoCommons SDMs output of three species on Marxan MaPP\n\n\n\n\n\n\n\n\nNo Costs, neither SDMs\n\n\n\n\n\n\n\n\nSDMs only\n\n\n\n\n\n\n\n\nCosts only\n\n\n\n\n\n\n\n\nCosts and SDMs"
  },
  {
    "objectID": "sp_marxan/ecocommons-marxan-integration-poc.html#introduction",
    "href": "sp_marxan/ecocommons-marxan-integration-poc.html#introduction",
    "title": "EcoCommons Marxan MaPP connection",
    "section": "",
    "text": "Using the Species distribution modeling techniques provided by the EcoCommons Platform (www.ecocommons.org.au), we produced probability distribution maps for the three Queensland endangered species: koala, brush tailed rock-wallaby, and beach stone curlew.\nThen we adjusted the probability distribution maps of these three species with the planning units shapefile prepared by the Marxan MaPP, and ran four planning scenarios with a target of expanding the coverage of protected areas in QLD to 30%."
  },
  {
    "objectID": "sp_marxan/ecocommons-marxan-integration-poc.html#ecocommons-outputs",
    "href": "sp_marxan/ecocommons-marxan-integration-poc.html#ecocommons-outputs",
    "title": "EcoCommons Marxan MaPP connection",
    "section": "",
    "text": "Species records pulled from GBIF, ALA, EcoPlots, OBIS\nSpecies distribution modelling output: Species distribution Probability maps (This is the input tested in this project)."
  },
  {
    "objectID": "sp_marxan/ecocommons-marxan-integration-poc.html#marxan-mapp-inputs",
    "href": "sp_marxan/ecocommons-marxan-integration-poc.html#marxan-mapp-inputs",
    "title": "EcoCommons Marxan MaPP connection",
    "section": "",
    "text": "Shapefile of planning area and units.\nShapefile of cost.\nShapefile and csv of biodiversity features (Where EcoCommons can help!)."
  },
  {
    "objectID": "sp_marxan/ecocommons-marxan-integration-poc.html#ecocommons-connects-with-marxan-showcase",
    "href": "sp_marxan/ecocommons-marxan-integration-poc.html#ecocommons-connects-with-marxan-showcase",
    "title": "EcoCommons Marxan MaPP connection",
    "section": "",
    "text": "Make sure you are in the directory you want\n\ngetwd()\n\n[1] \"/Users/zhaoxiang/Documents/tmp/notebook-blog/sp_marxan\"\n\n# setwd(“/replace_this_with_your_actual_directory/ecocommons-marxan-integration-poc”)\n\nActivate the virtual environment “renv” to install and load all essential packages\n\n# install \"renv\" package if not been installed\nif (!requireNamespace(\"renv\", quietly = TRUE)) {\n  install.packages(\"renv\")\n}\n\nif (!file.exists(\"renv/activate.R\")) {\n   message(\"renv has not been initiated in this project. Initializing now...\")\n   renv::init()  # This initializes renv if it's not set up\n} else {\n   source(\"renv/activate.R\")  # This ensures the renv environment is activated\n   message(\"renv is activated.\")\n}\n\n# Ensure renv is installed and initialized\nif (file.exists(\"renv.lock\")) {\n  renv::restore()\n} else {\n  message(\"No renv.lock file found in the current directory.\")\n}\n\nInstall and load essential packages\n\n# Set CRAN mirror\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\n\n# First specify the packages of interest\npackages = c(\"shiny\", \"sf\", \"terra\", \"ggplot2\", \"ggspatial\", \"raster\", \"dplyr\", \"shiny\", \"httpuv\", \"rmarkdown\", \"knitr\", \"jsonlite\", \"reticulate\", \"htmltools\", \"pryr\")\n\n# Now load or install&load all. This process will take a long time since we are using a virtual environment and install a lot of packages.\npackage.check &lt;- lapply(\n  packages,\n  FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n      install.packages(x, dependencies = TRUE)\n      library(x, character.only = TRUE)\n     }\n  }\n )\n\n\nSys.setenv(PROJ_LIB = \"/usr/local/Cellar/proj/9.5.0/share/proj\")\n\nrenv::snapshot()\n\n1. We get the QLD planning units from Marxan MaPP\n\nQLD_Unit &lt;- \"qld_3species_Marxan/QLD_plannningunits/cost-surface-template.shp\"  #This cost-surface-template was prepared by the Marxan Mapp with a resolution of 189 Km2, which is the highest resolution Marxan Mapp can give at this scale.\n\nQLD_Unit  &lt;- st_read(QLD_Unit)\nQLD_Unit  &lt;- st_simplify(QLD_Unit , dTolerance = 0.01) \n\n\n# Calculate the resolution since Marxan MaPP for visulization purpose\nareas &lt;- st_area(QLD_Unit)\nareas_numeric &lt;- as.numeric(areas)\naverage_area &lt;- mean(areas_numeric)\n\n# Convert to numeric\naverage_area_km2 &lt;- average_area / 1e6\n\n# Get the number of rows\nn_rows &lt;- nrow(QLD_Unit)\n\n# Plot the shapefile with no fill color and number of rows in the title\nggplot(data = QLD_Unit) +\n  geom_sf(fill = NA, color = \"gray\") +\n  theme_minimal() +\n  ggtitle(paste(\"QLD Planning Units:\", n_rows, \"\\n\",\n                \"Resolution of planning in square kilometers:\", round(average_area_km2)))+\n  theme(plot.title = element_text(hjust = 0.5))  # Center the title\n\n\n\n\n\n\n\n\n2. I made a cost layer using the reciprocal of the distance to state-owned road as a surrogate of the cost.\nThe assumption is: the closer to the state owned road, the more expensive to purchase the unit.\n\nQLD_cost_road &lt;- st_read(\"qld_3species_Marxan/QLD_Cost/QLD_cost_road.shp\")\n\n# Plot the shapefile with continuous cost_road values\nggplot(QLD_cost_road) +\n  geom_sf(aes(fill = cost_road)) +\n  scale_fill_continuous(name = \"Cost\",\n                        low = \"lightblue\", high = \"red\",\n                        labels = c(\"0 (Low cost)\", \"1 (High cost)\"),\n                        breaks = c(0.01, 1)) +\n  theme_minimal() +\n  labs(title = \"Cost: using the distance to road of each Unit as a proxy\")+\n  theme(plot.title = element_text(hjust = 0.5))  # Center the title\n\n\n\n\n\n\n\n\n3. Biodiversity features. I used EcoCommons to produce three species’ SDM to start with.\n\nSpecies 1: koala\nSpecies 2: brush tailed rock-wallaby\nSpecies 3: beach stone curlew\n\n\n# Define the folder path where the rasters are stored\nfolder_path &lt;- \"qld_3species_Marxan/QLD_feature/\"\n\n# Get a list of all .tif files in the folder\nraster_files &lt;- list.files(path = folder_path, pattern = \"\\\\.tif$\", full.names = TRUE)\n\n# Extract the species names from the file names (removing the folder path and .tif extension)\nspecies_names &lt;- tools::file_path_sans_ext(basename(raster_files))\n\n# Read all raster files in one go using lapply\nraster_list &lt;- lapply(raster_files, rast)  # Use rast() from terra for reading rasters\n\n# Using QLD_Unit as the spatial vector for masking\n\n# Transform the raster CRS to match the vector CRS and apply masking in one step\nraster_list &lt;- lapply(raster_list, function(r) {\n  r_transformed &lt;- project(r, crs(vect(QLD_Unit)))\n  mask(r_transformed, vect(QLD_Unit))\n})\n\n# Function to convert rasters to data frames and combine them\nprepare_raster_data &lt;- function(raster_list, species_names) {\n\n  # Initialize an empty data frame\n  combined_df &lt;- data.frame()\n  # Loop through each raster and combine them into one data frame\n  for (i in seq_along(raster_list)) {\n    # Convert raster to a data frame\n    raster_df &lt;- as.data.frame(raster_list[[i]], xy = TRUE)\n    # Rename the third column to 'value' or any appropriate name for the raster values\n    names(raster_df)[3] &lt;- \"value\"\n    # Add a column to identify the species name\n    raster_df$species &lt;- species_names[i]\n    # Combine the raster data with the overall data frame\n    combined_df &lt;- bind_rows(combined_df, raster_df)\n}\n  return(combined_df)\n}\n\n# Prepare the combined data frame\ncombined_raster_df &lt;- prepare_raster_data(raster_list, species_names)\n\n# Create the ggplot with facet_wrap to display each raster in a separate facet\nggplot(combined_raster_df, aes(x = x, y = y, fill = value)) +  # Use the correct column name for fill\n  geom_raster()+\n  facet_wrap(~ species, ncol = 3) +  # Adjust ncol to control the number of columns\n  scale_fill_viridis_c() +  # You can adjust the color scale as needed\n  labs(title = \"Species SDM\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n4. We need to turn these SDMs to binary results (shapefies).\n\n# Define the folder paths where the rasters and CSV files are stored\nfolder_path_rasters &lt;- \"qld_3species_Marxan/QLD_feature/\"\nfolder_path_csvs &lt;- \"qld_3species_Marxan/model_evaluation/\"\noutput_dir &lt;- \"qld_3species_Marxan/QLD_feature/Marxan_feature_input/\"\n\nQLD_Unit &lt;- \"qld_3species_Marxan/QLD_plannningunits/cost-surface-template.shp\"  #This cost-surface-template was prepared by the Marxan Mapp with a resolution of 189 Km2, which is the highest resolution Marxan Mapp can give at this scale.\n\nQLD_Unit  &lt;- st_read(QLD_Unit)\nQLD_Unit  &lt;- st_simplify(QLD_Unit , dTolerance = 0.01) \n\n\n# Get a list of all .tif files and CSV files in the folder\nraster_files &lt;- list.files(path = folder_path_rasters, pattern = \"\\\\.tif$\", full.names = TRUE)\ncsv_files &lt;- list.files(path = folder_path_csvs, pattern = \"\\\\.csv$\", full.names = TRUE)\n\n# Extract the species names from the file names (removing the folder path and .tif/.csv extension)\nspecies_names &lt;- tools::file_path_sans_ext(basename(raster_files))\n\n# Read all raster files in one go using lapply\nraster_list &lt;- lapply(raster_files, rast)  # Use rast() from terra for reading rasters\n\n# Transform the raster CRS to match the vector CRS and apply masking in one step\nraster_list &lt;- lapply(raster_list, function(r) {\n  r_transformed &lt;- project(r, crs(vect(QLD_Unit)))\n  mask(r_transformed, vect(QLD_Unit))\n})\n\n# Prepare a named list of rasters\nspecies_rasters &lt;- setNames(raster_list, species_names)\nspecies_csvs &lt;- setNames(csv_files, species_names)\n\n# Define UI for the application\nui &lt;- fluidPage(\n  titlePanel(\"Interactive TSS-based threshold for the probability of presence and absence of Species\"),\n  \n  # Use a loop to create a row for each species\n  lapply(species_names, function(species) {\n    fluidRow(\n      column(3, \n             h4(paste(\"Species:\", species)),\n             sliderInput(paste0(\"tss_value_\", species), \n                         \"Select TSS Value:\", \n                         min = 0, max = 1, value = 0.5, step = 0.01),\n             actionButton(paste0(\"run_analysis_\", species), \"Run Species Analysis\"),\n             br(),\n             textOutput(paste0(\"tpr_tnr_\", species))\n      ),\n      \n      column(4, \n             plotOutput(paste0(\"plot_\", species), width = \"400px\")\n      ),\n      \n      column(5, \n             plotOutput(paste0(\"species_plot_\", species))\n      )\n    )\n  })\n)\n\n# Define server logic\nserver &lt;- function(input, output, session) {\n  \n  selected_raster &lt;- function(species) {\n    species_rasters[[species]]\n  }\n  \n  species_eval_data &lt;- function(species) {\n    csv_path &lt;- species_csvs[[species]]\n    \n    if (!file.exists(csv_path)) {\n      showNotification(paste(\"CSV file for\", species, \"not found!\"), type = \"error\")\n      return(NULL)\n    }\n    \n    eval_data &lt;- read.csv(csv_path)\n    \n    if (!all(c(\"tpr\", \"tnr\", \"tpv\") %in% names(eval_data))) {\n      showNotification(paste(\"Required columns missing in CSV for\", species), type = \"error\")\n      return(NULL)\n    }\n    \n    if (nrow(eval_data) == 0) {\n      showNotification(paste(\"No data found in CSV for\", species), type = \"error\")\n      return(NULL)\n    }\n    \n    eval_data$tss &lt;- round(eval_data$tpr + eval_data$tnr - 1, 3)\n    return(eval_data)\n  }\n  \n  lapply(species_names, function(species) {\n    eval_data &lt;- species_eval_data(species)\n    \n    if (!is.null(eval_data)) {\n      min_tss &lt;- min(eval_data$tss, na.rm = TRUE)\n      max_tss &lt;- max(eval_data$tss, na.rm = TRUE)\n      \n      updateSliderInput(session, paste0(\"tss_value_\", species), \n                        min = min_tss, \n                        max = max_tss, \n                        value = max_tss,\n                        step = 0.01)\n    }\n    \n    observeEvent(input[[paste0(\"tss_value_\", species)]], {\n      if (!is.null(eval_data)) {\n        row &lt;- which.min(abs(eval_data$tss - input[[paste0(\"tss_value_\", species)]]))\n        \n        tpr &lt;- eval_data$tpr[row]\n        tnr &lt;- eval_data$tnr[row]\n        \n        output[[paste0(\"tpr_tnr_\", species)]] &lt;- renderText({\n          paste0(\"TPR (Sensitivity): \", round(tpr, 3), \n                 \", TNR (Specificity): \", round(tnr, 3))\n        })\n      }\n    })\n    \n    output[[paste0(\"plot_\", species)]] &lt;- renderPlot({\n      if (is.null(eval_data)) return(NULL)\n      \n      ggplot(eval_data, aes(x = tpv)) +\n        geom_line(aes(y = tpr, colour = \"TPR\"), linewidth = 1) +\n        geom_line(aes(y = tnr, colour = \"TNR\"), linewidth = 1) +\n        geom_line(aes(y = tss, colour = \"TSS\"), linewidth = 1) +\n        geom_vline(xintercept = eval_data$tpv[which.min(abs(eval_data$tss - input[[paste0(\"tss_value_\", species)]]))],\n                   linetype = \"dotted\", color = \"red\", linewidth = 1) +\n        labs(title = paste(\"Sensitivity, Specificity, and TSS for\", species),\n             x = \"Threshold Probability Value\",\n             y = \"Value\") +\n        scale_colour_manual(values = c(\"TPR\" = \"blue\", \"TNR\" = \"green\", \"TSS\" = \"red\")) +\n        theme_minimal()\n    })\n    \n    observeEvent(input[[paste0(\"run_analysis_\", species)]], {\n      species_shp &lt;- process_species(selected_raster(species), QLD_Unit, species, output_dir, input[[paste0(\"tss_value_\", species)]])\n      \n      output[[paste0(\"species_plot_\", species)]] &lt;- renderPlot({\n        ggplot() +\n          geom_sf(data = QLD_Unit, fill = NA, color = \"grey\") +\n          geom_sf(data = species_shp, aes(fill = feature), color = NA) +\n          scale_fill_viridis_c(option = \"plasma\") +\n          labs(title = paste(\"Species Distribution for\", species),\n               x = \"Longitude\", y = \"Latitude\") +\n          theme_minimal()\n      })\n    })\n  })\n}\n\nprocess_species &lt;- function(raster_data, planning_unit, species_name, output_dir, tss_threshold) {\n  raster_data_transformed &lt;- project(raster_data, crs(vect(planning_unit)))\n  extracted_values &lt;- extract(raster_data_transformed, vect(planning_unit), fun = mean, na.rm = TRUE)\n  names(planning_unit)[names(planning_unit) == \"cost\"] &lt;- \"feature\"\n  planning_unit$feature &lt;- extracted_values[, 2]\n  \n  QLD_species &lt;- subset(planning_unit, feature &gt;= tss_threshold)\n  shapefile_base &lt;- file.path(output_dir, species_name)\n  st_write(QLD_species, paste0(shapefile_base, \".shp\"), delete_layer = TRUE)\n  \n  return(QLD_species)\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)\n\n5. Plot species SDM binary shapefile outputs for double check\n\noutput_dir &lt;- \"qld_3species_Marxan/QLD_feature/Marxan_feature_input/\"\n\n# List all the shapefiles in the directory (assuming each species has its own shapefile)\nspecies_files &lt;- list.files(output_dir, pattern = \"\\\\.shp$\", full.names = TRUE)\n\nspecies_files\n\n# Extract species names from the filenames (you can adjust this depending on your naming conventions)\nspecies_names &lt;- tools::file_path_sans_ext(basename(species_files))\n\n# Load all species shapefiles and add a species identifier\nspecies_sf_list &lt;- lapply(seq_along(species_files), function(i) {\n  sf &lt;- st_read(species_files[i])\n  sf$species &lt;- species_names[i]  # Add species name column\n  return(sf)\n})\n\n# Combine all species into one dataset\ncombined_species_sf &lt;- do.call(rbind, species_sf_list)\n\n# Plot the unit (base map) first and overlay the species habitats without borders\ncombined_plot_with_unit &lt;- ggplot() +\n  geom_sf(data = QLD_Unit, fill = NA, color = \"grey\", linewidth = 0.01) +  # Base map (QLD Unit)\n  geom_sf(data = combined_species_sf, aes(fill = species), color = NA) +  # No borders for species\n  scale_fill_manual(values = RColorBrewer::brewer.pal(n = length(species_names), name = \"Set1\")) +  # Automatically assign colors\n  theme_minimal() +\n  labs(title = \"Species Habitats within QLD Unit\",\n       subtitle = paste(species_names, collapse = \", \")) +  # List all species in subtitle\n  theme(legend.title = element_blank())\n\n# Display the plot\nprint(combined_plot_with_unit)\n\n\n\n\n\n\n\n\n6. We can also make a species presence and absence csv table.\n\n# Function to extract presence (1) and absence (0) from raster based on a threshold (e.g., 0.5)\n\nextract_presence_absence &lt;- function(raster_data, unit) {\n  extracted_values &lt;- extract(raster_data, vect(unit), fun = mean, na.rm = TRUE)\n  presence_absence &lt;- ifelse(extracted_values[, 2] &gt;= 0.5, 1, 0)\n  return(presence_absence)\n}\n\n# Create an empty presence-absence data frame\npresence_absence_df &lt;- data.frame(puid = QLD_Unit$puid)  # Assuming 'puid' is the unique identifier\n\n# Loop through each species raster in the raster list and extract presence-absence data\nfor (i in seq_along(raster_list)) {\n  # Generate a dynamic presence column name for the current species\n  presence_col_name &lt;- paste0(species_names[i], \"_presence\")\n  \n  # Extract presence/absence data and add it to the presence-absence dataframe\n  presence_absence_df[[species_names[i]]] &lt;- extract_presence_absence(raster_list[[i]], QLD_Unit)\n}\n\n# Write the final presence-absence data frame to a CSV file\noutput_csv &lt;- file.path(output_dir, \"presence_absence_species.csv\")\nwrite.csv(presence_absence_df, output_csv, row.names = FALSE)\n\n# Check the CSV output\nprint(head(presence_absence_df))\n\n  puid beach_stone_curlew_GLM brushtailed_rockwallaby_GLM Koala_GLM\n1    1                      0                           0         0\n2    2                      0                           0         0\n3    3                      0                           0         0\n4    4                      0                           0         0\n5    5                      0                           0         0\n6    6                      0                           0         0"
  },
  {
    "objectID": "sp_marxan/ecocommons-marxan-integration-poc.html#marxan-four-scenarios-solutions",
    "href": "sp_marxan/ecocommons-marxan-integration-poc.html#marxan-four-scenarios-solutions",
    "title": "EcoCommons Marxan MaPP connection",
    "section": "",
    "text": "EcoCommons SDMs output of three species on Marxan MaPP\n\n\n\n\n\n\n\n\nNo Costs, neither SDMs\n\n\n\n\n\n\n\n\nSDMs only\n\n\n\n\n\n\n\n\nCosts only\n\n\n\n\n\n\n\n\nCosts and SDMs"
  },
  {
    "objectID": "EC_GLM.html#s.1-set-the-working-directory-and-create-a-folder-for-data.",
    "href": "EC_GLM.html#s.1-set-the-working-directory-and-create-a-folder-for-data.",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "S.1 Set the working directory and create a folder for data.",
    "text": "S.1 Set the working directory and create a folder for data.\nSave the Quarto Markdown file (.QMD) to a folder of your choice, and then set the path to your folder as your working directory.\n\n# Set the workspace to the current working directory\n# Uncomment and replace the path below with your own working directory if needed:\n# setwd(\"/Users/zhaoxiang/Documents/tmp/EC_GLM_notebook\") \n\nworkspace &lt;- getwd()  # Get the current working directory and store it in 'workspace'\n\n# Increase the plot size by adjusting the options for plot dimensions in the notebook output\noptions(repr.plot.width = 16, repr.plot.height = 8)  # Sets width to 16 and height to 8 for larger plots\n\nIdeally, you would use the renv package to create an isolated environment for installing all the required R packages used in this notebook. However, since installing renv and its dependencies can be time-consuming, we recommend trying this after the workshop.\n\n# # Ensure \"renv\" package is installed\n# if (!requireNamespace(\"renv\", quietly = TRUE)) {\n#   install.packages(\"renv\")\n# }\n# \n# # Check if renv has been initialized in the project\n# if (!file.exists(\"renv/activate.R\")) {\n#   message(\"renv has not been initiated in this project. Initializing now...\")\n#   renv::init()  # Initialize renv if not already set up\n# } else {\n#   source(\"renv/activate.R\")  # Activate the renv environment\n#   message(\"renv is activated.\")\n# }\n# \n# # Check for the existence of renv.lock and restore the environment\n# if (file.exists(\"renv.lock\")) {\n#   message(\"Restoring renv environment from renv.lock...\")\n#   renv::restore()\n# } else {\n#   message(\"No renv.lock file found in the current directory. Skipping restore.\")\n# }"
  },
  {
    "objectID": "EC_GLM.html#s.2-install-and-load-essential-libraries.",
    "href": "EC_GLM.html#s.2-install-and-load-essential-libraries.",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "S.2 Install and load essential libraries.",
    "text": "S.2 Install and load essential libraries.\nInstall and load R packages.\n\n# Set CRAN mirror\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\n\n# List of packages to check, install if needed, and load\npackages &lt;- c(\"dplyr\", \"terra\", \"sf\", \"googledrive\", \"ggplot2\", \"corrplot\", \"pROC\", \"dismo\", \"spatstat.geom\", \"patchwork\", \"biomod2\", \"leaflet\", \"car\", \"gridExtra\", \"htmltools\", \"RColorBrewer\")\n\n# Function to display a cat message\ncat_message &lt;- function(pkg, message_type) {\n  if (message_type == \"installed\") {\n    cat(paste0(pkg, \" has been installed successfully!\\n\"))\n  } else if (message_type == \"loading\") {\n    cat(paste0(pkg, \" is already installed and has been loaded!\\n\"))\n  }\n}\n\n# Install missing packages and load them\nfor (pkg in packages) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg)\n    cat_message(pkg, \"installed\")\n  } else {\n    cat_message(pkg, \"loading\")\n  }\n  library(pkg, character.only = TRUE)\n}\n\ndplyr is already installed and has been loaded!\n\n\nterra is already installed and has been loaded!\n\n\nsf is already installed and has been loaded!\n\n\ngoogledrive is already installed and has been loaded!\nggplot2 is already installed and has been loaded!\ncorrplot is already installed and has been loaded!\n\n\npROC is already installed and has been loaded!\n\n\ndismo is already installed and has been loaded!\n\n\nspatstat.geom is already installed and has been loaded!\n\n\npatchwork is already installed and has been loaded!\n\n\nbiomod2 is already installed and has been loaded!\n\n\nleaflet is already installed and has been loaded!\ncar is already installed and has been loaded!\n\n\ngridExtra is already installed and has been loaded!\n\n\nhtmltools is already installed and has been loaded!\nRColorBrewer is already installed and has been loaded!\n\n# If you are using renv, you can snapshot the renv after loading all the packages.\n\n#renv::snapshot()"
  },
  {
    "objectID": "EC_GLM.html#s.3-download-case-study-datasets",
    "href": "EC_GLM.html#s.3-download-case-study-datasets",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "S.3 Download case study datasets",
    "text": "S.3 Download case study datasets\nWe have prepared the following data and uploaded them to our Google Drive for your use:\n\nSpecies occurrence data: Shapefile format (.shp)\nEnvironmental variables: Stacked Raster format (.tif)\nStudy area boundary: Shapefile format (.shp)\n\n\n# De-authenticate Google Drive to access public files\ndrive_deauth()\n\n# Define Google Drive file ID and the path for downloading\nzip_file_id &lt;- \"1twKlNokB7t33QH2KesH7BHYffp5kvoiP\" # Replace with the actual file ID of the zipped file\ndatafolder_path &lt;- file.path(workspace)\n\n# Create a local path for the zipped file\nzip_file_path &lt;- file.path(datafolder_path, \"mountain_ash_centralhighlands_data.zip\")\n\n# Function to download a file with progress messages\ndownload_zip_file &lt;- function(file_id, file_path) {\n  cat(\"Downloading zipped file...\\n\")\n  drive_download(as_id(file_id), path = file_path, overwrite = TRUE)\n  cat(\"Downloaded zipped file to:\", file_path, \"\\n\")\n}\n\n# Create local directory if it doesn't exist\nif (!dir.exists(datafolder_path)) {\n  dir.create(datafolder_path, recursive = TRUE)\n}\n\n# Download the zipped file\ncat(\"Starting to download the zipped file...\\n\")\n\nStarting to download the zipped file...\n\ndownload_zip_file(zip_file_id, zip_file_path)\n\nDownloading zipped file...\n\n\nFile downloaded:\n\n\n• 'mountain_ash_centralhighlands-20241204T022054Z-001.zip'\n  &lt;id: 1twKlNokB7t33QH2KesH7BHYffp5kvoiP&gt;\n\n\nSaved locally as:\n\n\n• '/Users/zhaoxiang/Documents/tmp/notebook-blog/mountain_ash_centralhighlands_data.zip'\n\n\nDownloaded zipped file to: /Users/zhaoxiang/Documents/tmp/notebook-blog/mountain_ash_centralhighlands_data.zip \n\n# Unzip the downloaded file\ncat(\"Unzipping the file...\\n\")\n\nUnzipping the file...\n\nunzip(zip_file_path, exdir = datafolder_path)\ncat(\"Unzipped files to folder:\", datafolder_path, \"\\n\")\n\nUnzipped files to folder: /Users/zhaoxiang/Documents/tmp/notebook-blog"
  },
  {
    "objectID": "EC_GLM.html#taxon-location-data-and-scale",
    "href": "EC_GLM.html#taxon-location-data-and-scale",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "1.1 Taxon, location, data and scale",
    "text": "1.1 Taxon, location, data and scale\nTaxon: Mountain Ash (Eucalyptus regnans)\n\nPhotographer: Reiner Richter, ALA\nMountain Ash (Eucalyptus regnans), is a remarkably tall and straight tree native to Victoria and Tasmania. This species thrives in cool, temperate rainforests characterized by high rainfall, deep, well-drained soils, mild temperatures, and high humidity. It is typically found at altitudes ranging from 200 to 1,000 meters above sea level (Burns et al., 2015).\nThe Mountain Ash faces two main forms of disturbance: bushfires, which are its primary natural disturbance, and logging, which represents the primary human-induced threat to its habitat (Burns et al., 2015; Nevill et al., 2010).\nLocation: the Central Highlands (study area) in the south part of Victoria\nSpatial and temporal scales: small (spatial) and static (temporal)\n\n# Load your shapefiles\ncentral_highlands &lt;- st_read(\"mountain_ash_centralhighlands/central_highlands.shp\")\n\nReading layer `central_highlands' from data source \n  `/Users/zhaoxiang/Documents/tmp/notebook-blog/mountain_ash_centralhighlands/central_highlands.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 144.9398 ymin: -38.20964 xmax: 146.4563 ymax: -36.97746\nGeodetic CRS:  GDA94\n\n# Custom CSS for a smaller legend box\ncustom_css &lt;- tags$style(HTML(\"\n  .leaflet-control .legend {\n    font-size: 8px !important; /* Reduce font size */\n    padding: 4px; /* Reduce padding inside the legend box */\n    line-height: 1; /* Reduce spacing between lines */\n    width: auto; /* Automatically size the legend box */\n    height: auto; /* Automatically size the legend box */\n  }\n  .leaflet-control .legend i {\n    width: 10px; /* Smaller legend icons */\n    height: 10px;\n  }\n\"))\n\n# Render the map\nleaflet() %&gt;%\n  addProviderTiles(providers$Esri.WorldImagery) %&gt;%\n  # Add the Central Highlands layer with a distinct color\n  addPolygons(\n    data = central_highlands,\n    color = \"lightblue\",         # Border color of Central Highlands polygon\n    weight = 1,                  # Border width\n    fillColor = \"lightblue\",     # Fill color of Central Highlands\n    fillOpacity = 0.3,           # Transparency for fill\n    group = \"Central Highlands\"\n  ) %&gt;%\n  setView(lng = 145.7, lat = -37.5, zoom = 7) %&gt;% # Set the view to desired location\n  addLegend(\n    position = \"bottomright\",\n    colors = c(\"lightblue\"),\n    labels = c(\"Central Highlands\"),\n    opacity = 0.7\n  ) %&gt;%\n  # Add the custom CSS to modify the legend font size\n  htmlwidgets::prependContent(custom_css)"
  },
  {
    "objectID": "EC_GLM.html#model-objective",
    "href": "EC_GLM.html#model-objective",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "1.2 Model objective",
    "text": "1.2 Model objective\nExplanation: To conduct detailed analyses of species–environment relationships and test specific hypotheses about the main factors driving species distributions.\nMapping/interpolating: To use the estimated species-environment relationships to map the distribution of the targeted species in the same geographic area.\nPrediction in new area: To forecast or project the estimated species–environment relationships to a different geographic area. (Exercise, data provided)"
  },
  {
    "objectID": "EC_GLM.html#biodiversity-data",
    "href": "EC_GLM.html#biodiversity-data",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "2.1 Biodiversity data",
    "text": "2.1 Biodiversity data\nUnderstanding your species is essential. This includes knowing their common names (which may include multiple names) and scientific name to ensure you collect the most comprehensive records available in open-access biodiversity data portals, such as the Atlas of Living Australia (ALA) or the Global Biodiversity Information Facility (GBIF).\nFor this exercise, we have prepared a species occurrence data file in CSV format, which was downloaded from ALA. To make it accessible, we have stored this file in the EcoCommons Public Google Drive for you to download and use conveniently.\n\n# Read the shapefile for mountain ash occurrence point dataset\nmountain_ash_centralhighlands &lt;- st_read(\"mountain_ash_centralhighlands/mountain_ash_centralhighlands.shp\")\n\nReading layer `mountain_ash_centralhighlands' from data source \n  `/Users/zhaoxiang/Documents/tmp/notebook-blog/mountain_ash_centralhighlands/mountain_ash_centralhighlands.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3933 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 145.0258 ymin: -38.2 xmax: 146.4333 ymax: -37.22625\nGeodetic CRS:  GDA94\n\n# Filter the data to include only PRESENT points\nmountain_ash_present &lt;- mountain_ash_centralhighlands %&gt;%\n  dplyr::filter(occrrnS == \"1\")\n\nleaflet() %&gt;%\n  addProviderTiles(providers$Esri.WorldImagery) %&gt;%\n  # Add the Central Highlands layer with a distinct color\n  addPolygons(\n    data = central_highlands,\n    color = \"lightblue\",         # Border color of Central Highlands polygon\n    weight = 1,                  # Border width\n    fillColor = \"lightblue\",     # Fill color of Central Highlands\n    fillOpacity = 0.3,           # Transparency for fill\n    group = \"Central Highlands\"\n  ) %&gt;%\n  # Add Mountain Ash presence points\n  addCircleMarkers(\n    data = mountain_ash_present,\n    color = \"#11aa96\",\n    radius = 1,\n    weight = 0.5,\n    opacity = 1,\n    fillOpacity = 1,\n    group = \"Mountain Ash Presence Records\"\n  ) %&gt;%\n  setView(lng = 145.7, lat = -37.5, zoom = 7) %&gt;% # Adjust longitude, latitude, and zoom as needed\n  # Add layer controls for easier toggling\n  addLayersControl(\n    overlayGroups = c(\"Central Highlands\", \"Mountain Ash Presence Records\"),\n    options = layersControlOptions(collapsed = FALSE)\n  ) %&gt;%\n  # Add a compact legend with a clean style\n  addControl(\n    html = \"\n    &lt;div style='background-color: white; padding: 4px; font-size: 8px; border: none; box-shadow: none;'&gt;\n      &lt;div style='display: flex; align-items: center; margin-bottom: 3px;'&gt;\n        &lt;div style='background: lightblue; width: 10px; height: 10px; margin-right: 5px; opacity: 0.7;'&gt;&lt;/div&gt;\n        Central Highlands\n      &lt;/div&gt;\n      &lt;div style='display: flex; align-items: center;'&gt;\n        &lt;div style='background: #11aa96; width: 10px; height: 10px; margin-right: 5px;'&gt;&lt;/div&gt;\n        Mountain Ash Presence Records\n      &lt;/div&gt;\n    &lt;/div&gt;\n    \",\n    position = \"bottomright\"\n  )"
  },
  {
    "objectID": "EC_GLM.html#pseudo-absence-data",
    "href": "EC_GLM.html#pseudo-absence-data",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "2.2 Pseudo Absence Data",
    "text": "2.2 Pseudo Absence Data\nSpecies distribution models typically require both presence and absence data to predict the distribution of a species. However, true absence data—locations where the species is confirmed not to occur—are often unavailable for various reasons. In such cases, pseudo-absence data are used to fill this gap.\nWe generated pseudo-absence data using the EcoCommons platform with the following configuration:\n\nDispersal Kernel\n\nKey point: Mountain Ash seed dispersal is likely within 150 meters, based on von Takach Dukai (2019).\nImplication: This distance should be factored into pseudo-absence generation to avoid selecting pseudo-absence points too close to presence points, which could bias the model by including areas that the species might still occupy but haven’t been sampled.\n\nAbsence-Presence Ratio\n\nKey point: The ratio of absence to presence is set to 1.\nImplication: For each presence point, one pseudo-absence point should be generated. This balanced ratio ensures the model isn’t skewed by an overabundance of either class and aids in robust statistical comparisons.\n\nPseudo-Absence Strategy\n\nKey point: Disk strategy with a range of 1000 - 5000 meters.\nImplication:\n\nThe disk strategy selects pseudo-absences outside a certain buffer zone from presence points.\nThe range of 1000–5000 meters should be carefully reviewed since it must balance avoiding areas within the species’ potential dispersal kernel (150 meters) and including areas beyond the likely range of colonization.\n\n\n\n\n# Filter the data to include only ABSENT points\nmountain_ash_absent &lt;- mountain_ash_centralhighlands %&gt;%\n  dplyr::filter(occrrnS == \"0\")\n\nleaflet() %&gt;%\n  addProviderTiles(providers$Esri.WorldImagery) %&gt;%\n # Add the Central Highlands layer with a distinct color\n  addPolygons(data = central_highlands,\n              color = \"lightblue\",         # Border color of Central Highlands polygon\n              weight = 1,            # Border width\n              fillColor = \"lightblue\",  # Fill color of Central Highlands\n              fillOpacity = 0.3,     # Transparency for fill\n              group = \"Central Highlands\") %&gt;%\n  \n    # Add Mountain Ash presence points\n  addCircleMarkers(data = mountain_ash_present,\n                   color = \"#11aa96\",\n                   radius = 1,\n                   weight = 0.5,\n                   opacity = 1,\n                   fillOpacity = 1,\n                   group = \"Mountain Ash Presence Records\") %&gt;%\n  \n\n      # Add Mountain Ash absent points\n  addCircleMarkers(data = mountain_ash_absent,\n                   color = \"#f6aa70\",\n                   radius = 1,\n                   weight = 0.5,\n                   opacity = 1,\n                   fillOpacity = 1,\n                   group = \"Mountain Ash Pseudo_absent Records\") %&gt;%\n  \n  setView(lng = 145.7, lat = -37.5, zoom = 7)  %&gt;% # Adjust longitude, latitude, and zoom as needed \n  \n    # Add layer controls for easier toggling\n  addLayersControl(\n    overlayGroups = c(\"Central Highlands\", \"Mountain Ash Presence Records\", \"Mountain Ash Pseudo_absent Records\"),\n    options = layersControlOptions(collapsed = FALSE)\n  ) %&gt;%\n  \n  # Add a legend for the layers\n  addControl(\n    html = \"\n    &lt;div style='background-color: white; padding: 10px; border-radius: 5px;'&gt;\n      &lt;strong&gt;Legend&lt;/strong&gt;&lt;br&gt;\n      &lt;i style='background: lightblue; width: 18px; height: 18px; display: inline-block; margin-right: 8px; opacity: 0.7;'&gt;&lt;/i&gt;\n      Central Highlands&lt;br&gt;\n      &lt;i style='background: #11aa96; width: 10px; height: 10px; border-radius: 50%; display: inline-block; margin-right: 8px;'&gt;&lt;/i&gt;\n      Mountain Ash Presence Records&lt;br&gt;\n      &lt;i style='background: #f6aa70; width: 10px; height: 10px; border-radius: 50%; display: inline-block; margin-right: 8px;'&gt;&lt;/i&gt;\n      Mountain Ash Pseudo-absent Records\n    &lt;/div&gt;\n    \",\n    position = \"bottomright\"\n  )"
  },
  {
    "objectID": "EC_GLM.html#environmental-data",
    "href": "EC_GLM.html#environmental-data",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "2.3 Environmental Data",
    "text": "2.3 Environmental Data\nWhen selecting environmental variables for a model, it is important to avoid indiscriminately including any available data. Instead, select variables thoughtfully, guided by ecological knowledge and the specific hypotheses being tested.\nAs previously mentioned, Mountain Ash thrives in cool, temperate rainforests characterized by high rainfall, deep, well-drained soils, mild temperatures, and high humidity. This species is typically found at altitudes ranging from 200 to 1,000 meters above sea level (Burns et al., 2015). Mountain Ash habitats face two primary forms of disturbance: bushfires, which are the main natural disturbance, and logging, which constitutes the primary human-induced threat (Burns et al., 2015; Nevill et al., 2010).\n\n\n\n\n\n\n\n\n\nEnvironmental Variables Categories\nVariables\nData Type\nSource\n\n\n\n\nTemperature and Radiation\nBioclim 01: Annual mean temperature\nBioclim 04: Temperature Seasonality (standard deviation *100)\nBioclim 06: Min Temperature of Coldest Month\nBioclim 10: Mean Temperature of Warmest Quarter\nBioclim 20: Annual mean radiation\nContinuous\n1976-2005, CSIRO via EcoCommons\n\n\nHumidity\nBioclim 12: Annual Precipitation\nBioclim 18: Precipitation of Warmest Quarter\nBioclim 19: Precipitation of Coldest Quarter\nBioclim 28: Annual mean moisture index\nBioclim 34: Mean moisture index of warmest quarter\nBioclim 35: Mean moisture index of coldest quarter\nContinuous\n1976-2005, CSIRO via EcoCommons\n\n\nTopography\nDigital Elevation Model\nContinuous\nGeoscience Australia via EcoCommons\n\n\nSoil\nAustralian Soil Classification\nCategorical\nTern via EcoCommons\n\n\nDisturbance\nFires\nLogging\nContinuous\nVic DEECA spatial data and resources\n\n\n\n\n# Load the stacked raster layers\nenv_var_stack &lt;- rast(\"mountain_ash_centralhighlands/central_highlands_15envvar.tif\")\n\n# Define the custom names for the raster layers\nlayer_names &lt;- c(\n  \"Annual_Mean_Temp\",\n  \"Temp_Seasonality\",\n  \"Min_Temp_Coldest_Month\",\n  \"Mean_Temp_Warmest_Quarter\",\n  \"Annual_Mean_Radiation\",\n  \"Annual_Precipitation\",\n  \"Precip_Warmest_Quarter\",\n  \"Precip_Coldest_Quarter\",\n  \"Annual_Mean_Moisture\",\n  \"Moisture_Warmest_Quarter\",\n  \"Moisture_Coldest_Quarter\",\n  \"Elevation\",\n  \"Soil_Type\",\n  \"Fires\",\n  \"Logging\"\n)\n\n\n# Assign the custom names to the raster layers\nnames(env_var_stack) &lt;- layer_names\n\n# We want to make sure that soil type raster layer is factor.\nenv_var_stack[[\"Soil_Type\"]] &lt;- as.factor(env_var_stack[[\"Soil_Type\"]])\n\n# Check if the names are assigned correctly\nprint(names(env_var_stack))\n\n [1] \"Annual_Mean_Temp\"          \"Temp_Seasonality\"         \n [3] \"Min_Temp_Coldest_Month\"    \"Mean_Temp_Warmest_Quarter\"\n [5] \"Annual_Mean_Radiation\"     \"Annual_Precipitation\"     \n [7] \"Precip_Warmest_Quarter\"    \"Precip_Coldest_Quarter\"   \n [9] \"Annual_Mean_Moisture\"      \"Moisture_Warmest_Quarter\" \n[11] \"Moisture_Coldest_Quarter\"  \"Elevation\"                \n[13] \"Soil_Type\"                 \"Fires\"                    \n[15] \"Logging\"                  \n\n\n\n# Custom titles for the layers\nlayer_titles &lt;- c(\n  \"Bioclim 01: Annual Mean Temperature\",\n  \"Bioclim 04: Temperature Seasonality (standard deviation *100)\",\n  \"Bioclim 06: Min Temperature of Coldest Month\",\n  \"Bioclim 10: Mean Temperature of Warmest Quarter\",\n  \"Bioclim 20: Annual mean radiation\"\n)\n\n# Indices of the layers to plot\nlayers_to_plot &lt;- c(1, 2, 3, 4, 8)\n\n# Set layout for plotting (3 rows, 2 columns for 5 plots)\npar(mfrow = c(3, 2)) \n\n# Plot each specified layer with its custom title and smaller title size\nfor (i in seq_along(layers_to_plot)) {\n  layer_index &lt;- layers_to_plot[i]\n  plot(env_var_stack[[layer_index]], main = layer_titles[i], cex.main = 0.8) # Adjust cex.main for title size\n}\n\n\n\n\n\n\n\n\n\n# Custom titles for the specified layers\nlayer_titles &lt;- c(\n  \"Bioclim 12: Annual Precipitation\",\n  \"Bioclim 18: Precipitation of Warmest Quarter\",\n  \"Bioclim 19: Precipitation of Coldest Quarter\",\n  \"Bioclim 28: Annual Mean Moisture Index\",\n  \"Bioclim 34: Mean Moisture Index of Warmest Quarter\",\n  \"Bioclim 35: Mean Moisture Index of Coldest Quarter\"\n)\n\n# Indices of the layers to plot\nlayers_to_plot &lt;- c(5, 6, 7, 9, 10, 11)\n\n# Set layout for plotting (3 rows, 2 columns for 5 plots)\npar(mfrow = c(3, 2)) \n\n# Plot each specified layer with its custom title and smaller title size\nfor (i in seq_along(layers_to_plot)) {\n  layer_index &lt;- layers_to_plot[i]\n  plot(env_var_stack[[layer_index]], main = layer_titles[i], cex.main = 0.8) # Adjust cex.main for title size\n}\n\n\n\n\n\n\n\n\n\n# Custom titles for the specified layers\nlayer_titles &lt;- c(\n  \"Digital Elevation Model\",\n  \"Australian Soil Classification\",\n  \"Logging\",\n  \"Fires\"\n)\n\n# Indices of the layers to plot\nlayers_to_plot &lt;- c(12:15)\n\n# Set layout for plotting (3 rows, 2 columns for 5 plots)\npar(mfrow = c(2, 2)) \n\n# Plot each specified layer with its custom title and smaller title size\nfor (i in seq_along(layers_to_plot)) {\n  layer_index &lt;- layers_to_plot[i]\n  plot(env_var_stack[[layer_index]], main = layer_titles[i], cex.main = 0.8) # Adjust cex.main for title size\n}\n\n\n\n\n\n\n\n\nSoil Type Classification: 3 - Dermosol, 4 - Chromosol, 5 - Ferrosol, 7 - Tenosol, 8 - Kandosol,12 - Calcarosol, 13 - Organosol, and 14 - Anthroposol."
  },
  {
    "objectID": "EC_GLM.html#combine-species-occurrence-data-and-environmental-variables",
    "href": "EC_GLM.html#combine-species-occurrence-data-and-environmental-variables",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "2.4 Combine species occurrence data and environmental variables",
    "text": "2.4 Combine species occurrence data and environmental variables\nWe will create a data frame that combines each presence/absence record of Mountain Ash with data from our 15 environmental variables.\n\n# Convert species occurrence data to terra-compatible SpatVector\noccurrence_vect &lt;- vect(mountain_ash_centralhighlands)\n\n# Extract raster values at species occurrence points\nextracted_values &lt;- terra::extract(env_var_stack, occurrence_vect)\n\n# Combine occurrence data with extracted raster values\n# (Keep geometry or drop it based on your needs)\noccurrence_data &lt;- cbind(as.data.frame(mountain_ash_centralhighlands), extracted_values)\n\n# Remove rows with any NA values in predictors\noccurrence_data &lt;- na.omit(occurrence_data)\n\n# we want to make sure the data type of soil types is factor.\noccurrence_data$Soil_Type &lt;- as.factor(occurrence_data$Soil_Type)\n\nhead(occurrence_data)\n\n  occrrnS                   geometry ID Annual_Mean_Temp Temp_Seasonality\n1       1 POINT (145.7339 -37.67417)  1        10.369396         1.424792\n2       1  POINT (146.1373 -37.7804)  2         8.822482         1.449565\n3       1 POINT (145.3817 -37.88166)  3        12.967784         1.280466\n4       1 POINT (146.1797 -37.84517)  4        10.826058         1.390526\n5       1 POINT (145.3362 -37.88002)  5        11.825127         1.278574\n6       1 POINT (145.9281 -37.83222)  6        10.293063         1.386414\n  Min_Temp_Coldest_Month Mean_Temp_Warmest_Quarter Annual_Mean_Radiation\n1              2.0631714                  15.60523              1578.439\n2              0.4309082                  14.10276              1577.427\n3              4.2351027                  17.71625              1133.458\n4              1.5544521                  15.95073              1583.145\n5              3.9153066                  16.52677              1266.487\n6              1.6763960                  15.38035              1609.709\n  Annual_Precipitation Precip_Warmest_Quarter Precip_Coldest_Quarter\n1             250.6433               530.1663               13.70784\n2             268.0575               503.1617               13.63218\n3             203.8828               331.7352               14.27531\n4             275.0496               479.6527               13.56016\n5             230.7354               364.2117               13.97706\n6             267.1724               513.3069               13.54408\n  Annual_Mean_Moisture Moisture_Warmest_Quarter Moisture_Coldest_Quarter\n1            0.9548221                0.8892441                1.0000000\n2            0.9821509                0.9541187                1.0000000\n3            0.8531148                0.6036963                0.9996078\n4            0.9700990                0.9209611                1.0000000\n5            0.9097116                0.7599657                1.0000000\n6            0.9698939                0.9229909                1.0000000\n  Elevation Soil_Type Fires Logging\n1  834.7029         4     0       0\n2 1058.5144         4     0       3\n3  314.3798         4     0       0\n4  658.4626         7     0       9\n5  544.9786         4     0       0\n6  902.7314         4     0       7"
  },
  {
    "objectID": "EC_GLM.html#multicollinearity-and-variable-selection",
    "href": "EC_GLM.html#multicollinearity-and-variable-selection",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "3.1 Multicollinearity and Variable Selection",
    "text": "3.1 Multicollinearity and Variable Selection\nTesting for collinearity among continuous variables is an important step in many modeling processes, particularly in species distribution modeling and other regression-based analyses. Codllinearity occurs when two or more predictor variables in a dataset are highly correlated, which can lead to unstable estimates of regression coefficients and make it difficult to interpret the results.\nThere are two common methods for testing collinearity among continuous variables.\nCorrelation matrix.\n\n\nlayer_names &lt;- c(\n  \"Annual_Mean_Temp\",\n  \"Temp_Seasonality\",\n  \"Min_Temp_Coldest_Month\",\n  \"Mean_Temp_Warmest_Quarter\",\n  \"Annual_Mean_Radiation\",\n  \"Annual_Precipitation\",\n  \"Precip_Warmest_Quarter\",\n  \"Precip_Coldest_Quarter\",\n  \"Annual_Mean_Moisture\",\n  \"Moisture_Warmest_Quarter\",\n  \"Moisture_Coldest_Quarter\",\n  \"Elevation\",\n  \"Fires\",\n  \"Logging\"\n)\n\n\n# Select columns by their names\ncor_data &lt;- occurrence_data[, layer_names]\n\n# Check the structure of the numeric data\nstr(cor_data)\n\n'data.frame':   3932 obs. of  14 variables:\n $ Annual_Mean_Temp         : num  10.37 8.82 12.97 10.83 11.83 ...\n $ Temp_Seasonality         : num  1.42 1.45 1.28 1.39 1.28 ...\n $ Min_Temp_Coldest_Month   : num  2.063 0.431 4.235 1.554 3.915 ...\n $ Mean_Temp_Warmest_Quarter: num  15.6 14.1 17.7 16 16.5 ...\n $ Annual_Mean_Radiation    : num  1578 1577 1133 1583 1266 ...\n $ Annual_Precipitation     : num  251 268 204 275 231 ...\n $ Precip_Warmest_Quarter   : num  530 503 332 480 364 ...\n $ Precip_Coldest_Quarter   : num  13.7 13.6 14.3 13.6 14 ...\n $ Annual_Mean_Moisture     : num  0.955 0.982 0.853 0.97 0.91 ...\n $ Moisture_Warmest_Quarter : num  0.889 0.954 0.604 0.921 0.76 ...\n $ Moisture_Coldest_Quarter : num  1 1 1 1 1 ...\n $ Elevation                : num  835 1059 314 658 545 ...\n $ Fires                    : num  0 0 0 0 0 0 5 0 0 0 ...\n $ Logging                  : num  0 3 0 9 0 7 0 4 8 4 ...\n\n# Calculate the correlation matrix for the numeric columns\ncor_matrix &lt;- cor(cor_data, use = \"complete.obs\", method = \"pearson\")\n\n\ncorrplot(cor_matrix,\n         method = \"color\",            # Use colored squares for correlation\n         type = \"upper\",              # Show upper triangle only\n         order = \"hclust\",            # Reorder variables hierarchically\n         addCoef.col = \"black\",       # Show correlation coefficients in black\n         number.cex = 0.5,            # Reduce the size of correlation labels\n         tl.col = \"black\",            # Text label color\n         tl.srt = 30,                 # Rotate labels slightly for readability\n         tl.cex = 0.5,                # Reduce text size of variable labels (set smaller valu)\n         cl.cex = 0.8,                # Reduce text size of color legend\n         diag = FALSE,                # Hide diagonal\n         col = colorRampPalette(c(\"#11aa96\", \"#61c6fa\", \"#f6aa70\"))(200),\n         sig.level = 0.01, insig = \"blank\")\n\n\n\n\n\n\n\n\nIf you find corrplot is hard for you to make decisions, we can use Variance Inflation Factor (VIF). VIF is another statistical measure used to detect multicollinearity in a set of explanatory (independent) variables in a regression model.\nInterpretation:\n\nVIF = 1: No correlation\nVIF &gt; 1 and &lt;= 5: Moderate correlation; may not require corrective action.\nVIF &gt; 5: Indicates high correlation. Multicollinearity may be problematic, and further investigation is recommended.\nVIF &gt; 10: Strong multicollinearity. The variable is highly collinear with others, and steps should be taken to address this.\n\n\n# Fit a GLM for species distribution\nglm_model &lt;- glm(\n  occrrnS ~ Annual_Mean_Temp + Temp_Seasonality + Min_Temp_Coldest_Month +\n    Mean_Temp_Warmest_Quarter + Annual_Mean_Radiation + Annual_Precipitation +\n    Precip_Warmest_Quarter + Precip_Coldest_Quarter + Annual_Mean_Moisture +\n    Moisture_Warmest_Quarter + Moisture_Coldest_Quarter + Elevation + Fires + Logging,\n  data = occurrence_data,\n  family = binomial(link = \"logit\")  # Logistic regression\n)\n\n\n# Calculate VIF for the GLM\nvif_values &lt;- vif(glm_model)\n\n# Convert VIF values to a data frame with two columns\nvif_table &lt;- data.frame(\n  Variable = names(vif_values),  # Column 1: Variable names\n  VIF = round(vif_values, 2)     # Column 2: VIF values rounded to 2 decimals\n)\n\n# Rank the VIF table from high to low\nvif_table &lt;- vif_table[order(vif_table$VIF, decreasing = TRUE), ]\n\n# Print the ranked table\nprint(vif_table)\n\n                                           Variable      VIF\nAnnual_Mean_Temp                   Annual_Mean_Temp 30369.96\nMean_Temp_Warmest_Quarter Mean_Temp_Warmest_Quarter 21826.71\nAnnual_Mean_Radiation         Annual_Mean_Radiation  2863.99\nAnnual_Mean_Moisture           Annual_Mean_Moisture  1625.31\nTemp_Seasonality                   Temp_Seasonality  1527.84\nMoisture_Warmest_Quarter   Moisture_Warmest_Quarter  1241.81\nPrecip_Warmest_Quarter       Precip_Warmest_Quarter  1228.60\nPrecip_Coldest_Quarter       Precip_Coldest_Quarter   562.37\nAnnual_Precipitation           Annual_Precipitation   308.52\nElevation                                 Elevation    42.83\nMin_Temp_Coldest_Month       Min_Temp_Coldest_Month    24.07\nMoisture_Coldest_Quarter   Moisture_Coldest_Quarter     3.80\nLogging                                     Logging     1.27\nFires                                         Fires     1.03\n\n\nRules of thumb for VIF:\nVariables to Drop (Initial Recommendation):\n\nAnnual_Mean_Temp (High VIF + highly correlated with many others).\nMean_Temp_Warmest_Quarter (High VIF + redundant with Min_Temp_Coldest_Month).\nAnnual_Mean_Radiation (High VIF + redundant with Elevation).\nAnnual_Precipitation (Redundant with Annual_Mean_Moisture).\nPrecip_Warmest_Quarter (Redundant with Moisture_Warmest_Quarter).\n\nGetting rid of some highly correlated variables and run VIF again.\n\n# Fit a GLM for testing the VIF\nglm_model &lt;- glm(\n  occrrnS ~ Temp_Seasonality + Min_Temp_Coldest_Month +\n    Precip_Coldest_Quarter + Moisture_Coldest_Quarter + Elevation + Fires + Logging,\n  data = occurrence_data,\n  family = binomial(link = \"logit\")  # Logistic regression\n)\n\n# Calculate VIF for the GLM\nvif_values &lt;- vif(glm_model)\n\n# Convert VIF values to a data frame with two columns\nvif_table &lt;- data.frame(\n  Variable = names(vif_values),  # Column 1: Variable names\n  VIF = round(vif_values, 2)     # Column 2: VIF values rounded to 2 decimals\n)\n\n# Rank the VIF table from high to low\nvif_table &lt;- vif_table[order(vif_table$VIF, decreasing = TRUE), ]\n\n# Print the ranked table\nprint(vif_table)\n\n                                         Variable  VIF\nElevation                               Elevation 7.21\nMin_Temp_Coldest_Month     Min_Temp_Coldest_Month 5.43\nTemp_Seasonality                 Temp_Seasonality 4.33\nPrecip_Coldest_Quarter     Precip_Coldest_Quarter 3.41\nMoisture_Coldest_Quarter Moisture_Coldest_Quarter 1.53\nLogging                                   Logging 1.13\nFires                                       Fires 1.01\n\n\nNow, from our 14 continuous variables, we choose above 7 variables and 1 categorical variable Soil_Types to make our final model."
  },
  {
    "objectID": "EC_GLM.html#data-splitting",
    "href": "EC_GLM.html#data-splitting",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "3.2 Data splitting",
    "text": "3.2 Data splitting\nFor cross-validation purposes, we need to leave out some data as testing dataset. There are many strategies of splitting data for cross-validation, like random, k-fold, and leave-one-out etc. Here we will use the easiest one: random splitting.\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Split the data into training (80%) and testing (20%)\ntrain_index &lt;- sample(1:nrow(occurrence_data), size = 0.8 * nrow(occurrence_data))\n\n# Create training and testing datasets\ntrain_data &lt;- occurrence_data[train_index, ]\ntest_data &lt;- occurrence_data[-train_index, ]\n\n# Check the split\ncat(\"Training Set:\", nrow(train_data), \"rows\\n\")\n\nTraining Set: 3145 rows\n\ncat(\"Testing Set:\", nrow(test_data), \"rows\\n\")\n\nTesting Set: 787 rows"
  },
  {
    "objectID": "EC_GLM.html#model-fitting-1",
    "href": "EC_GLM.html#model-fitting-1",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "3.3 Model fitting",
    "text": "3.3 Model fitting\nNull model: no explanatory variables or predictors are included.\nIt is always helpful to create a null model as a benchmark to assess how the inclusion of explanatory variables improves the model.\n\n# Let's make a null model as a benchmark\n\n# Fit a null model with only the intercept\nnull_model &lt;- glm(occrrnS ~ 1,\n                  data = train_data,\n                  family = binomial(link = \"logit\"))\n\nsummary(null_model)\n\n\nCall:\nglm(formula = occrrnS ~ 1, family = binomial(link = \"logit\"), \n    data = train_data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.51541    0.03685   13.98   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 4157.8  on 3144  degrees of freedom\nResidual deviance: 4157.8  on 3144  degrees of freedom\nAIC: 4159.8\n\nNumber of Fisher Scoring iterations: 4\n\n\nNow, we can fit a full model.\n\n# Fit the GLM on the training data\nglm_model &lt;- glm(\n  occrrnS ~ Temp_Seasonality + Min_Temp_Coldest_Month +\n    Precip_Coldest_Quarter + Moisture_Coldest_Quarter +\n    Elevation + Fires + Soil_Type + Logging,\n  data = train_data,\n  family = binomial(link = \"logit\")  # Logistic regression\n)\n\n# Summarize the model\nsummary(glm_model)\n\n\nCall:\nglm(formula = occrrnS ~ Temp_Seasonality + Min_Temp_Coldest_Month + \n    Precip_Coldest_Quarter + Moisture_Coldest_Quarter + Elevation + \n    Fires + Soil_Type + Logging, family = binomial(link = \"logit\"), \n    data = train_data)\n\nCoefficients:\n                           Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)               1.662e+01  3.074e+01   0.541   0.5887    \nTemp_Seasonality         -3.247e+00  1.315e+00  -2.470   0.0135 *  \nMin_Temp_Coldest_Month    1.551e+00  9.849e-02  15.750  &lt; 2e-16 ***\nPrecip_Coldest_Quarter   -4.519e+00  3.233e-01 -13.978  &lt; 2e-16 ***\nMoisture_Coldest_Quarter  4.487e+01  2.935e+01   1.529   0.1264    \nElevation                 2.484e-03  4.838e-04   5.133 2.85e-07 ***\nFires                     1.018e-02  9.933e-02   0.103   0.9184    \nSoil_Type4                1.949e+00  3.955e-01   4.928 8.31e-07 ***\nSoil_Type5               -1.770e-01  4.959e-01  -0.357   0.7211    \nSoil_Type7                1.621e+00  4.052e-01   4.002 6.29e-05 ***\nSoil_Type8               -1.347e+01  6.038e+02  -0.022   0.9822    \nSoil_Type12              -1.336e+01  4.723e+02  -0.028   0.9774    \nSoil_Type13              -1.554e+01  1.309e+03  -0.012   0.9905    \nSoil_Type14              -1.286e+01  6.500e+02  -0.020   0.9842    \nLogging                   1.378e-01  1.514e-02   9.102  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 4157.8  on 3144  degrees of freedom\nResidual deviance: 2414.8  on 3130  degrees of freedom\nAIC: 2444.8\n\nNumber of Fisher Scoring iterations: 15"
  },
  {
    "objectID": "EC_GLM.html#summary-of-interpretation",
    "href": "EC_GLM.html#summary-of-interpretation",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "4.1 Summary of Interpretation",
    "text": "4.1 Summary of Interpretation\n\n# Let's compare the performance of our model to a null model\n\n# Compare null model with full model using the analysis of deviance (Likelihood Ratio Test)\nanova(null_model, glm_model, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: occrrnS ~ 1\nModel 2: occrrnS ~ Temp_Seasonality + Min_Temp_Coldest_Month + Precip_Coldest_Quarter + \n    Moisture_Coldest_Quarter + Elevation + Fires + Soil_Type + \n    Logging\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1      3144     4157.8                          \n2      3130     2414.8 14     1743 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Compare the AIC of the null model and the full model\nAIC(null_model, glm_model)\n\n           df      AIC\nnull_model  1 4159.769\nglm_model  15 2444.787\n\n# Get the null deviance and residual deviance from the full model\nnull_deviance &lt;- glm_model$null.deviance\nresidual_deviance &lt;- glm_model$deviance\n\n# Calculate the deviance explained\ndeviance_explained &lt;- (null_deviance - residual_deviance) / null_deviance\n\n# Print the deviance explained as a percentage\ndeviance_explained_percent &lt;- deviance_explained * 100\ncat(\"Deviance Explained:\", deviance_explained_percent, \"%\\n\")\n\nDeviance Explained: 41.92108 %\n\n\nThe Likelihood Ratio Test (ANOVA) shows that adding the predictors significantly improved the model’s fit compared to the null model, as indicated by the high deviance reduction and a p-value of 0.\nThe AIC for the full model is much lower than the null model, further indicating a better fit when balancing model complexity.\nThe Deviance Explained of 42 % suggests that the full model explains almost half of the variability in mountain ash presence/absence, indicating that while the predictors contribute useful information, there is still substantial unexplained variability that may require further investigation or additional predictors.\nVariable Importance metric.\nIt is a measure used to assess the relative importance of predictors (environmental variables) in the model.\n\n# Function to plot effect size graph\nplot_effect_size &lt;- function(glm_model) {\n  # Check if required libraries are installed\n  if (!requireNamespace(\"ggplot2\", quietly = TRUE)) {\n    stop(\"Please install the 'ggplot2' package to use this function.\")\n  }\n  library(ggplot2)\n\n  # Extract effect sizes (coefficients) from the model\n  coefs &lt;- summary(glm_model)$coefficients\n  effect_sizes &lt;- data.frame(\n    Variable = rownames(coefs)[-1],  # Exclude the intercept\n    Effect_Size = coefs[-1, \"Estimate\"],\n    Std_Error = coefs[-1, \"Std. Error\"]\n  )\n\n  # Sort by effect size\n  effect_sizes &lt;- effect_sizes[order(-abs(effect_sizes$Effect_Size)), ]\n\n  # Plot the effect sizes with error bars\n  ggplot(effect_sizes, aes(x = reorder(Variable, Effect_Size), y = Effect_Size)) +\n    geom_bar(stat = \"identity\", fill = \"#11aa96\") +\n    geom_errorbar(aes(ymin = Effect_Size - Std_Error, ymax = Effect_Size + Std_Error), width = 0.2) +\n    coord_flip() +\n    labs(\n      title = \"Effect Sizes of Variables\",\n      x = \"Variable\",\n      y = \"Effect Size (Coefficient Estimate)\"\n    ) +\n    theme_minimal()\n}\n\n# Example usage of effect size plot\nplot_effect_size(glm_model)"
  },
  {
    "objectID": "EC_GLM.html#cross-validation",
    "href": "EC_GLM.html#cross-validation",
    "title": "Species Distribution Analysis - Generalised Linear Model (GLM)",
    "section": "4.2 Cross validation",
    "text": "4.2 Cross validation\nNow, we use the testing data to evaluate the model performance.\n\n# Predict on the testing data\npredicted_probs &lt;- predict(glm_model, newdata = test_data, type = \"response\")\n\n# Create an ROC curve and compute AUC\nroc_curve &lt;- roc(test_data$occrrnS, predicted_probs)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nauc_value &lt;- auc(roc_curve)\n\n# Extract ROC data for ggplot\nroc_data &lt;- data.frame(\n  Sensitivity = roc_curve$sensitivities,\n  Specificity = 1 - roc_curve$specificities\n)\n\n# Plot the ROC curve using ggplot2\nggplot(roc_data, aes(x = Specificity, y = Sensitivity)) +\n  geom_line(color = \"#61cafa\", linewidth = 0.5) +                  # ROC curve\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray\") + # Diagonal line\n  labs(\n    title = paste(\"ROC Curve (AUC =\", round(auc_value, 2), \")\"),\n    x = \"1 - Specificity\",\n    y = \"Sensitivity\"\n  ) +\n  theme_minimal() +                                           # Minimal theme\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"), # Centered and bold title\n    axis.title = element_text(size = 12),                   # Axis label font size\n    axis.text = element_text(size = 10)                     # Axis tick font size\n  )\n\n\n\n\n\n\n\n\n\nplot_species_response &lt;- function(glm_model, predictors, data) {\n  # Check if required libraries are installed\n  if (!requireNamespace(\"ggplot2\", quietly = TRUE) || !requireNamespace(\"gridExtra\", quietly = TRUE)) {\n    stop(\"Please install the 'ggplot2' and 'gridExtra' packages to use this function.\")\n  }\n  library(ggplot2)\n  library(gridExtra)\n\n  # Create empty list to store response plots\n  response_plots &lt;- list()\n\n  # Loop through each predictor variable\n  for (predictor in predictors) {\n    # Create new data frame to vary predictor while keeping others constant\n    pred_range &lt;- seq(\n      min(data[[predictor]], na.rm = TRUE),\n      max(data[[predictor]], na.rm = TRUE),\n      length.out = 100\n    )\n    const_data &lt;- data[1, , drop = FALSE]  # Use first row to keep other predictors constant\n    response_data &lt;- const_data[rep(1, 100), ]  # Duplicate the row\n    response_data[[predictor]] &lt;- pred_range\n\n    # Predict probabilities\n    predicted_response &lt;- predict(glm_model, newdata = response_data, type = \"response\")\n\n    # Create data frame for plotting\n    plot_data &lt;- data.frame(\n      Predictor_Value = pred_range,\n      Predicted_Probability = predicted_response\n    )\n\n    # Add presence and absence data\n    presence_absence_data &lt;- data.frame(\n      Predictor_Value = data[[predictor]],\n      Presence_Absence = data$occrrnS\n    )\n\n    # Generate the response plot\n    p &lt;- ggplot() +\n      geom_line(data = plot_data, aes(x = Predictor_Value, y = Predicted_Probability), color = \"#61c6fa\", linewidth = 1) +\n      geom_point(data = presence_absence_data[presence_absence_data$Presence_Absence == 1, ], aes(x = Predictor_Value, y = Presence_Absence), color = \"#11aa96\", alpha = 0.6) +\n      geom_point(data = presence_absence_data[presence_absence_data$Presence_Absence == 0, ], aes(x = Predictor_Value, y = Presence_Absence), color = \"#f6aa70\", alpha = 0.6) +\n      labs(x = predictor, y = NULL) +\n      theme_minimal() +\n      theme(axis.title.y = element_blank())\n\n    # Store the plot in the list\n    response_plots[[predictor]] &lt;- p\n  }\n\n  # Arrange all plots in one combined plot with a single shared y-axis label\n  grid.arrange(\n    grobs = response_plots, \n    ncol = 3,\n    left = \"Predicted Probability / Presence-Absence\"\n  )\n}\n\n# Example usage:\npredictors &lt;- c(\"Temp_Seasonality\", \"Min_Temp_Coldest_Month\", \"Precip_Coldest_Quarter\", \"Moisture_Coldest_Quarter\", \"Elevation\", \"Fires\", \"Logging\")\nplot_species_response(glm_model, predictors, train_data)\n\n\n\n\n\n\n\n\n\n# Density and Histogram Plot Function\nplot_density_histogram &lt;- function(predicted_probs, actual_labels) {\n  # Combine data into a data frame\n  plot_data &lt;- data.frame(\n    Predicted_Probability = predicted_probs,\n    Presence_Absence = factor(actual_labels, levels = c(0, 1), labels = c(\"Absence\", \"Presence\"))\n  )\n  \n  # Plot density and histogram\n  ggplot(plot_data, aes(x = Predicted_Probability, fill = Presence_Absence)) +\n    geom_histogram(aes(y = after_stat(density)), bins = 10, alpha = 0.6, position = \"identity\") +  # Histogram with density\n    geom_density(alpha = 0.4) +  # Density curve\n    labs(\n      title = \"Density and Histogram of Predicted Probabilities\",\n      x = \"Predicted Probability\",\n      y = \"Density\",\n      fill = \"Presence/Absence\"\n    ) +\n    scale_fill_manual(values = c(\"#f6aa70\", \"#11aa96\")) +  # Custom colors\n    theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n      axis.title = element_text(size = 12),\n      axis.text = element_text(size = 10),\n      legend.position = \"top\"\n    )\n}\n\n# Example usage:\n# Replace `predicted_probs` with your predicted probabilities and `test_data$occrrnS` with your actual labels\nplot_density_histogram(predicted_probs, test_data$occrrnS)"
  },
  {
    "objectID": "dataprep.html",
    "href": "dataprep.html",
    "title": "Data Preparation Overview",
    "section": "",
    "text": "Welcome to the Data Preparation section! Here, you can find various guides and resources to help you with the preparation of data for Species Distribution Models (SDM).\n\n\nBelow is a list of specific topics related to data preparation. Click on each link to access more detailed guides.\n\n\nEnvironmental Data Preparation\nThis guide will help you prepare environmental variables such as bioclimatic data, land use, and others required for SDM.\n\n\n\nOccurrence Data Preparation\nLearn how to download, clean, and format occurrence data for your species of interest.\n\n\n\nRaster Processing\nStep-by-step instructions on how to handle raster data, including reprojecting, cropping, and masking.\n\n\n\nData Cleaning Techniques\nA guide on the best practices for cleaning both environmental and occurrence datasets.\n\nIf you have questions or suggestions, please contact the EcoCommons team."
  },
  {
    "objectID": "dataprep.html#available-guides",
    "href": "dataprep.html#available-guides",
    "title": "Data Preparation Overview",
    "section": "",
    "text": "Below is a list of specific topics related to data preparation. Click on each link to access more detailed guides.\n\n\nEnvironmental Data Preparation\nThis guide will help you prepare environmental variables such as bioclimatic data, land use, and others required for SDM.\n\n\n\nOccurrence Data Preparation\nLearn how to download, clean, and format occurrence data for your species of interest.\n\n\n\nRaster Processing\nStep-by-step instructions on how to handle raster data, including reprojecting, cropping, and masking.\n\n\n\nData Cleaning Techniques\nA guide on the best practices for cleaning both environmental and occurrence datasets.\n\nIf you have questions or suggestions, please contact the EcoCommons team."
  }
]